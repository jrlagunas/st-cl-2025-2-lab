# -*- coding: utf-8 -*-
"""TSPLN, practica 6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dW5jtn4z62GOMhwsJiR9HJfge7iWITsU

#Librerías
"""

from datasets import load_dataset
from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments
from transformers import pipeline
from huggingface_hub import Repository

"""#Carga del dataset"""

# Cargamos el dataset de titulares sarcásticos vs. no sarcásticos
dataset = load_dataset("raquiba/Sarcasm_News_Headline")  # 49 000 ejemplos aprox.

"""#Preprocesamiento y tokenización."""

MODEL_NAME = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)  # Tokenizer de BERT básico

def preprocess(batch):
    return tokenizer(batch["headline"],
                     truncation=True,
                     padding="max_length",
                     max_length=128)

# Tokenizamos en paralelo
dataset = dataset.map(preprocess, batched=True, remove_columns=["headline", "article_link"])
# Renombramos la columna de etiquetas a "labels" para que sea compatible con el Trainer
dataset = dataset.rename_column("is_sarcastic", "labels")

dataset.set_format("torch", columns=["input_ids", "attention_mask", "labels"])

"""#Configuración del modelo y entrenamiento."""

# Cargamos un modelo de clasificación con 2 etiquetas
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)
# Definimos argumentos de entrenamiento
args = TrainingArguments(
    output_dir="sarcasm-checkpoint",
    eval_strategy="epoch",      # Evalúa al final de cada época
    per_device_train_batch_size=16,
    per_device_eval_batch_size=32,
    num_train_epochs=3,
    save_strategy="epoch",
    logging_strategy="steps",
    logging_steps=200,
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
)

# Creamos el Trainer
trainer = Trainer(
    model=model,
    args=args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    tokenizer=tokenizer,
    compute_metrics=lambda p: {"accuracy": (p.predictions.argmax(-1) == p.label_ids).mean()},
)
# Entrenamiento
trainer.train()

"""#Evaluación y prueba"""

# Evaluar en el test set
metrics = trainer.evaluate()
print(metrics)  # Devuelve accuracy, loss, etc.

# Función de inferencia básica

sarcasm_pipe = pipeline(
    "text-classification",
    model="EARSV/sarcasm-detector",
    tokenizer="EARSV/sarcasm-detector",
    return_all_scores=False
)
# Prueba rápida
examples = [
    "scientist discovers water is wet, wins nobel prize for groundbreaking revelation",
    "local man finally learns to parallel park after 20 years of daily practice",
    "city council announces new plan to solve traffic by building more traffic lights",
    "study confirms people who sleep 8 hours feel more rested",
    "ceo of fast-food chain urges employees to eat healthier during unpaid overtime",
    "new app reminds users to blink regularly while staring at screens",
    "weather forecast predicts rain during outdoor wedding, couple devastated",
    "man wins lifetime supply of broccoli, considers moving to another country",
    "government proposes tax on air to fund climate change initiatives",
    "new yoga studio opens downtown, offers free classes this weekend"
]

for text in examples:
    res = sarcasm_pipe(text)[0]
    print(f"Texto: {text}\n  Sarcástico: {res['label']} ({res['score']:.4f})\n")

"""#Subir el modelo a Hugging Face"""

#Clonamos el repo de Hugging Face donde subiremos el modelo
repo = Repository(
    local_dir="sarcasm-detector-local",
    clone_from="EARSV/sarcasm-detector"
)

# Copiamos el modelo y el tokenizer al repo
model.save_pretrained("sarcasm-detector-local/")
tokenizer.save_pretrained("sarcasm-detector-local/")

# Añadimos el README.md
with open("sarcasm-detector-local/README.md","w") as f:
    f.write("""
# Sarcasm Detector

Fine-tuned `bert-base-uncased` on raquiba/Sarcasm_News_Headline.

**Exactitud (test)**: 99.86 %
**Epochs**: 3
**Batch size**: 16
**Dataset**: titulares con etiqueta `is_sarcastic`
    """)

# Commit y push
repo.push_to_hub(commit_message="Initial upload of sarcasm-detector")