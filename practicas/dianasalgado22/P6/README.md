# **Pr√°ctica 06** ‚Äì Fine-tuning en producci√≥n  
## **Hecha por:** Diana Laura Salgado Tirado

### üß† **Descripci√≥n**
En esta pr√°ctica se realiz√≥ el ajuste fino (*fine-tuning*) de un modelo de lenguaje preentrenado para clasificar oraciones en espa√±ol como **sexistas** o **no sexistas**. Posteriormente, el modelo fue puesto en producci√≥n a trav√©s de una interfaz interactiva desarrollada con **Gradio** y desplegada en **Hugging Face Spaces**.

Se utiliz√≥ como base el modelo `delarosajav95/HateSpeech-BETO-cased-v2` y el conjunto de datos proveniente de la competencia **EXIST 2024**. 

Adem√°s, se us√≥ **CodeCarbon** para medir el impacto ambiental del entrenamiento del modelo.

---

### ‚öôÔ∏è **Librer√≠as y Dependencias Utilizadas**

Esta pr√°ctica hace uso de m√∫ltiples librer√≠as para el procesamiento, entrenamiento y despliegue del modelo:

- `pandas`, `numpy`, `os`, `time`, `datetime`
- `transformers` (Hugging Face)
- `datasets`
- `sklearn`
- `torch`
- `evaluate`
- `gradio`
- `huggingface_hub`
- `codecarbon`
- `utils` (archivo auxiliar para el ajuste fino del modelo)

---

### üå± **Reporte de Emisiones**
Se utiliz√≥ la librer√≠a `codecarbon` para estimar las emisiones de CO‚ÇÇ durante el ajuste fino del modelo, obteniendo un valor aproximado de:

> **0.0041 kg de CO‚ÇÇ**

Este c√°lculo se realiz√≥ en un entorno con GPU (NVIDIA RTX 3080). No fue posible medir las emisiones de la app en producci√≥n debido a que Hugging Face Spaces no permite monitorear el uso energ√©tico directamente.

---

### üìå **Notas**
Se emplearon modelos de lenguaje (LLMs) como herramienta de apoyo para la documentaci√≥n, optimizaci√≥n del c√≥digo, y correcci√≥n ortogr√°fica y sint√°ctica.

