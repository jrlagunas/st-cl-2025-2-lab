{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e6ea71-b103-47ca-a9ae-f5d793a018cf",
   "metadata": {
    "id": "23e6ea71-b103-47ca-a9ae-f5d793a018cf"
   },
   "source": [
    "# 7. Aprovechando LLMs locales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0f1a26-87c1-4358-a977-dcf6f0cd4ac3",
   "metadata": {
    "id": "cc0f1a26-87c1-4358-a977-dcf6f0cd4ac3"
   },
   "source": [
    "## ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57c01f-79d1-4852-906b-6b71474ee1d9",
   "metadata": {
    "id": "df57c01f-79d1-4852-906b-6b71474ee1d9"
   },
   "source": [
    "<center><img src=\"https://ollama.com/public/ollama.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f51b9eb-cafb-4c18-aa43-3b6b7567220f",
   "metadata": {
    "id": "2f51b9eb-cafb-4c18-aa43-3b6b7567220f"
   },
   "source": [
    "Ollama es una app chiquita que permite obtener y correr LLMs de forma sencilla. Podemos visitar la [documentación](https://github.com/ollama/ollama/blob/main/README.md#quickstart) para saber más características. Hay una lista de modelos disponibles y filtros para identificar sus capacidades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aecdccb-c732-4c3d-91af-bc5ff0831eb4",
   "metadata": {
    "id": "3aecdccb-c732-4c3d-91af-bc5ff0831eb4"
   },
   "source": [
    "### Modelos de Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c528127-5775-4cc8-ba4c-2d98ef9c6d34",
   "metadata": {
    "id": "9c528127-5775-4cc8-ba4c-2d98ef9c6d34"
   },
   "source": [
    "<center><img src=\"https://ollama.com/public/blog/what-are-embeddings.svg\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cd19dc-5a63-4cc7-8f0c-e096b505233e",
   "metadata": {
    "id": "c5cd19dc-5a63-4cc7-8f0c-e096b505233e"
   },
   "source": [
    "Estos modelos estan especialmente diseñados para generar vectores de embeddings (o seá arreglos de números que capturan características semánticas y de otros tipos de la entrada). Estos modelos son fundamentales para crear aplicaciones como *RAGs*.\n",
    "\n",
    "> source: https://ollama.com/blog/embedding-models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124117bf-60c4-4d94-ba58-b7ad21f6baef",
   "metadata": {
    "id": "124117bf-60c4-4d94-ba58-b7ad21f6baef"
   },
   "source": [
    "### Modelos con soporte para *tools*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a12d22-f679-491a-8dfe-930b2f0695d1",
   "metadata": {
    "id": "45a12d22-f679-491a-8dfe-930b2f0695d1"
   },
   "source": [
    "<center><img src=\"https://wallpapercave.com/wp/wp2195747.jpg\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85ad21c-3804-4bdb-aa6f-c39a50fcfb69",
   "metadata": {
    "id": "d85ad21c-3804-4bdb-aa6f-c39a50fcfb69"
   },
   "source": [
    "Llamar *tools* le da la posibilidad a los LLMs de realizar tareas complejas o interactuar con entornos fuera del contexto local del LLM:\n",
    "\n",
    "Ejemplos pueden ser los siguientes:\n",
    "\n",
    "- Uso de funciones pre-exitentes o APIs\n",
    "- Navegación en la web\n",
    "- Utilizar un interprete de código\n",
    "\n",
    "> source: https://ollama.com/blog/tool-support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd96a7b-6280-48fb-aad0-ec66d763de1a",
   "metadata": {
    "id": "cbd96a7b-6280-48fb-aad0-ec66d763de1a"
   },
   "source": [
    "### Comandos útiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b639d-6535-49f2-852b-6ceee41e4952",
   "metadata": {
    "id": "7d1b639d-6535-49f2-852b-6ceee41e4952"
   },
   "outputs": [],
   "source": [
    "!ollama serve &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab05f9b-dd50-4ea7-8d8a-5c8eb1dbf510",
   "metadata": {
    "id": "1ab05f9b-dd50-4ea7-8d8a-5c8eb1dbf510",
    "outputId": "4912c28e-84cc-4cfc-a06d-9fdcbe53220b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "  ollama [flags]\n",
      "  ollama [command]\n",
      "\n",
      "Available Commands:\n",
      "  serve       Start ollama\n",
      "  create      Create a model from a Modelfile\n",
      "  show        Show information for a model\n",
      "  run         Run a model\n",
      "  stop        Stop a running model\n",
      "  pull        Pull a model from a registry\n",
      "  push        Push a model to a registry\n",
      "  list        List models\n",
      "  ps          List running models\n",
      "  cp          Copy a model\n",
      "  rm          Remove a model\n",
      "  help        Help about any command\n",
      "\n",
      "Flags:\n",
      "  -h, --help      help for ollama\n",
      "  -v, --version   Show version information\n",
      "\n",
      "Use \"ollama [command] --help\" for more information about a command.\n"
     ]
    }
   ],
   "source": [
    "!ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd42fa4a-cf4d-4409-a55c-b8bfea51ac3b",
   "metadata": {
    "id": "bd42fa4a-cf4d-4409-a55c-b8bfea51ac3b",
    "outputId": "5907a881-e7ce-4470-fabc-1c0bd822fbf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED   \n",
      "qwen3:1.7b                 458ce03a2187    1.4 GB    3 days ago    \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    4 days ago    \n",
      "qwen2.5-coder:1.5b         6d3abb8d2d53    986 MB    6 days ago    \n",
      "qwen2.5-coder:0.5b         d392ed348d5b    531 MB    6 days ago    \n",
      "codegemma:7b               0c96700aaada    5.0 GB    6 days ago    \n",
      "gemma3:4b                  a2af6cc3eb7f    3.3 GB    7 days ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad6ada-ffcc-4bea-a6b4-a3686474c25b",
   "metadata": {
    "id": "12ad6ada-ffcc-4bea-a6b4-a3686474c25b"
   },
   "outputs": [],
   "source": [
    "!ollama pull <model>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108e91e6-8914-4116-84f3-999acb9c9f54",
   "metadata": {},
   "source": [
    "Modelos a utiliza:\n",
    "\n",
    "### nomic-embed-text:latest   \n",
    "### qwen3:1.7b             \n",
    "### qwen2.5-coder:0.5b "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d132290-3bf9-4ff7-b0d6-593e0e749228",
   "metadata": {
    "id": "1d132290-3bf9-4ff7-b0d6-593e0e749228"
   },
   "source": [
    "### Probando en terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e7dea2-6dfe-4d98-8b91-558c7b8977f1",
   "metadata": {
    "id": "e0e7dea2-6dfe-4d98-8b91-558c7b8977f1"
   },
   "source": [
    "- Simples preguntas\n",
    "- Creando un `ModelFile`\n",
    "- ollama API\n",
    "\n",
    "```bash\n",
    "curl http://localhost:11434/api/chat -d '{\n",
    "  \"model\": \"llama3.2\",\n",
    "  \"messages\": [\n",
    "    { \"role\": \"user\", \"content\": \"why is the sky blue?\" }\n",
    "  ]\n",
    "}'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a47f9b-3378-4818-bf81-6a71d066fbc8",
   "metadata": {
    "id": "68a47f9b-3378-4818-bf81-6a71d066fbc8"
   },
   "source": [
    "### Integrando llms a nuestro flujo de trabajo local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea5a46f-fc01-40ee-be2f-a1deda77f51c",
   "metadata": {
    "id": "9ea5a46f-fc01-40ee-be2f-a1deda77f51c"
   },
   "source": [
    "Vamos a integrar los modelos que obtenemos con `ollama` para completado de código en nuestro editor de código vía un plug-in llamado [Continue](https://docs.continue.dev/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9fee67-a473-4230-b246-f9f5422dddcd",
   "metadata": {
    "id": "9f9fee67-a473-4230-b246-f9f5422dddcd",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Demo en vivo (esperemos que salga bien)\n",
    "\n",
    "- https://docs.continue.dev/customize/deep-dives/autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2695120-27ca-4544-96ae-54c59eacfabb",
   "metadata": {
    "id": "e2695120-27ca-4544-96ae-54c59eacfabb"
   },
   "source": [
    "## Question answering (*Q&A*) y la técnica de Retrieval-augmented generation (*RAG*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfc864-7dfe-4a97-8373-218e7aca4e1c",
   "metadata": {
    "id": "6ecfc864-7dfe-4a97-8373-218e7aca4e1c"
   },
   "source": [
    "Una tarea que han resuleto los LLMs es la generación de respuestas a preguntas del usuario. Sistemas especializados en *Q&A* de hecho han mostrado ser tan buenos o mejores que personas antes de los LLMs. Por ejemplo, Watson que ganó el juego Jeopardy en 2011 superando humanos en preguntas como:\n",
    "\n",
    "> Soy la comida por la que le hacen burla a los chilangos fuera de la CDMX^[1]\n",
    "\n",
    "[1]: Guajolota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3787e7db-0b34-4146-9e3f-c33145dfc8f6",
   "metadata": {
    "id": "3787e7db-0b34-4146-9e3f-c33145dfc8f6",
    "outputId": "5f6e2bef-0b45-4631-b82c-c3608dd9febb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"960\" height=\"515\" src=\"https://www.youtube.com/embed/P18EdAKuC1U\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"960\" height=\"515\" src=\"https://www.youtube.com/embed/P18EdAKuC1U\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b3b491-3c94-46b9-b18d-7ceb4cb2e970",
   "metadata": {
    "id": "26b3b491-3c94-46b9-b18d-7ceb4cb2e970"
   },
   "source": [
    "Los sistemas de *Q&A* estan diseñados para completar información de acuerdo a las necesidades de las personas. Ya que mucha información está disponible en forma de texto (como en internet, libros o nuestros emails), estos sistemas están intimamente ligados a los motores de búsqueda. En realidad, esta distinción es cada vez más difusa ya que los motores de búsqueda actuales incorporan LLMs para proponer respuestas.\n",
    "\n",
    "<center><img src=\"https://nextcloud.tepezil.net/apps/files_sharing/publicpreview/85Mdrbi8CyYjxjs?file=/&fileId=74451&x=2560&y=1440&a=true&etag=e0442b519a9265c9e9324e41716c8929\" width=700></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d68ecd-6c8a-4047-9402-7df95747ba87",
   "metadata": {
    "id": "e1d68ecd-6c8a-4047-9402-7df95747ba87"
   },
   "source": [
    "En general los sistemas de *Q&A* se han enfocado en un subtipo de preguntas: **factoides**. Este tipo de preguntas pueden ser respondidas con simples hecho expresados en respuestas cortas o medianas. Por ejemplo:\n",
    "\n",
    "- ¿Dónde está el Museo de Antropología e Historia de la CDMX?\n",
    "- ¿Cómo poner el `@` en un teclado en inglés?\n",
    "- ¿Cómo instalar archlinux sin morir en el intento?^[2]\n",
    "\n",
    "[2]: Visita la wiki: https://wiki.archlinux.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb93d8-83e7-4a75-8fac-12e2ca41ff26",
   "metadata": {
    "id": "36cb93d8-83e7-4a75-8fac-12e2ca41ff26"
   },
   "source": [
    "### ❓ Con los temas vistos ¿Cómo resolverían esta tarea?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287bda53-cc89-4e93-9482-f12f82a76aa1",
   "metadata": {
    "id": "287bda53-cc89-4e93-9482-f12f82a76aa1"
   },
   "source": [
    "Una opción es hacer un *fine-tunning* a un modelo pre-entrenado con un *dataset* de question-answering y despues crear prompts con la pregunta y la respuesta en blanco:\n",
    "\n",
    "> Q: ¿Dónde se encuentra la biblioteca del IIMAS? R: ____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0abd5fb-f67d-43d0-893a-edf5eac043fd",
   "metadata": {
    "id": "b0abd5fb-f67d-43d0-893a-edf5eac043fd"
   },
   "source": [
    "### Problemas de LLMs tirando factos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa608145-6fc8-49a7-b06d-9af757527217",
   "metadata": {
    "id": "aa608145-6fc8-49a7-b06d-9af757527217"
   },
   "source": [
    "Los LLMs tienen varias deficiencias a la hora de responder a las preguntas que les hacemos\n",
    "\n",
    "- **Alucinaciones:** Los modelos tienden a alucinar, esto es que crean respuestas que parecen convincentes y bien formadas pero que no son reales en absoluto. Es dificil saber cuando un modelo está alucinando.\n",
    "- **Carencia de datos privados:** Los modelos han sido entrenados con grandes cantidades de datos pero no todos los datos posibles. Si queremos que respondan cosas acerca de nuestros correos o registros dentales probablemente no obtendremos respuestas satisfactorias.\n",
    "- **Datos estáticos:** Los modelos tienen problemas en responder preguntas acerca de eventos cuya información esta cambiando rápidamente. Los LLMs se entrenan con datos hasta alguna fecha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330bb59-7efa-4885-8265-c149eaee09fa",
   "metadata": {
    "id": "2330bb59-7efa-4885-8265-c149eaee09fa"
   },
   "source": [
    "![](https://i.pinimg.com/originals/82/c1/22/82c122be87204cf8baa442aa27e68a84.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d54e279-0cce-4467-ac0b-303a46cc7915",
   "metadata": {
    "id": "5d54e279-0cce-4467-ac0b-303a46cc7915"
   },
   "source": [
    "### Acerca de los *RAGs*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f315ffc-b0da-407c-acd5-8e891d63cb15",
   "metadata": {
    "id": "8f315ffc-b0da-407c-acd5-8e891d63cb15"
   },
   "source": [
    "Por las razones antes enumeradas, una estrategía para que los LLMs realicen *Q&A* efectivamente es la de *retrieval-augmented generation (RAG)*. *RAG* utiliza técnicas de *Information Retrieval (IR)* para obtener documentos que serán reelevantes para responder a la pregunta del usuario. Despues se utiliza un LLM para generar una respuesta con base en los documentos obtenidos.\n",
    "\n",
    "Basar las respuestas en los documentos obtenidos resuelve varios de los problemas mencionados anteriormente. En primer lugar, ayuda a que la respuesta esté basada en hecho obtenidos de documentos previamente curados. Además, el sistema puede otorgar al usuario el contexto o documentos que tomó en cuenta para generar la respuesta (un ejemplo: [perplexity AI](https://www.perplexity.ai/search/las-bicicletas-de-pinon-fijo-s-Qr0l4YnETi.Q_d4yrxVyVA)). Esta característica brinda confianza y mayor explicabilidad. Por último, esta técnica permite agregar al sistema información personal o confidencial como registros médicos, legales o notas (aunque mucho ojo con dar sus datos a grandes empresas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a61a1c1-0837-48d9-be75-6af7a1c9717e",
   "metadata": {
    "id": "9a61a1c1-0837-48d9-be75-6af7a1c9717e"
   },
   "source": [
    "### Arquitectura de un *RAG*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081537df-b4a4-4378-aa6f-d2642936674f",
   "metadata": {
    "id": "081537df-b4a4-4378-aa6f-d2642936674f"
   },
   "source": [
    "La idea principal es que dada una **pregunta** del usuario y tomando en cuenta un conjunto de **documentos reelevantes** previamente **obtenidos** se **generar** una respuesta. Podemos entonces dividirlo en dos fases:\n",
    "\n",
    "1. *Retrieval:* Obtenemos los documentos reelevantes de alguna colección\n",
    "2. *Generation:* Se genera una respuesta con base en estos documentos reelvantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30646ea-a11b-41a5-9491-40cd6863cac6",
   "metadata": {
    "id": "b30646ea-a11b-41a5-9491-40cd6863cac6"
   },
   "source": [
    "<center><img src=\"https://nextcloud.tepezil.net/apps/files_sharing/publicpreview/qsnw9Q8q4TWLQ88?file=/&fileId=74486&x=2560&y=1440&a=true&etag=4560b4a64d98ac7e1e16b563ce2db91e\" width=700></center>\n",
    "> Tomada de Speech and Language Processing, (Jurafsky et al 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfcdfa9-fd35-488a-b068-688485c10392",
   "metadata": {
    "id": "cdfcdfa9-fd35-488a-b068-688485c10392"
   },
   "source": [
    "Visto de otro modo, la tarea de *Q&A* puede modelarse como predicción de texto de forma auto-regresiva condicionada a un prompt con características particulares.\n",
    "\n",
    "```\n",
    "Q: ¿Quien escribió el libro 'Bovedas de acero'? A:\n",
    "```\n",
    "\n",
    "$$\n",
    "p(x_1,...,x_n) = \\displaystyle\\prod_{i=1}^{n} p(\\texttt{[Q:]};q;\\texttt{[A:]};x_{<i})\n",
    "$$\n",
    "\n",
    "Podemos hacer esto gracias a que los LLMs codifican una enorme cantidad de información en los parámetros gracias al acceso a muchísimos datos de entrenamiento. Sin embargo, si bien esté prompt servirá para responder preguntas *factoides*, aún tendriamos los problemas de alucinaciones, falta de evidencia en la respuesta y limitaciones con datos no disponibles de forma pública.\n",
    "\n",
    "Los *RAGs* lidian con este problema condicionando la respuesta con documentos reelevantes y algún prompts como: \"Con base en los siguientes documentos, contesta la siguiente pregunta:\"\n",
    "\n",
    "Supongase que tenemos una query $q$ y un conjunto de documentos reelevantes a la query $R(q)$ el prompt se vería como se muestra a continuación:\n",
    "\n",
    "```c\n",
    "doc 1\n",
    "doc 2\n",
    "...\n",
    "doc n\n",
    "\n",
    "Con base en los textos anteriores, responde esta pregunta: Q: \"¿Quien escribió el libro 'Bovedas de acero'\" A:\n",
    "```\n",
    "\n",
    "$$\n",
    "p(x_1,...,x_n) = \\displaystyle\\prod_{i=1}^{n} p(x_i|R(q);prompt;\\texttt{[Q:]};q;\\texttt{[A:]};x_{<i})\n",
    "$$\n",
    "\n",
    "Se pueden combinar enfoques legados como $tfidf$ o $BM25$ con representaciones densas (AKA *embeddings*) de los documentos para la obtención y ordenamiento de los documentos reelevantes. Una parte importante es el *prompt engineering*; decidir como marcar la pregunta o los documentos o si agregar tokens especiales como `[SEP]` puede mejorar o empeorar nuestros resultados.\n",
    "\n",
    "- [Curso gratuito de Prompt Engineering, DeepLearning.AI](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6f898a-f94f-47bd-baf1-7cf0ed54e23f",
   "metadata": {
    "id": "cb6f898a-f94f-47bd-baf1-7cf0ed54e23f"
   },
   "source": [
    "## Creando un RAG con `langchain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61aa4e46-6596-428a-8071-9cb6f57be2e2",
   "metadata": {
    "id": "61aa4e46-6596-428a-8071-9cb6f57be2e2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from rich import print as rprint\n",
    "\n",
    "# Necesario que langchain vea esto\n",
    "os.environ[\"OLLAMA_HOST\"] = \"127.0.0.1\"\n",
    "os.environ[\"OLLAMA_PORT\"] = \"11434\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2d508e-7c28-4d85-9eae-fd5b57b115e0",
   "metadata": {
    "id": "be2d508e-7c28-4d85-9eae-fd5b57b115e0",
    "outputId": "321977b7-f519-443d-c109-207ba25f2d28"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">environ</span><span style=\"font-weight: bold\">({</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'BROWSER'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'firefox'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'COLORTERM'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'truecolor'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'CONDA_EXE'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/opt/miniconda3/bin/conda'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'CONDA_PYTHON_EXE'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/opt/miniconda3/bin/python'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'CONDA_SHLVL'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'DBUS_SESSION_BUS_ADDRESS'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'unix:path=/run/user/1000/bus'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'DEBUGINFOD_URLS'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://debuginfod.archlinux.org '</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'DESKTOP_SESSION'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gnome'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'DISPLAY'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">':0'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'EDITOR'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'nvim'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'FZF_DEFAULT_COMMAND'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fd --type f --hidden --exclude .git'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'GDMSESSION'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gnome'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'GDM_LANG'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en_US.UTF-8'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'GIO_LAUNCHED_DESKTOP_FILE_PID'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2374'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'GNOME_KEYRING_CONTROL'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/run/user/1000/keyring'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'GNOME_SETUP_DISPLAY'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">':1'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'GOPATH'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/umoqnier/go/bin/'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'HOME'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/umoqnier'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'INVOCATION_ID'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'d4b57d9c98974eb99981fdaf37ad2d77'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'JOURNAL_STREAM'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'9:15040'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'KITTY_INSTALLATION_DIR'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/usr/lib/kitty'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'KITTY_PID'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2374'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'KITTY_PUBLIC_KEY'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1:?ER0gqZ{Qn!&amp;L`sK1WU;MBXi8`RTdBFksq$_k@=)'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'KITTY_WINDOW_ID'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'LANG'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en_US.UTF-8'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'LC_ADDRESS'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en_US.UTF-8'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'LC_IDENTIFICATION'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en_US.UTF-8'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'LC_MEASUREMENT'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en_US.UTF-8'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'LC_MONETARY'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en_US.UTF-8'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'LC_NAME'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en_US.UTF-8'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'LC_NUMERIC'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en_US.UTF-8'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'LC_PAPER'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en_US.UTF-8'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'LC_TELEPHONE'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en_US.UTF-8'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'LC_TIME'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en_US.UTF-8'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'LESS'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'-R'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'LOGNAME'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'umoqnier'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'LSCOLORS'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Gxfxcxdxbxegedabagacad'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'LS_COLORS'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;4</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">3:ca=00:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.7z=01;31:*.ace=01;31:*.alz=01;31:*.apk=01;31:*.arc=01;31:*.arj=01;31:</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">*.bz=01;31:*.bz2=01;31:*.cab=01;31:*.cpio=01;31:*.crate=01;31:*.deb=01;31:*.drpm=01;31:*.dwm=01;31:*.dz=01;31:*.ear</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">=01;31:*.egg=01;31:*.esd=01;31:*.gz=01;31:*.jar=01;31:*.lha=01;31:*.lrz=01;31:*.lz=01;31:*.lz4=01;31:*.lzh=01;31:*.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">lzma=01;31:*.lzo=01;31:*.pyz=01;31:*.rar=01;31:*.rpm=01;31:*.rz=01;31:*.sar=01;31:*.swm=01;31:*.t7z=01;31:*.tar=01;</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">31:*.taz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tgz=01;31:*.tlz=01;31:*.txz=01;31:*.tz=01;31:*.tzo=01;31:*.tzst=01;31:*.u</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">deb=01;31:*.war=01;31:*.whl=01;31:*.wim=01;31:*.xz=01;31:*.z=01;31:*.zip=01;31:*.zoo=01;31:*.zst=01;31:*.avif=01;35</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">:*.jpg=01;35:*.jpeg=01;35:*.jxl=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=0</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">1;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.c</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">gm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xs</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pf=00;36:*~=00;90:*#=00;90:*.bak=00;90:*.crdownload=00;90:*.dpkg-dist=00;90:*.dpkg-new=00;90:*.dpkg-old=00;90:*.dpk</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">g-tmp=00;90:*.old=00;90:*.orig=00;90:*.part=00;90:*.rej=00;90:*.rpmnew=00;90:*.rpmorig=00;90:*.rpmsave=00;90:*.swp=</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">00;90:*.tmp=00;90:*.ucf-dist=00;90:*.ucf-new=00;90:*.ucf-old=00;90:'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'MAIL'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/var/spool/mail/umoqnier'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'MANAGERPID'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1423'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'MEMORY_PRESSURE_WATCH'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'/sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/session.slice/org.gnome.SettingsDaemon.MediaKeys.servi</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ce/memory.pressure'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'MEMORY_PRESSURE_WRITE'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'c29tZSAyMDAwMDAgMjAwMDAwMAA='</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'MOTD_SHOWN'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'pam'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'OLDPWD'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/umoqnier'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'PAGER'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cat'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'PATH'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'/home/umoqnier/develop/lectures/st-cl-2025-2-lab/.venv/bin:/opt/miniconda3/condabin:/home/umoqnier/.emacs.d/bin:/h</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ome/umoqnier/.cargo/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bi</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">n/vendor_perl:/usr/bin/core_perl:/opt/rocm/bin:/home/umoqnier/.local/bin/:/home/umoqnier/go/bin/'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'PWD'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/umoqnier/develop/lectures/st-cl-2025-2-lab'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ROCM_PATH'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/opt/rocm'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'SDKMAN_DIR'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/umoqnier/.sdkman'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'SESSION_MANAGER'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'local/arrakis:@/tmp/.ICE-unix/1504,unix/arrakis:/tmp/.ICE-unix/1504'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'SHELL'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/usr/bin/zsh'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'SHLVL'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'SSH_KEY_PATH'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'~/.ssh/id_ed25519'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'SYSTEMD_EXEC_PID'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1648'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'TERM'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'xterm-color'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'TERMINFO'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/usr/lib/kitty/terminfo'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'USER'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'umoqnier'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'USERNAME'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'umoqnier'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'UV'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/usr/bin/uv'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'UV_RUN_RECURSION_DEPTH'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'VIRTUAL_ENV'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/umoqnier/develop/lectures/st-cl-2025-2-lab/.venv'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'WAYLAND_DISPLAY'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'wayland-0'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'XAUTHORITY'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/run/user/1000/.mutter-Xwaylandauth.IBII62'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'XDG_CURRENT_DESKTOP'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'GNOME'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'XDG_MENU_PREFIX'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gnome-'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'XDG_RUNTIME_DIR'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/run/user/1000'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'XDG_SESSION_CLASS'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'XDG_SESSION_DESKTOP'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gnome'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'XDG_SESSION_TYPE'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'wayland'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ZSH'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/umoqnier/.oh-my-zsh'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'_'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/usr/bin/uv'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'_CE_CONDA'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'_CE_M'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'JPY_SESSION_NAME'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/home/umoqnier/develop/lectures/st-cl-2025-2-lab/notebooks/7_local_llm_apps.ipynb'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'JPY_PARENT_PID'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2510'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'PYDEVD_USE_FRAME_EVAL'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'NO'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'CLICOLOR'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'FORCE_COLOR'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'CLICOLOR_FORCE'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'GIT_PAGER'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cat'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'MPLBACKEND'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'module://matplotlib_inline.backend_inline'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'OLLAMA_HOST'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'127.0.0.1'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'OLLAMA_PORT'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'11434'</span>\n",
       "<span style=\"font-weight: bold\">})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35menviron\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'BROWSER'\u001b[0m: \u001b[32m'firefox'\u001b[0m,\n",
       "    \u001b[32m'COLORTERM'\u001b[0m: \u001b[32m'truecolor'\u001b[0m,\n",
       "    \u001b[32m'CONDA_EXE'\u001b[0m: \u001b[32m'/opt/miniconda3/bin/conda'\u001b[0m,\n",
       "    \u001b[32m'CONDA_PYTHON_EXE'\u001b[0m: \u001b[32m'/opt/miniconda3/bin/python'\u001b[0m,\n",
       "    \u001b[32m'CONDA_SHLVL'\u001b[0m: \u001b[32m'0'\u001b[0m,\n",
       "    \u001b[32m'DBUS_SESSION_BUS_ADDRESS'\u001b[0m: \u001b[32m'unix:\u001b[0m\u001b[32mpath\u001b[0m\u001b[32m=/run/user/1000/bus'\u001b[0m,\n",
       "    \u001b[32m'DEBUGINFOD_URLS'\u001b[0m: \u001b[32m'https://debuginfod.archlinux.org '\u001b[0m,\n",
       "    \u001b[32m'DESKTOP_SESSION'\u001b[0m: \u001b[32m'gnome'\u001b[0m,\n",
       "    \u001b[32m'DISPLAY'\u001b[0m: \u001b[32m':0'\u001b[0m,\n",
       "    \u001b[32m'EDITOR'\u001b[0m: \u001b[32m'nvim'\u001b[0m,\n",
       "    \u001b[32m'FZF_DEFAULT_COMMAND'\u001b[0m: \u001b[32m'fd --type f --hidden --exclude .git'\u001b[0m,\n",
       "    \u001b[32m'GDMSESSION'\u001b[0m: \u001b[32m'gnome'\u001b[0m,\n",
       "    \u001b[32m'GDM_LANG'\u001b[0m: \u001b[32m'en_US.UTF-8'\u001b[0m,\n",
       "    \u001b[32m'GIO_LAUNCHED_DESKTOP_FILE_PID'\u001b[0m: \u001b[32m'2374'\u001b[0m,\n",
       "    \u001b[32m'GNOME_KEYRING_CONTROL'\u001b[0m: \u001b[32m'/run/user/1000/keyring'\u001b[0m,\n",
       "    \u001b[32m'GNOME_SETUP_DISPLAY'\u001b[0m: \u001b[32m':1'\u001b[0m,\n",
       "    \u001b[32m'GOPATH'\u001b[0m: \u001b[32m'/home/umoqnier/go/bin/'\u001b[0m,\n",
       "    \u001b[32m'HOME'\u001b[0m: \u001b[32m'/home/umoqnier'\u001b[0m,\n",
       "    \u001b[32m'INVOCATION_ID'\u001b[0m: \u001b[32m'd4b57d9c98974eb99981fdaf37ad2d77'\u001b[0m,\n",
       "    \u001b[32m'JOURNAL_STREAM'\u001b[0m: \u001b[32m'9:15040'\u001b[0m,\n",
       "    \u001b[32m'KITTY_INSTALLATION_DIR'\u001b[0m: \u001b[32m'/usr/lib/kitty'\u001b[0m,\n",
       "    \u001b[32m'KITTY_PID'\u001b[0m: \u001b[32m'2374'\u001b[0m,\n",
       "    \u001b[32m'KITTY_PUBLIC_KEY'\u001b[0m: \u001b[32m'1:?ER0gqZ\u001b[0m\u001b[32m{\u001b[0m\u001b[32mQn!&L`sK1WU;MBXi8`RTdBFksq$_k@=\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[32m'KITTY_WINDOW_ID'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "    \u001b[32m'LANG'\u001b[0m: \u001b[32m'en_US.UTF-8'\u001b[0m,\n",
       "    \u001b[32m'LC_ADDRESS'\u001b[0m: \u001b[32m'en_US.UTF-8'\u001b[0m,\n",
       "    \u001b[32m'LC_IDENTIFICATION'\u001b[0m: \u001b[32m'en_US.UTF-8'\u001b[0m,\n",
       "    \u001b[32m'LC_MEASUREMENT'\u001b[0m: \u001b[32m'en_US.UTF-8'\u001b[0m,\n",
       "    \u001b[32m'LC_MONETARY'\u001b[0m: \u001b[32m'en_US.UTF-8'\u001b[0m,\n",
       "    \u001b[32m'LC_NAME'\u001b[0m: \u001b[32m'en_US.UTF-8'\u001b[0m,\n",
       "    \u001b[32m'LC_NUMERIC'\u001b[0m: \u001b[32m'en_US.UTF-8'\u001b[0m,\n",
       "    \u001b[32m'LC_PAPER'\u001b[0m: \u001b[32m'en_US.UTF-8'\u001b[0m,\n",
       "    \u001b[32m'LC_TELEPHONE'\u001b[0m: \u001b[32m'en_US.UTF-8'\u001b[0m,\n",
       "    \u001b[32m'LC_TIME'\u001b[0m: \u001b[32m'en_US.UTF-8'\u001b[0m,\n",
       "    \u001b[32m'LESS'\u001b[0m: \u001b[32m'-R'\u001b[0m,\n",
       "    \u001b[32m'LOGNAME'\u001b[0m: \u001b[32m'umoqnier'\u001b[0m,\n",
       "    \u001b[32m'LSCOLORS'\u001b[0m: \u001b[32m'Gxfxcxdxbxegedabagacad'\u001b[0m,\n",
       "    \u001b[32m'LS_COLORS'\u001b[0m: \n",
       "\u001b[32m'\u001b[0m\u001b[32mrs\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m:\u001b[0m\u001b[32mdi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;34:\u001b[0m\u001b[32mln\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;36:\u001b[0m\u001b[32mmh\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m:\u001b[0m\u001b[32mpi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m40\u001b[0m\u001b[32m;33:\u001b[0m\u001b[32mso\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:\u001b[0m\u001b[32mdo\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:\u001b[0m\u001b[32mbd\u001b[0m\u001b[32m=\u001b[0m\u001b[32m40\u001b[0m\u001b[32m;33;01:\u001b[0m\u001b[32mcd\u001b[0m\u001b[32m=\u001b[0m\u001b[32m40\u001b[0m\u001b[32m;33;01:\u001b[0m\u001b[32mor\u001b[0m\u001b[32m=\u001b[0m\u001b[32m40\u001b[0m\u001b[32m;31;01:\u001b[0m\u001b[32mmi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m:\u001b[0m\u001b[32msu\u001b[0m\u001b[32m=\u001b[0m\u001b[32m37\u001b[0m\u001b[32m;41:\u001b[0m\u001b[32msg\u001b[0m\u001b[32m=\u001b[0m\u001b[32m30\u001b[0m\u001b[32m;4\u001b[0m\n",
       "\u001b[32m3:\u001b[0m\u001b[32mca\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m:\u001b[0m\u001b[32mtw\u001b[0m\u001b[32m=\u001b[0m\u001b[32m30\u001b[0m\u001b[32m;42:\u001b[0m\u001b[32mow\u001b[0m\u001b[32m=\u001b[0m\u001b[32m34\u001b[0m\u001b[32m;42:\u001b[0m\u001b[32mst\u001b[0m\u001b[32m=\u001b[0m\u001b[32m37\u001b[0m\u001b[32m;44:\u001b[0m\u001b[32mex\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;32:*.\u001b[0m\u001b[32m7z\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mace\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32malz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mapk\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32marc\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32marj\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:\u001b[0m\n",
       "\u001b[32m*.\u001b[0m\u001b[32mbz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mbz2\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mcab\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mcpio\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mcrate\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mdeb\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mdrpm\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mdwm\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mdz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mear\u001b[0m\n",
       "\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32megg\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mesd\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mgz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mjar\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mlha\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mlrz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mlz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mlz4\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mlzh\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\n",
       "\u001b[32mlzma\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mlzo\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mpyz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mrar\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mrpm\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mrz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32msar\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mswm\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mt7z\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mtar\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;\u001b[0m\n",
       "\u001b[32m31:*.\u001b[0m\u001b[32mtaz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mtbz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mtbz2\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mtgz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mtlz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mtxz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mtz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mtzo\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mtzst\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mu\u001b[0m\n",
       "\u001b[32mdeb\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mwar\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mwhl\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mwim\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mxz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mzip\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mzoo\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mzst\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;31:*.\u001b[0m\u001b[32mavif\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35\u001b[0m\n",
       "\u001b[32m:*.\u001b[0m\u001b[32mjpg\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mjpeg\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mjxl\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mmjpg\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mmjpeg\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mgif\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mbmp\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mpbm\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mpgm\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\n",
       "\u001b[32mppm\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mtga\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mxbm\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mxpm\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mtif\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mtiff\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mpng\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32msvg\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32msvgz\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mmng\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\n",
       "\u001b[32m1\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mpcx\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mmov\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mmpg\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mmpeg\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mm2v\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mmkv\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mwebm\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mwebp\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mogm\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35\u001b[0m\n",
       "\u001b[32m:*.\u001b[0m\u001b[32mmp4\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mm4v\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mmp4v\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mvob\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mqt\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mnuv\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mwmv\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32masf\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mrm\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mrmvb\u001b[0m\u001b[32m=\u001b[0m\n",
       "\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mflc\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mavi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mfli\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mflv\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mgl\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mdl\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mxcf\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mxwd\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32myuv\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mc\u001b[0m\n",
       "\u001b[32mgm\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32memf\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mogv\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32mogx\u001b[0m\u001b[32m=\u001b[0m\u001b[32m01\u001b[0m\u001b[32m;35:*.\u001b[0m\u001b[32maac\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*.\u001b[0m\u001b[32mau\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*.\u001b[0m\u001b[32mflac\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*.\u001b[0m\u001b[32mm4a\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*.\u001b[0m\u001b[32mmid\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*.\u001b[0m\u001b[32mmidi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;\u001b[0m\n",
       "\u001b[32m36:*.\u001b[0m\u001b[32mmka\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*.\u001b[0m\u001b[32mmp3\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*.\u001b[0m\u001b[32mmpc\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*.\u001b[0m\u001b[32mogg\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*.\u001b[0m\u001b[32mra\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*.\u001b[0m\u001b[32mwav\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*.\u001b[0m\u001b[32moga\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*.\u001b[0m\u001b[32mopus\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*.\u001b[0m\u001b[32mspx\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*.\u001b[0m\u001b[32mxs\u001b[0m\n",
       "\u001b[32mpf\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;36:*~=00;90:*#=00;90:*.\u001b[0m\u001b[32mbak\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.\u001b[0m\u001b[32mcrdownload\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.dpkg-\u001b[0m\u001b[32mdist\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.dpkg-\u001b[0m\u001b[32mnew\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.dpkg-\u001b[0m\u001b[32mold\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.dpk\u001b[0m\n",
       "\u001b[32mg-\u001b[0m\u001b[32mtmp\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.\u001b[0m\u001b[32mold\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.\u001b[0m\u001b[32morig\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.\u001b[0m\u001b[32mpart\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.\u001b[0m\u001b[32mrej\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.\u001b[0m\u001b[32mrpmnew\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.\u001b[0m\u001b[32mrpmorig\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.\u001b[0m\u001b[32mrpmsave\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.\u001b[0m\u001b[32mswp\u001b[0m\u001b[32m=\u001b[0m\n",
       "\u001b[32m00\u001b[0m\u001b[32m;90:*.\u001b[0m\u001b[32mtmp\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.ucf-\u001b[0m\u001b[32mdist\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.ucf-\u001b[0m\u001b[32mnew\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:*.ucf-\u001b[0m\u001b[32mold\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m;90:'\u001b[0m,\n",
       "    \u001b[32m'MAIL'\u001b[0m: \u001b[32m'/var/spool/mail/umoqnier'\u001b[0m,\n",
       "    \u001b[32m'MANAGERPID'\u001b[0m: \u001b[32m'1423'\u001b[0m,\n",
       "    \u001b[32m'MEMORY_PRESSURE_WATCH'\u001b[0m: \n",
       "\u001b[32m'/sys/fs/cgroup/user.slice/user-1000.slice/user@1000.service/session.slice/org.gnome.SettingsDaemon.MediaKeys.servi\u001b[0m\n",
       "\u001b[32mce/memory.pressure'\u001b[0m,\n",
       "    \u001b[32m'MEMORY_PRESSURE_WRITE'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32mc29tZSAyMDAwMDAgMjAwMDAwMAA\u001b[0m\u001b[32m='\u001b[0m,\n",
       "    \u001b[32m'MOTD_SHOWN'\u001b[0m: \u001b[32m'pam'\u001b[0m,\n",
       "    \u001b[32m'OLDPWD'\u001b[0m: \u001b[32m'/home/umoqnier'\u001b[0m,\n",
       "    \u001b[32m'PAGER'\u001b[0m: \u001b[32m'cat'\u001b[0m,\n",
       "    \u001b[32m'PATH'\u001b[0m: \n",
       "\u001b[32m'/home/umoqnier/develop/lectures/st-cl-2025-2-lab/.venv/bin:/opt/miniconda3/condabin:/home/umoqnier/.emacs.d/bin:/h\u001b[0m\n",
       "\u001b[32mome/umoqnier/.cargo/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bi\u001b[0m\n",
       "\u001b[32mn/vendor_perl:/usr/bin/core_perl:/opt/rocm/bin:/home/umoqnier/.local/bin/:/home/umoqnier/go/bin/'\u001b[0m,\n",
       "    \u001b[32m'PWD'\u001b[0m: \u001b[32m'/home/umoqnier/develop/lectures/st-cl-2025-2-lab'\u001b[0m,\n",
       "    \u001b[32m'ROCM_PATH'\u001b[0m: \u001b[32m'/opt/rocm'\u001b[0m,\n",
       "    \u001b[32m'SDKMAN_DIR'\u001b[0m: \u001b[32m'/home/umoqnier/.sdkman'\u001b[0m,\n",
       "    \u001b[32m'SESSION_MANAGER'\u001b[0m: \u001b[32m'local/arrakis:@/tmp/.ICE-unix/1504,unix/arrakis:/tmp/.ICE-unix/1504'\u001b[0m,\n",
       "    \u001b[32m'SHELL'\u001b[0m: \u001b[32m'/usr/bin/zsh'\u001b[0m,\n",
       "    \u001b[32m'SHLVL'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "    \u001b[32m'SSH_KEY_PATH'\u001b[0m: \u001b[32m'~/.ssh/id_ed25519'\u001b[0m,\n",
       "    \u001b[32m'SYSTEMD_EXEC_PID'\u001b[0m: \u001b[32m'1648'\u001b[0m,\n",
       "    \u001b[32m'TERM'\u001b[0m: \u001b[32m'xterm-color'\u001b[0m,\n",
       "    \u001b[32m'TERMINFO'\u001b[0m: \u001b[32m'/usr/lib/kitty/terminfo'\u001b[0m,\n",
       "    \u001b[32m'USER'\u001b[0m: \u001b[32m'umoqnier'\u001b[0m,\n",
       "    \u001b[32m'USERNAME'\u001b[0m: \u001b[32m'umoqnier'\u001b[0m,\n",
       "    \u001b[32m'UV'\u001b[0m: \u001b[32m'/usr/bin/uv'\u001b[0m,\n",
       "    \u001b[32m'UV_RUN_RECURSION_DEPTH'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "    \u001b[32m'VIRTUAL_ENV'\u001b[0m: \u001b[32m'/home/umoqnier/develop/lectures/st-cl-2025-2-lab/.venv'\u001b[0m,\n",
       "    \u001b[32m'WAYLAND_DISPLAY'\u001b[0m: \u001b[32m'wayland-0'\u001b[0m,\n",
       "    \u001b[32m'XAUTHORITY'\u001b[0m: \u001b[32m'/run/user/1000/.mutter-Xwaylandauth.IBII62'\u001b[0m,\n",
       "    \u001b[32m'XDG_CURRENT_DESKTOP'\u001b[0m: \u001b[32m'GNOME'\u001b[0m,\n",
       "    \u001b[32m'XDG_MENU_PREFIX'\u001b[0m: \u001b[32m'gnome-'\u001b[0m,\n",
       "    \u001b[32m'XDG_RUNTIME_DIR'\u001b[0m: \u001b[32m'/run/user/1000'\u001b[0m,\n",
       "    \u001b[32m'XDG_SESSION_CLASS'\u001b[0m: \u001b[32m'user'\u001b[0m,\n",
       "    \u001b[32m'XDG_SESSION_DESKTOP'\u001b[0m: \u001b[32m'gnome'\u001b[0m,\n",
       "    \u001b[32m'XDG_SESSION_TYPE'\u001b[0m: \u001b[32m'wayland'\u001b[0m,\n",
       "    \u001b[32m'ZSH'\u001b[0m: \u001b[32m'/home/umoqnier/.oh-my-zsh'\u001b[0m,\n",
       "    \u001b[32m'_'\u001b[0m: \u001b[32m'/usr/bin/uv'\u001b[0m,\n",
       "    \u001b[32m'_CE_CONDA'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "    \u001b[32m'_CE_M'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "    \u001b[32m'JPY_SESSION_NAME'\u001b[0m: \u001b[32m'/home/umoqnier/develop/lectures/st-cl-2025-2-lab/notebooks/7_local_llm_apps.ipynb'\u001b[0m,\n",
       "    \u001b[32m'JPY_PARENT_PID'\u001b[0m: \u001b[32m'2510'\u001b[0m,\n",
       "    \u001b[32m'PYDEVD_USE_FRAME_EVAL'\u001b[0m: \u001b[32m'NO'\u001b[0m,\n",
       "    \u001b[32m'CLICOLOR'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "    \u001b[32m'FORCE_COLOR'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "    \u001b[32m'CLICOLOR_FORCE'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "    \u001b[32m'GIT_PAGER'\u001b[0m: \u001b[32m'cat'\u001b[0m,\n",
       "    \u001b[32m'MPLBACKEND'\u001b[0m: \u001b[32m'module://matplotlib_inline.backend_inline'\u001b[0m,\n",
       "    \u001b[32m'OLLAMA_HOST'\u001b[0m: \u001b[32m'127.0.0.1'\u001b[0m,\n",
       "    \u001b[32m'OLLAMA_PORT'\u001b[0m: \u001b[32m'11434'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(os.environ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b64dce1-fdb0-41ef-8b2c-54ab7cee8870",
   "metadata": {},
   "source": [
    "### Dependencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cfb2bf-c5b9-4434-8c65-bc88ad4e35f3",
   "metadata": {},
   "source": [
    "```\n",
    "\"langchain-text-splitters>=0.3.8\",\n",
    "\"langchain-community>=0.3.21\",\n",
    "\"langgraph>=0.4.3\",\n",
    "\"langchain-ollama>=0.3.2\",\n",
    "\"langchain-chroma>=0.2.2\",\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb7c4af-7c0c-413d-beaf-10d1cc0d0aae",
   "metadata": {
    "id": "eeb7c4af-7c0c-413d-beaf-10d1cc0d0aae"
   },
   "source": [
    "### Cargando un modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1504ed3a-e5ea-4175-b474-4a9bd7b8df80",
   "metadata": {
    "id": "1504ed3a-e5ea-4175-b474-4a9bd7b8df80"
   },
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "MODEL = \"qwen3:1.7b\"\n",
    "\n",
    "llm = ChatOllama(model=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279abc3a-351a-42a1-a78a-150c6f5a2fc0",
   "metadata": {
    "id": "279abc3a-351a-42a1-a78a-150c6f5a2fc0"
   },
   "source": [
    "### Cargando embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c73a6f51-a298-499c-b7ae-017da917c297",
   "metadata": {
    "id": "c73a6f51-a298-499c-b7ae-017da917c297"
   },
   "outputs": [],
   "source": [
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f69e6a0-57dc-44d5-bbe5-32f3aa25d08b",
   "metadata": {
    "id": "7f69e6a0-57dc-44d5-bbe5-32f3aa25d08b"
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "from rich import print as rprint\n",
    "from rich.rule import Rule\n",
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813a348-bb3b-4a25-8d5f-b211d4fdcfd7",
   "metadata": {
    "id": "3813a348-bb3b-4a25-8d5f-b211d4fdcfd7"
   },
   "source": [
    "### Creación de un motor de búsquedas semánticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cbbb1e-4d09-4054-9fa9-6c77bb365678",
   "metadata": {
    "id": "74cbbb1e-4d09-4054-9fa9-6c77bb365678"
   },
   "source": [
    "LangChain utiliza abtracciones para integrar la carga y recuperación de información en bases de datos vectoriales, y otras fuentes, en un flujo con LLMs. Estas abstracciones son importantes para aplicaciones que requieren extraer datos y hacer \"razonamiento\" sobre los mismos como parte de la inferencia (como es el caso del RAG). Estas abstracciones son:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074dd9f6-5474-4bfc-90ea-443bcc635abb",
   "metadata": {
    "id": "074dd9f6-5474-4bfc-90ea-443bcc635abb"
   },
   "source": [
    "#### Documentos y cargadores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76366f04-e177-4d04-bf76-025e51b12cf1",
   "metadata": {
    "id": "76366f04-e177-4d04-bf76-025e51b12cf1"
   },
   "source": [
    "Los documentos representan unidades de texto con metadata que puede carpturar información sobre donde viene el documento, su relación con otros documentos y más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ca6d3c-27d0-4fb4-baf9-5afb28e2dbe6",
   "metadata": {
    "id": "c5ca6d3c-27d0-4fb4-baf9-5afb28e2dbe6"
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Simply put, bikepacking is a mix of all-terrain cycling and backpacking.\",\n",
    "        metadata={\"source\": \"bikepacking-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Bikepacking involves carrying the essential gear—and not much more—on an off-road-capable bike for an overnight or multi-day ride\",\n",
    "        metadata={\"source\": \"bikepacking-doc\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cf2987-b342-4908-b141-2a3c742eb250",
   "metadata": {
    "id": "b4cf2987-b342-4908-b141-2a3c742eb250"
   },
   "source": [
    "Sin embargo, es más común utilizar [*doc loaders*](https://python.langchain.com/docs/concepts/document_loaders/) para obtener [integraciones](https://python.langchain.com/docs/integrations/document_loaders/) varias con fuentes de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16aa86bc-9ed1-4d96-9d44-19fe76f659e5",
   "metadata": {
    "id": "16aa86bc-9ed1-4d96-9d44-19fe76f659e5",
    "outputId": "6ab377fd-18e3-437b-e0b3-d9957a344d03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Cargador basado en extracción de datos de la web\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\n",
    "        \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "        \"https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/\",\n",
    "        \"https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/\"\n",
    "        ),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\", \"post\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2acac135-ce8b-4de8-9ad5-40d556a84461",
   "metadata": {
    "id": "2acac135-ce8b-4de8-9ad5-40d556a84461",
    "outputId": "98312960-9a34-47aa-d0bc-8a18153f6cec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total documents <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total documents \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────────────────────────────────────────────────────── </span>Doc <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────────────────────────────────────────────────────── \u001b[0mDoc \u001b[1;36m1\u001b[0m\u001b[92m ──────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "      LLM Powered Autonomous Agents\n",
       "    \n",
       "Date: June <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>  |  Estimated Reading Time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span> min  |  Author: Lilian Weng\n",
       "\n",
       "\n",
       "Building agents with LLM <span style=\"font-weight: bold\">(</span>large language model<span style=\"font-weight: bold\">)</span> as its core controller is a cool concept. Several proof-of-concepts\n",
       "demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as i\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "      LLM Powered Autonomous Agents\n",
       "    \n",
       "Date: June \u001b[1;36m23\u001b[0m, \u001b[1;36m2023\u001b[0m  |  Estimated Reading Time: \u001b[1;36m31\u001b[0m min  |  Author: Lilian Weng\n",
       "\n",
       "\n",
       "Building agents with LLM \u001b[1m(\u001b[0mlarge language model\u001b[1m)\u001b[0m as its core controller is a cool concept. Several proof-of-concepts\n",
       "demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as i\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────────────────────────────────────────────────────── </span>Doc <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────────────────────────────────────────────────────── \u001b[0mDoc \u001b[1;36m2\u001b[0m\u001b[92m ──────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "Conditional Random Fields for Sequence Prediction\n",
       "\n",
       "\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> November <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2017</span>\n",
       "      \n",
       "\n",
       "\n",
       "\n",
       "This is the third and <span style=\"font-weight: bold\">(</span>maybe<span style=\"font-weight: bold\">)</span> the last part of a series of posts about sequential supervised learning applied to \n",
       "NLP. In this post I will talk about Conditional Random Fields <span style=\"font-weight: bold\">(</span>CRF<span style=\"font-weight: bold\">)</span>, explain what was the main mot\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "Conditional Random Fields for Sequence Prediction\n",
       "\n",
       "\n",
       "        \u001b[1;36m13\u001b[0m November \u001b[1;36m2017\u001b[0m\n",
       "      \n",
       "\n",
       "\n",
       "\n",
       "This is the third and \u001b[1m(\u001b[0mmaybe\u001b[1m)\u001b[0m the last part of a series of posts about sequential supervised learning applied to \n",
       "NLP. In this post I will talk about Conditional Random Fields \u001b[1m(\u001b[0mCRF\u001b[1m)\u001b[0m, explain what was the main mot\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────────────────────────────────────────────────────── </span>Doc <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────────────────────────────────────────────────────── \u001b[0mDoc \u001b[1;36m3\u001b[0m\u001b[92m ──────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "Maximum Entropy Markov Models and Logistic Regression\n",
       "\n",
       "\n",
       "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> November <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2017</span>\n",
       "      \n",
       "\n",
       "\n",
       "\n",
       "This is the second part of a series of posts about sequential supervised learning applied to NLP. It can be seen as\n",
       "a follow-up to the previous post, where I tried to explain the relationship between HMM and\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "Maximum Entropy Markov Models and Logistic Regression\n",
       "\n",
       "\n",
       "        \u001b[1;36m12\u001b[0m November \u001b[1;36m2017\u001b[0m\n",
       "      \n",
       "\n",
       "\n",
       "\n",
       "This is the second part of a series of posts about sequential supervised learning applied to NLP. It can be seen as\n",
       "a follow-up to the previous post, where I tried to explain the relationship between HMM and\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(f\"Total documents {len(docs)}\")\n",
    "for i, doc in enumerate(docs, start=1):\n",
    "    rprint(Rule(f\"Doc {i}\"))\n",
    "    rprint(doc.page_content[:300])\n",
    "    rprint(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f695279a-e015-418f-abd5-8e7fd68c72b7",
   "metadata": {
    "id": "f695279a-e015-418f-abd5-8e7fd68c72b7"
   },
   "source": [
    "#### Separadores de texto (*text splitters*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8ee2b6-62b7-4ff5-b81d-3b242f45ff10",
   "metadata": {
    "id": "8c8ee2b6-62b7-4ff5-b81d-3b242f45ff10"
   },
   "source": [
    "Típicamente en las aplicaciones de recuperación de información o *question answering* una página de un documento puede ser demasiado grande para una representación. Lo que buscamos es obtener partes del documento para contestar preguntas basadas en la *query* de entrada y separar los documentos va a prevenir que porciones reelevantes del texto no sean opacadas por texto alrededor.\n",
    "\n",
    "Definiremos la cantidad de caracteres que tendrá cada *chunk* y los caracteres de *overlap*, que ayuda a mitigar que perdamos información reelevante al separar el documento. `RecursiveCharacterTextSplitter` separará recursivamente utilizando el salto de línea hasta obtener *chunks* del tamaño deseado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28d0fe97-a70e-4a7d-86bb-50481c79d5d8",
   "metadata": {
    "id": "28d0fe97-a70e-4a7d-86bb-50481c79d5d8"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, add_start_index=True)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14ee40bb-6a7a-4737-ad33-a7445abe5c55",
   "metadata": {
    "id": "14ee40bb-6a7a-4737-ad33-a7445abe5c55",
    "outputId": "52d9d710-cb36-46ea-870d-c0741318b2ac",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Splits <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Splits \u001b[1;36m102\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────────── </span>split #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────────────── \u001b[0msplit #\u001b[1;36m1\u001b[0m\u001b[92m ─────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10702</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Graph representation of HMM, MEMM and CRF.  (taken from Lafferty et al. 2001)\\n\\n\\nHidden Markov </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Models:\\n\\n\\n\\\\[P(\\\\bar{y}, \\\\bar{x}) = \\\\prod\\\\limits_{i=1}^{|\\\\bar{y}|} P(y_{i} \\\\mid y_{i-1}) \\\\cdot P(x_{i} </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\mid y_{i})\\\\]\\n\\n\\n\\nMaximum Entropy Markov Models:\\n\\n\\n\\\\[P(\\\\bar{y}, \\\\bar{x}) = </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\prod\\\\limits_{i=1}^{|\\\\bar{y}|} P(y_{i} \\\\mid y_{i-1}, x_{i}) = \\\\prod\\\\limits_{i=1}^{|\\\\bar{y}|} </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\frac{1}{Z(x,y_{i-1})}\\\\  \\\\exp\\\\bigg( \\\\sum_{j=1}^{N} w_{j} \\\\cdot f_{j}(x,y_{i-1}) \\\\bigg)\\\\]\\n\\n\\n\\nConditional</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Random Fields:\\n\\n\\n\\\\[P(\\\\bar{y} \\\\mid \\\\bar{x}, \\\\bar{w}) = \\\\frac{\\\\exp(\\\\bar{w} \\\\cdot </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">F(\\\\bar{x},\\\\bar{y}))}{\\\\sum\\\\limits_{\\\\bar{y}' \\\\in Y} \\\\exp(\\\\bar{w} \\\\cdot F(\\\\bar{x},\\\\bar{y}'))}\\\\]\\n\\n\\nCRF </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Important Observations\\n\\n\\nMEMMs are normalized locally over each observation and hence suffer from the Label Bias</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problem, where the transitions going out from a state compete only against each other, as opposed to all the other </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transitions in the model.\"</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'source'\u001b[0m: \u001b[32m'https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/'\u001b[0m,\n",
       "        \u001b[32m'start_index'\u001b[0m: \u001b[1;36m10702\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpage_content\u001b[0m=\u001b[32m\"Graph\u001b[0m\u001b[32m representation of HMM, MEMM and CRF.  \u001b[0m\u001b[32m(\u001b[0m\u001b[32mtaken from Lafferty et al. 2001\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n\\nHidden Markov \u001b[0m\n",
       "\u001b[32mModels:\\n\\n\\n\\\\\u001b[0m\u001b[32m[\u001b[0m\u001b[32mP\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32mx\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = \\\\prod\\\\limits_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m^\u001b[0m\u001b[32m{\u001b[0m\u001b[32m|\\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m|\u001b[0m\u001b[32m}\u001b[0m\u001b[32m P\u001b[0m\u001b[32m(\u001b[0m\u001b[32my_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\mid y_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi-1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\\\cdot P\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32m\\\\mid y_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\\n\\nMaximum Entropy Markov Models:\\n\\n\\n\\\\\u001b[0m\u001b[32m[\u001b[0m\u001b[32mP\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32mx\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = \u001b[0m\n",
       "\u001b[32m\\\\prod\\\\limits_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m^\u001b[0m\u001b[32m{\u001b[0m\u001b[32m|\\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m|\u001b[0m\u001b[32m}\u001b[0m\u001b[32m P\u001b[0m\u001b[32m(\u001b[0m\u001b[32my_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\mid y_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi-1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, x_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = \\\\prod\\\\limits_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m^\u001b[0m\u001b[32m{\u001b[0m\u001b[32m|\\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m|\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32m\\\\frac\u001b[0m\u001b[32m{\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32mZ\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx,y_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi-1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\  \\\\exp\\\\bigg\u001b[0m\u001b[32m(\u001b[0m\u001b[32m \\\\sum_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mj\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m^\u001b[0m\u001b[32m{\u001b[0m\u001b[32mN\u001b[0m\u001b[32m}\u001b[0m\u001b[32m w_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mj\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\cdot f_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mj\u001b[0m\u001b[32m}\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx,y_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi-1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\\\bigg\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\\n\\nConditional\u001b[0m\n",
       "\u001b[32mRandom Fields:\\n\\n\\n\\\\\u001b[0m\u001b[32m[\u001b[0m\u001b[32mP\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\mid \\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32mx\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32mw\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = \\\\frac\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\exp\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32mw\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\cdot \u001b[0m\n",
       "\u001b[32mF\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32mx\u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\sum\\\\limits_\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m' \\\\in Y\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\exp\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32mw\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\cdot F\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32mx\u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\\\bar\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\\nCRF \u001b[0m\n",
       "\u001b[32mImportant Observations\\n\\n\\nMEMMs are normalized locally over each observation and hence suffer from the Label Bias\u001b[0m\n",
       "\u001b[32mproblem, where the transitions going out from a state compete only against each other, as opposed to all the other \u001b[0m\n",
       "\u001b[32mtransitions in the model.\"\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────────── </span>split #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────────────── \u001b[0msplit #\u001b[1;36m2\u001b[0m\u001b[92m ─────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11602</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'CRFs avoid the label bias problem a weakness exhibited by Maximum Entropy Markov Models (MEMM). </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The big difference between MEMM and CRF is that MEMM is locally renormalized and suffers from the label bias </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problem, while CRFs are globally renormalised.\\n\\n\\nThe inference algorithm in CRF is again based on the Viterbi </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">algorithm.\\n\\n\\nOutput transition and observation probabilities are not modelled separately.\\n\\n\\nOutput transition</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dependent on the state and the observation as one conditional probability.\\n\\n\\nSoftware </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Packages\\n\\n\\npython-crfsuite: is a python binding for CRFsuite which is a fast implementation of Conditional </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Random Fields written in C++.\\n\\n\\nCRF++: Yet Another CRF toolkit: is a popular implementation in C++ but as far as</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">I know there are no python bindings.\\n\\n\\nMALLET: includes implementations of widely used sequence algorithms </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">including hidden Markov models (HMMs) and linear chain conditional random fields (CRFs), it’s written in Java.'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'source'\u001b[0m: \u001b[32m'https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/'\u001b[0m,\n",
       "        \u001b[32m'start_index'\u001b[0m: \u001b[1;36m11602\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpage_content\u001b[0m=\u001b[32m'CRFs avoid the label bias problem a weakness exhibited by Maximum Entropy Markov Models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMEMM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. \u001b[0m\n",
       "\u001b[32mThe big difference between MEMM and CRF is that MEMM is locally renormalized and suffers from the label bias \u001b[0m\n",
       "\u001b[32mproblem, while CRFs are globally renormalised.\\n\\n\\nThe inference algorithm in CRF is again based on the Viterbi \u001b[0m\n",
       "\u001b[32malgorithm.\\n\\n\\nOutput transition and observation probabilities are not modelled separately.\\n\\n\\nOutput transition\u001b[0m\n",
       "\u001b[32mdependent on the state and the observation as one conditional probability.\\n\\n\\nSoftware \u001b[0m\n",
       "\u001b[32mPackages\\n\\n\\npython-crfsuite: is a python binding for CRFsuite which is a fast implementation of Conditional \u001b[0m\n",
       "\u001b[32mRandom Fields written in C++.\\n\\n\\nCRF++: Yet Another CRF toolkit: is a popular implementation in C++ but as far as\u001b[0m\n",
       "\u001b[32mI know there are no python bindings.\\n\\n\\nMALLET: includes implementations of widely used sequence algorithms \u001b[0m\n",
       "\u001b[32mincluding hidden Markov models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHMMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and linear chain conditional random fields \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCRFs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, it’s written in Java.'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────────── </span>split #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────────────── \u001b[0msplit #\u001b[1;36m3\u001b[0m\u001b[92m ─────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12372</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'MALLET: includes implementations of widely used sequence algorithms including hidden Markov </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models (HMMs) and linear chain conditional random fields (CRFs), it’s written in Java.\\n\\n\\nFlexCRFs supports both </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">first-order and second-order Markov CRFs, it’s written in C/C++ using the STL library.\\n\\n\\npython-wapiti is a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">python wrapper for wapiti, a sequence labelling tool with support for maxent models, maximum entropy Markov models </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and linear-chain CRF.\\n\\n\\nReferences\\n\\n\\n“Conditional Random Fields: Probabilistic Models for Segmenting and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Labeling Sequence Data”\\n\\n\\n“Log-linear models and Conditional Random Fields”. Notes for a tutorial at CIKM’08 by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Charles Elkan. October 20, 2008”\\n\\n\\nVideo: tutorial at CIKM’08 by Charles Elkan\\n\\n\\n“Conditional Random Fields: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">An Introduction”. Hanna M. Wallach, February 24, 2004. University of Pennsylvania CIS Technical Report </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">MS-CIS-04-21\\n\\n\\n“Statistical NLP for the Web Log Linear Models, MEMM, Conditional Random Fields” class by Sameer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Maskey'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'source'\u001b[0m: \u001b[32m'https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/'\u001b[0m,\n",
       "        \u001b[32m'start_index'\u001b[0m: \u001b[1;36m12372\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpage_content\u001b[0m=\u001b[32m'MALLET: includes implementations of widely used sequence algorithms including hidden Markov \u001b[0m\n",
       "\u001b[32mmodels \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHMMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and linear chain conditional random fields \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCRFs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, it’s written in Java.\\n\\n\\nFlexCRFs supports both \u001b[0m\n",
       "\u001b[32mfirst-order and second-order Markov CRFs, it’s written in C/C++ using the STL library.\\n\\n\\npython-wapiti is a \u001b[0m\n",
       "\u001b[32mpython wrapper for wapiti, a sequence labelling tool with support for maxent models, maximum entropy Markov models \u001b[0m\n",
       "\u001b[32mand linear-chain CRF.\\n\\n\\nReferences\\n\\n\\n“Conditional Random Fields: Probabilistic Models for Segmenting and \u001b[0m\n",
       "\u001b[32mLabeling Sequence Data”\\n\\n\\n“Log-linear models and Conditional Random Fields”. Notes for a tutorial at CIKM’08 by \u001b[0m\n",
       "\u001b[32mCharles Elkan. October 20, 2008”\\n\\n\\nVideo: tutorial at CIKM’08 by Charles Elkan\\n\\n\\n“Conditional Random Fields: \u001b[0m\n",
       "\u001b[32mAn Introduction”. Hanna M. Wallach, February 24, 2004. University of Pennsylvania CIS Technical Report \u001b[0m\n",
       "\u001b[32mMS-CIS-04-21\\n\\n\\n“Statistical NLP for the Web Log Linear Models, MEMM, Conditional Random Fields” class by Sameer \u001b[0m\n",
       "\u001b[32mMaskey'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────────── </span>split #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────────────── \u001b[0msplit #\u001b[1;36m4\u001b[0m\u001b[92m ─────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13243</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'“Statistical NLP for the Web Log Linear Models, MEMM, Conditional Random Fields” class by Sameer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Maskey\\n\\n\\n“Log-Linear Models, MEMMs, and CRFs”. Michael Collins\\n\\n\\n“An Introduction to Conditional Random </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Fields” Sutton, Charles; McCallum, Andrew (2010)\\n\\n\\nAcknowledgments\\nThe writing of this post is also the outcome</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of many discussions and white board sessions I had together with Tobias Sterbak and Sebastian Mika.\\nRelated </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">posts\\n\\n\\nHidden Markov Model and Naive Bayes relationship\\n\\n\\nMaximum Entropy Markov Models and Logistic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Regression\\n\\n\\nStanfordNER - training a new model and deploying a web service'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'source'\u001b[0m: \u001b[32m'https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/'\u001b[0m,\n",
       "        \u001b[32m'start_index'\u001b[0m: \u001b[1;36m13243\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpage_content\u001b[0m=\u001b[32m'“Statistical NLP for the Web Log Linear Models, MEMM, Conditional Random Fields” class by Sameer \u001b[0m\n",
       "\u001b[32mMaskey\\n\\n\\n“Log-Linear Models, MEMMs, and CRFs”. Michael Collins\\n\\n\\n“An Introduction to Conditional Random \u001b[0m\n",
       "\u001b[32mFields” Sutton, Charles; McCallum, Andrew \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2010\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n\\nAcknowledgments\\nThe writing of this post is also the outcome\u001b[0m\n",
       "\u001b[32mof many discussions and white board sessions I had together with Tobias Sterbak and Sebastian Mika.\\nRelated \u001b[0m\n",
       "\u001b[32mposts\\n\\n\\nHidden Markov Model and Naive Bayes relationship\\n\\n\\nMaximum Entropy Markov Models and Logistic \u001b[0m\n",
       "\u001b[32mRegression\\n\\n\\nStanfordNER - training a new model and deploying a web service'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────────── </span>split #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────────────── \u001b[0msplit #\u001b[1;36m5\u001b[0m\u001b[92m ─────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Maximum Entropy Markov Models and Logistic Regression\\n\\n\\n        12 November 2017\\n      </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\n\\n\\n\\nThis is the second part of a series of posts about sequential supervised learning applied to NLP. It can be</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">seen as a follow-up to the previous post, where I tried to explain the relationship between HMM and Naive Bayes. In</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">this post I will try to explain how to build a sequence classifier based on a Logistic Regression classifier, i.e.,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">using a discriminative approach.\\nYou can find the first and third posts here:\\n\\n\\nHidden Markov Model and Naive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Bayes relationship\\n\\n\\nConditional Random Fields for Sequence Prediction'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'source'\u001b[0m: \u001b[32m'https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/'\u001b[0m,\n",
       "        \u001b[32m'start_index'\u001b[0m: \u001b[1;36m2\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpage_content\u001b[0m=\u001b[32m'Maximum Entropy Markov Models and Logistic Regression\\n\\n\\n        12 November 2017\\n      \u001b[0m\n",
       "\u001b[32m\\n\\n\\n\\nThis is the second part of a series of posts about sequential supervised learning applied to NLP. It can be\u001b[0m\n",
       "\u001b[32mseen as a follow-up to the previous post, where I tried to explain the relationship between HMM and Naive Bayes. In\u001b[0m\n",
       "\u001b[32mthis post I will try to explain how to build a sequence classifier based on a Logistic Regression classifier, i.e.,\u001b[0m\n",
       "\u001b[32musing a discriminative approach.\\nYou can find the first and third posts here:\\n\\n\\nHidden Markov Model and Naive \u001b[0m\n",
       "\u001b[32mBayes relationship\\n\\n\\nConditional Random Fields for Sequence Prediction'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────────── </span>split #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────────────── \u001b[0msplit #\u001b[1;36m6\u001b[0m\u001b[92m ─────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">514</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hidden Markov Model and Naive Bayes relationship\\n\\n\\nConditional Random Fields for Sequence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Prediction\\n\\n\\n\\nDiscriminative vs. Generative Models\\nIn a previous post I wrote about the Naive Bayes Model and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">how it is connected with the Hidden Markov Model. Both are generative models, in contrast, Logistic Regression is a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discriminative model, this post will start, by explaining this difference.\\nIn general, a machine learning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">classifier chooses which output label \\\\(y\\\\) to assign to a given input \\\\(x\\\\), by selecting from all the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">possible \\\\(y_{i}\\\\) the one that maximizes \\\\(P(y\\\\mid x)\\\\).\\nThe Naive Bayes classifier estimates \\\\(p(y \\\\mid </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">x)\\\\) indirectly, by applying Baye’s theorem, and then computing the class conditional distribution/likelihood </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\(P(x \\\\mid y)\\\\) and the prior \\\\(P(y)\\\\).\\n\\n\\\\[\\\\hat{y} = \\\\underset{y}{\\\\arg\\\\max}\\\\ P(y \\\\mid x) = </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\underset{y}{\\\\arg\\\\max} \\\\ P(x \\\\mid y) \\\\cdot P(y)\\\\]'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'source'\u001b[0m: \u001b[32m'https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/'\u001b[0m,\n",
       "        \u001b[32m'start_index'\u001b[0m: \u001b[1;36m514\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpage_content\u001b[0m=\u001b[32m'Hidden Markov Model and Naive Bayes relationship\\n\\n\\nConditional Random Fields for Sequence \u001b[0m\n",
       "\u001b[32mPrediction\\n\\n\\n\\nDiscriminative vs. Generative Models\\nIn a previous post I wrote about the Naive Bayes Model and \u001b[0m\n",
       "\u001b[32mhow it is connected with the Hidden Markov Model. Both are generative models, in contrast, Logistic Regression is a\u001b[0m\n",
       "\u001b[32mdiscriminative model, this post will start, by explaining this difference.\\nIn general, a machine learning \u001b[0m\n",
       "\u001b[32mclassifier chooses which output label \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32my\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to assign to a given input \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, by selecting from all the \u001b[0m\n",
       "\u001b[32mpossible \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32my_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m the one that maximizes \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mP\u001b[0m\u001b[32m(\u001b[0m\u001b[32my\\\\mid x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nThe Naive Bayes classifier estimates \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mp\u001b[0m\u001b[32m(\u001b[0m\u001b[32my \\\\mid \u001b[0m\n",
       "\u001b[32mx\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m indirectly, by applying Baye’s theorem, and then computing the class conditional distribution/likelihood \u001b[0m\n",
       "\u001b[32m\\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mP\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx \\\\mid y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and the prior \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mP\u001b[0m\u001b[32m(\u001b[0m\u001b[32my\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\n\\\\\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\\\hat\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m = \\\\underset\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\arg\\\\max\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\ P\u001b[0m\u001b[32m(\u001b[0m\u001b[32my \\\\mid x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = \u001b[0m\n",
       "\u001b[32m\\\\underset\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\arg\\\\max\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\ P\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx \\\\mid y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\\\cdot P\u001b[0m\u001b[32m(\u001b[0m\u001b[32my\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────────── </span>split #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────────────── \u001b[0msplit #\u001b[1;36m7\u001b[0m\u001b[92m ─────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1297</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\\\[\\\\hat{y} = \\\\underset{y}{\\\\arg\\\\max}\\\\ P(y \\\\mid x) = \\\\underset{y}{\\\\arg\\\\max} \\\\ P(x \\\\mid </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">y) \\\\cdot P(y)\\\\]\\n\\nThis indirection makes Naive Bayes a generative model, a model that is trained to generate the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">data \\\\(x\\\\) from the class \\\\(y\\\\). The likelihood \\\\(p(x \\\\mid y)\\\\), means that we are given a class \\\\(y\\\\) and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">will try to predict which features to see in the input \\\\(x\\\\).\\nIn contrast, a discriminative model directly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">computes \\\\(p(y \\\\mid x)\\\\) by discriminating among the different possible values of the class \\\\(y\\\\) instead of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">computing a likelihood. The Logistic Regression classifier is one such type of classifier.\\n\\n\\\\[\\\\hat{y} = </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\underset{y}{\\\\arg\\\\max} \\\\ P(y \\\\mid x)\\\\]'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'source'\u001b[0m: \u001b[32m'https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/'\u001b[0m,\n",
       "        \u001b[32m'start_index'\u001b[0m: \u001b[1;36m1297\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpage_content\u001b[0m=\u001b[32m'\\\\\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\\\hat\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m = \\\\underset\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\arg\\\\max\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\ P\u001b[0m\u001b[32m(\u001b[0m\u001b[32my \\\\mid x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = \\\\underset\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\arg\\\\max\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\ P\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx \\\\mid \u001b[0m\n",
       "\u001b[32my\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\\\cdot P\u001b[0m\u001b[32m(\u001b[0m\u001b[32my\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nThis indirection makes Naive Bayes a generative model, a model that is trained to generate the\u001b[0m\n",
       "\u001b[32mdata \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m from the class \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32my\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The likelihood \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mp\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx \\\\mid y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, means that we are given a class \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32my\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and\u001b[0m\n",
       "\u001b[32mwill try to predict which features to see in the input \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nIn contrast, a discriminative model directly \u001b[0m\n",
       "\u001b[32mcomputes \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mp\u001b[0m\u001b[32m(\u001b[0m\u001b[32my \\\\mid x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by discriminating among the different possible values of the class \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32my\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m instead of \u001b[0m\n",
       "\u001b[32mcomputing a likelihood. The Logistic Regression classifier is one such type of classifier.\\n\\n\\\\\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\\\hat\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m = \u001b[0m\n",
       "\u001b[32m\\\\underset\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\arg\\\\max\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\ P\u001b[0m\u001b[32m(\u001b[0m\u001b[32my \\\\mid x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────────── </span>split #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────────────── \u001b[0msplit #\u001b[1;36m8\u001b[0m\u001b[92m ─────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1908</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\\\[\\\\hat{y} = \\\\underset{y}{\\\\arg\\\\max} \\\\ P(y \\\\mid x)\\\\]\\n\\n\\nLogistic Regression\\nLogistic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">regression is a supervised machine learning algorithm used for classification, which has its roots in linear </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">regression.\\nWhen used to solve NLP tasks, it estimates \\\\(p( y\\\\mid x)\\\\) by extracting features from the input </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">text and combining them linearly i.e., multiplying each feature by a weight and then adding them up, and then </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">applying the exponential function to this linear combination:\\n\\n\\\\[P(y|x) = \\\\frac{1}{Z} \\\\ \\\\exp \\\\sum_{i=1}^{N} </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">w_{i} \\\\cdot f_{i}\\\\]'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'source'\u001b[0m: \u001b[32m'https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/'\u001b[0m,\n",
       "        \u001b[32m'start_index'\u001b[0m: \u001b[1;36m1908\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpage_content\u001b[0m=\u001b[32m'\\\\\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\\\hat\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m = \\\\underset\u001b[0m\u001b[32m{\u001b[0m\u001b[32my\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\arg\\\\max\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\ P\u001b[0m\u001b[32m(\u001b[0m\u001b[32my \\\\mid x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\n\\nLogistic Regression\\nLogistic \u001b[0m\n",
       "\u001b[32mregression is a supervised machine learning algorithm used for classification, which has its roots in linear \u001b[0m\n",
       "\u001b[32mregression.\\nWhen used to solve NLP tasks, it estimates \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mp\u001b[0m\u001b[32m(\u001b[0m\u001b[32m y\\\\mid x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by extracting features from the input \u001b[0m\n",
       "\u001b[32mtext and combining them linearly i.e., multiplying each feature by a weight and then adding them up, and then \u001b[0m\n",
       "\u001b[32mapplying the exponential function to this linear combination:\\n\\n\\\\\u001b[0m\u001b[32m[\u001b[0m\u001b[32mP\u001b[0m\u001b[32m(\u001b[0m\u001b[32my|x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = \\\\frac\u001b[0m\u001b[32m{\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32mZ\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\ \\\\exp \\\\sum_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m^\u001b[0m\u001b[32m{\u001b[0m\u001b[32mN\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mw_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\cdot f_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────────── </span>split #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────────────── \u001b[0msplit #\u001b[1;36m9\u001b[0m\u001b[92m ─────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2381</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"\\\\[P(y|x) = \\\\frac{1}{Z} \\\\ \\\\exp \\\\sum_{i=1}^{N} w_{i} \\\\cdot f_{i}\\\\]\\n\\nwhere \\\\(f_{i}\\\\) is a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">feature and \\\\(w_{i}\\\\) the weight associated to the feature. The \\\\(\\\\exp\\\\) (i.e., exponential function) </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">surrounding the weight-feature dot product ensures that all values are positive and the denominator \\\\(Z\\\\) is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">needed to force all values into a valid probability where the sum is 1.\\nThe extracted features are binary-valued </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">features, i.e., only take the values 0 and 1, and are commonly called indicator functions. Each of these features </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is calculated by a function that is associated with the input \\\\(x\\\\) and the class \\\\(y\\\\). Each indicator </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">function is represented as \\\\(f_{i}(y,x)\\\\), the feature \\\\(i\\\\) for class \\\\(y\\\\), given observation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\(x\\\\):\\n\\n\\\\[P(y|x) = \\\\frac{\\\\exp \\\\bigg( \\\\sum\\\\limits_{i=1}^{N} w_{i} \\\\cdot f_{i}(x,y) \\\\bigg)} </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{\\\\sum\\\\limits_{y' \\\\in Y} \\\\exp \\\\bigg( \\\\sum\\\\limits_{i=1}^{N} w_{i} \\\\cdot f_{i}(x,y') \\\\bigg)}\\\\]\"</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'source'\u001b[0m: \u001b[32m'https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/'\u001b[0m,\n",
       "        \u001b[32m'start_index'\u001b[0m: \u001b[1;36m2381\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpage_content\u001b[0m=\u001b[32m\"\\\\\u001b[0m\u001b[32m[\u001b[0m\u001b[32mP\u001b[0m\u001b[32m(\u001b[0m\u001b[32my|x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = \\\\frac\u001b[0m\u001b[32m{\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32mZ\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\ \\\\exp \\\\sum_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m^\u001b[0m\u001b[32m{\u001b[0m\u001b[32mN\u001b[0m\u001b[32m}\u001b[0m\u001b[32m w_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\cdot f_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nwhere \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mf_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is a\u001b[0m\n",
       "\u001b[32mfeature and \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mw_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m the weight associated to the feature. The \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\\\exp\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m(\u001b[0m\u001b[32mi.e., exponential function\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32msurrounding the weight-feature dot product ensures that all values are positive and the denominator \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mZ\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is \u001b[0m\n",
       "\u001b[32mneeded to force all values into a valid probability where the sum is 1.\\nThe extracted features are binary-valued \u001b[0m\n",
       "\u001b[32mfeatures, i.e., only take the values 0 and 1, and are commonly called indicator functions. Each of these features \u001b[0m\n",
       "\u001b[32mis calculated by a function that is associated with the input \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and the class \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32my\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Each indicator \u001b[0m\n",
       "\u001b[32mfunction is represented as \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mf_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m(\u001b[0m\u001b[32my,x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, the feature \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mi\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for class \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32my\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, given observation \u001b[0m\n",
       "\u001b[32m\\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n\\n\\\\\u001b[0m\u001b[32m[\u001b[0m\u001b[32mP\u001b[0m\u001b[32m(\u001b[0m\u001b[32my|x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = \\\\frac\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\exp \\\\bigg\u001b[0m\u001b[32m(\u001b[0m\u001b[32m \\\\sum\\\\limits_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m^\u001b[0m\u001b[32m{\u001b[0m\u001b[32mN\u001b[0m\u001b[32m}\u001b[0m\u001b[32m w_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\cdot f_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx,y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\\\bigg\u001b[0m\u001b[32m)\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m\\\\sum\\\\limits_\u001b[0m\u001b[32m{\u001b[0m\u001b[32my' \\\\in Y\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\exp \\\\bigg\u001b[0m\u001b[32m(\u001b[0m\u001b[32m \\\\sum\\\\limits_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m^\u001b[0m\u001b[32m{\u001b[0m\u001b[32mN\u001b[0m\u001b[32m}\u001b[0m\u001b[32m w_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\cdot f_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx,y'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\\\bigg\u001b[0m\u001b[32m)\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────────── </span>split #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────────────── \u001b[0msplit #\u001b[1;36m10\u001b[0m\u001b[92m ────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3114</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"\\\\[P(y|x) = \\\\frac{\\\\exp \\\\bigg( \\\\sum\\\\limits_{i=1}^{N} w_{i} \\\\cdot f_{i}(x,y) \\\\bigg)} </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">{\\\\sum\\\\limits_{y' \\\\in Y} \\\\exp \\\\bigg( \\\\sum\\\\limits_{i=1}^{N} w_{i} \\\\cdot f_{i}(x,y') </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\bigg)}\\\\]\\n\\nTrainning\\nBy training the logistic regression classifier we want to find the ideal weights for each</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">feature, that is, the weights that will make training examples fit best the classes to which they belong.\\nLogistic</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">regression is trained with conditional maximum likelihood estimation. This means that we will choose the parameters</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\(w\\\\) that maximize the probability of the \\\\(y\\\\) labels in the training data given the observations </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\\\(x\\\\):\\n\\n\\\\[\\\\hat{w} = \\\\underset{w}{\\\\arg\\\\max} \\\\sum_{j} \\\\log \\\\ P(y^{j} \\\\mid y^{j})\\\\]\\n\\nThe objective </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">function to maximize is:\\n\\n\\\\[L(w) = \\\\sum_{j} \\\\log\\\\ P(y^{j} \\\\mid y^{j})\\\\]\\n\\nwhich by replacing with expanded</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">form presented before and by applying the division log rules, takes the following form:\"</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'source'\u001b[0m: \u001b[32m'https://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/'\u001b[0m,\n",
       "        \u001b[32m'start_index'\u001b[0m: \u001b[1;36m3114\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpage_content\u001b[0m=\u001b[32m\"\\\\\u001b[0m\u001b[32m[\u001b[0m\u001b[32mP\u001b[0m\u001b[32m(\u001b[0m\u001b[32my|x\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = \\\\frac\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\exp \\\\bigg\u001b[0m\u001b[32m(\u001b[0m\u001b[32m \\\\sum\\\\limits_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m^\u001b[0m\u001b[32m{\u001b[0m\u001b[32mN\u001b[0m\u001b[32m}\u001b[0m\u001b[32m w_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\cdot f_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx,y\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\\\bigg\u001b[0m\u001b[32m)\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32m{\u001b[0m\u001b[32m\\\\sum\\\\limits_\u001b[0m\u001b[32m{\u001b[0m\u001b[32my' \\\\in Y\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\exp \\\\bigg\u001b[0m\u001b[32m(\u001b[0m\u001b[32m \\\\sum\\\\limits_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m^\u001b[0m\u001b[32m{\u001b[0m\u001b[32mN\u001b[0m\u001b[32m}\u001b[0m\u001b[32m w_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\cdot f_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mi\u001b[0m\u001b[32m}\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx,y'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32m\\\\bigg\u001b[0m\u001b[32m)\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nTrainning\\nBy training the logistic regression classifier we want to find the ideal weights for each\u001b[0m\n",
       "\u001b[32mfeature, that is, the weights that will make training examples fit best the classes to which they belong.\\nLogistic\u001b[0m\n",
       "\u001b[32mregression is trained with conditional maximum likelihood estimation. This means that we will choose the parameters\u001b[0m\n",
       "\u001b[32m\\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mw\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m that maximize the probability of the \\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32my\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m labels in the training data given the observations \u001b[0m\n",
       "\u001b[32m\\\\\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx\\\\\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n\\n\\\\\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\\\\hat\u001b[0m\u001b[32m{\u001b[0m\u001b[32mw\u001b[0m\u001b[32m}\u001b[0m\u001b[32m = \\\\underset\u001b[0m\u001b[32m{\u001b[0m\u001b[32mw\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\\\arg\\\\max\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\sum_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mj\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\log \\\\ P\u001b[0m\u001b[32m(\u001b[0m\u001b[32my^\u001b[0m\u001b[32m{\u001b[0m\u001b[32mj\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\mid y^\u001b[0m\u001b[32m{\u001b[0m\u001b[32mj\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nThe objective \u001b[0m\n",
       "\u001b[32mfunction to maximize is:\\n\\n\\\\\u001b[0m\u001b[32m[\u001b[0m\u001b[32mL\u001b[0m\u001b[32m(\u001b[0m\u001b[32mw\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = \\\\sum_\u001b[0m\u001b[32m{\u001b[0m\u001b[32mj\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\log\\\\ P\u001b[0m\u001b[32m(\u001b[0m\u001b[32my^\u001b[0m\u001b[32m{\u001b[0m\u001b[32mj\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\mid y^\u001b[0m\u001b[32m{\u001b[0m\u001b[32mj\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nwhich by replacing with expanded\u001b[0m\n",
       "\u001b[32mform presented before and by applying the division log rules, takes the following form:\"\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(f\"Splits {len(all_splits)}\")\n",
    "for i, split in enumerate(all_splits[80:90], start=1):\n",
    "    rprint(Rule(f\"split #{i}\"))\n",
    "    rprint(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc0f9e0-74fa-40cb-89f0-7dc3f108497f",
   "metadata": {
    "id": "fbc0f9e0-74fa-40cb-89f0-7dc3f108497f"
   },
   "source": [
    "#### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c5e57-40cc-448e-ada5-b69d3f24cdf8",
   "metadata": {
    "id": "708c5e57-40cc-448e-ada5-b69d3f24cdf8"
   },
   "source": [
    "La forma habitual de hacer búsquedas en textos no estructurados es por medio de vectores. Recordemos que las representaciones vectoriales son útiles para hacer búsquedas basandonos en una medida de similitud (ej: *cosine similarity*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02c506cd-4ab0-4247-96de-d6d177fa2f3b",
   "metadata": {
    "id": "02c506cd-4ab0-4247-96de-d6d177fa2f3b",
    "outputId": "75642de5-66fc-4286-d174-b42f724c5a20"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Generated vectors of length <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Generated vectors of length \u001b[1;36m768\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">V1\n",
       "<span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0125058275</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.03718732</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.15584643</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.07565208</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.045629725</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.05164143</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0013306361</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.015095599</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0064935167</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0157191</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "V1\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;36m-0.0125058275\u001b[0m,\n",
       "    \u001b[1;36m0.03718732\u001b[0m,\n",
       "    \u001b[1;36m-0.15584643\u001b[0m,\n",
       "    \u001b[1;36m-0.07565208\u001b[0m,\n",
       "    \u001b[1;36m0.045629725\u001b[0m,\n",
       "    \u001b[1;36m-0.05164143\u001b[0m,\n",
       "    \u001b[1;36m-0.0013306361\u001b[0m,\n",
       "    \u001b[1;36m-0.015095599\u001b[0m,\n",
       "    \u001b[1;36m0.0064935167\u001b[0m,\n",
       "    \u001b[1;36m-0.0157191\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">V2\n",
       "<span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.001428467</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.013767078</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1690818</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.08120458</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.025699997</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.007035082</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.026442833</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0105799455</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.010471876</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.03033129</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "V2\n",
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;36m0.001428467\u001b[0m,\n",
       "    \u001b[1;36m0.013767078\u001b[0m,\n",
       "    \u001b[1;36m-0.1690818\u001b[0m,\n",
       "    \u001b[1;36m-0.08120458\u001b[0m,\n",
       "    \u001b[1;36m0.025699997\u001b[0m,\n",
       "    \u001b[1;36m-0.007035082\u001b[0m,\n",
       "    \u001b[1;36m0.026442833\u001b[0m,\n",
       "    \u001b[1;36m-0.0105799455\u001b[0m,\n",
       "    \u001b[1;36m0.010471876\u001b[0m,\n",
       "    \u001b[1;36m-0.03033129\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vector_1 = embeddings.embed_query(all_splits[0].page_content)\n",
    "vector_2 = embeddings.embed_query(all_splits[1].page_content)\n",
    "\n",
    "assert len(vector_1) == len(vector_2)\n",
    "rprint(f\"Generated vectors of length {len(vector_1)}\")\n",
    "rprint(\"V1\", vector_1[:10])\n",
    "rprint(\"V2\", vector_2[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c120933-4698-4108-84ed-52e3f8c59b81",
   "metadata": {
    "id": "2c120933-4698-4108-84ed-52e3f8c59b81"
   },
   "source": [
    "#### Creando la base de datos de embeggings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089d3a3-f2d2-415d-acab-677c8ae0ff99",
   "metadata": {
    "id": "2089d3a3-f2d2-415d-acab-677c8ae0ff99"
   },
   "source": [
    "Los objetos `VectorStore` de langchain exponen métodos para agregar texto o `Documents` al almacenamiento y realizar *queries* con base en multiples medidas de similitud. Se inicializan con modelos de embeddings (en nuestro caso [Nomic Embed Text](https://ollama.com/library/nomic-embed-text)) que determinará como es que el texto será transformado a una representación vectorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "438203bf-09c2-4d38-85de-27d719b1c326",
   "metadata": {
    "id": "438203bf-09c2-4d38-85de-27d719b1c326"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    # Nombramos nuestra colección\n",
    "    collection_name=\"my_collection\",\n",
    "    # embeddings lo definimos más arriba\n",
    "    embedding_function=embeddings,\n",
    "    # Where to save data locally\n",
    "    persist_directory=\"./my_chroma_langchain_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da886106-b999-4db8-b4aa-69724370e759",
   "metadata": {
    "id": "da886106-b999-4db8-b4aa-69724370e759"
   },
   "source": [
    "Una vez creada la base de datos vectorial podemos indexar los documentos y dada una *query* de entrada obtener documentos reelevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "414e713a-af9b-4972-9300-47e3758feb41",
   "metadata": {
    "id": "414e713a-af9b-4972-9300-47e3758feb41",
    "outputId": "90c21445-9e68-423c-b06f-9c416b6348db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 209 ms, sys: 45.8 ms, total: 255 ms\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01e214a2-6357-487f-99b3-addb4b357dd9",
   "metadata": {
    "id": "01e214a2-6357-487f-99b3-addb4b357dd9",
    "outputId": "91e97b0e-f9f5-4234-c05b-e86b163db1f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'fdb4f6e8-537f-4657-b282-fd6473414782'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'f5c58151-fd29-469f-a8cd-b3f5bfa86bb5'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'2b182e3f-5f8e-476b-b506-fd89740f71c7'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'34be87fb-8ab2-4d1e-957f-e06c8d31372b'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'da84d2b1-1800-4d49-a92d-1507412aa910'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'7ce1046f-8ff2-4eba-84c9-332abba12556'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'d9845478-5cc5-4790-86e1-40c438ef9339'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'8550deb3-2944-4f27-9ae3-840559b471a7'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'aa7dc25d-ecb4-4628-9106-89294ae12f0f'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'07b7ce2a-f5a9-4f67-bbfc-2fb723754337'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'fdb4f6e8-537f-4657-b282-fd6473414782'\u001b[0m,\n",
       "    \u001b[32m'f5c58151-fd29-469f-a8cd-b3f5bfa86bb5'\u001b[0m,\n",
       "    \u001b[32m'2b182e3f-5f8e-476b-b506-fd89740f71c7'\u001b[0m,\n",
       "    \u001b[32m'34be87fb-8ab2-4d1e-957f-e06c8d31372b'\u001b[0m,\n",
       "    \u001b[32m'da84d2b1-1800-4d49-a92d-1507412aa910'\u001b[0m,\n",
       "    \u001b[32m'7ce1046f-8ff2-4eba-84c9-332abba12556'\u001b[0m,\n",
       "    \u001b[32m'd9845478-5cc5-4790-86e1-40c438ef9339'\u001b[0m,\n",
       "    \u001b[32m'8550deb3-2944-4f27-9ae3-840559b471a7'\u001b[0m,\n",
       "    \u001b[32m'aa7dc25d-ecb4-4628-9106-89294ae12f0f'\u001b[0m,\n",
       "    \u001b[32m'07b7ce2a-f5a9-4f67-bbfc-2fb723754337'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c45a2627-616c-4645-9a7f-56e3d8948753",
   "metadata": {
    "id": "c45a2627-616c-4645-9a7f-56e3d8948753",
    "outputId": "5118261b-5f2c-4094-b22d-209e4cb5139f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ebaaaf87-eaa8-418c-b503-d22584837d63'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">633</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Introduction\\nCRFs were proposed roughly only a year after the Maximum Entropy Markov Model, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">basically by the same authors. Reading through the original paper that introduced Conditional Random Fields, one </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">finds at the beginning of this sentence:\\n“The critical difference between CRF and MEMM is that the latter uses </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">per-state exponential models for the conditional probabilities of next states given the current state, whereas CRF </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">uses a single exponential model to determine the joint probability of the entire sequence of labels, given the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">observation sequence. Therefore, in CRF, the weights of different features in different states compete against each</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">other.”\\nThis means that in the MEMMs there is a model to compute the probability of the next state, given the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">current state and the observation. On the other hand, CRF computes all state transitions globally, in a single </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model.'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'ebaaaf87-eaa8-418c-b503-d22584837d63'\u001b[0m,\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'source'\u001b[0m: \u001b[32m'https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/'\u001b[0m,\n",
       "        \u001b[32m'start_index'\u001b[0m: \u001b[1;36m633\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mpage_content\u001b[0m=\u001b[32m'Introduction\\nCRFs were proposed roughly only a year after the Maximum Entropy Markov Model, \u001b[0m\n",
       "\u001b[32mbasically by the same authors. Reading through the original paper that introduced Conditional Random Fields, one \u001b[0m\n",
       "\u001b[32mfinds at the beginning of this sentence:\\n“The critical difference between CRF and MEMM is that the latter uses \u001b[0m\n",
       "\u001b[32mper-state exponential models for the conditional probabilities of next states given the current state, whereas CRF \u001b[0m\n",
       "\u001b[32muses a single exponential model to determine the joint probability of the entire sequence of labels, given the \u001b[0m\n",
       "\u001b[32mobservation sequence. Therefore, in CRF, the weights of different features in different states compete against each\u001b[0m\n",
       "\u001b[32mother.”\\nThis means that in the MEMMs there is a model to compute the probability of the next state, given the \u001b[0m\n",
       "\u001b[32mcurrent state and the observation. On the other hand, CRF computes all state transitions globally, in a single \u001b[0m\n",
       "\u001b[32mmodel.'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = await vector_store.asimilarity_search(\"CRFs\")\n",
    "\n",
    "rprint(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1951736-3934-45c8-9274-0e8aed475a1b",
   "metadata": {
    "id": "f1951736-3934-45c8-9274-0e8aed475a1b",
    "outputId": "c05cfdbd-3e66-4d98-f78b-4a3e2b2fd459",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Results</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mResults\u001b[0m=\u001b[1;36m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────────── </span>Result #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────────────── \u001b[0mResult #\u001b[1;36m0\u001b[0m\u001b[92m ────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">MEMM Important Observations\n",
       "\n",
       "\n",
       "The main advantage over the HMM is the use of feature vectors, making the transition probability sensitive to any \n",
       "word in the input sequence.\n",
       "\n",
       "\n",
       "There is an exponential model associated with each <span style=\"font-weight: bold\">(</span>state, word<span style=\"font-weight: bold\">)</span> pair to calculate the conditional probability of \n",
       "the next state.\n",
       "\n",
       "\n",
       "The exponential model allows the MEMMs to support long-distance interactions over the whole observation sequence \n",
       "together with the previous state, instead of two different probability distributions.\n",
       "\n",
       "\n",
       "MEMM can be also augmented to include features involving additional past states, instead of just the previous one.\n",
       "\n",
       "\n",
       "It also uses the Viterbi algorithm <span style=\"font-weight: bold\">(</span>slightly adapted<span style=\"font-weight: bold\">)</span> to perform decoding.\n",
       "\n",
       "\n",
       "It suffers from the label bias problem, which I will detail in the next post about Conditional Random Fields.\n",
       "\n",
       "\n",
       "Software Packages\n",
       "\n",
       "\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/willxie/hmm-vs-memm:</span> a project for a class by William Xie which implements and compares HMM vs. \n",
       "MEMM on the task of part-of-speech tagging.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "MEMM Important Observations\n",
       "\n",
       "\n",
       "The main advantage over the HMM is the use of feature vectors, making the transition probability sensitive to any \n",
       "word in the input sequence.\n",
       "\n",
       "\n",
       "There is an exponential model associated with each \u001b[1m(\u001b[0mstate, word\u001b[1m)\u001b[0m pair to calculate the conditional probability of \n",
       "the next state.\n",
       "\n",
       "\n",
       "The exponential model allows the MEMMs to support long-distance interactions over the whole observation sequence \n",
       "together with the previous state, instead of two different probability distributions.\n",
       "\n",
       "\n",
       "MEMM can be also augmented to include features involving additional past states, instead of just the previous one.\n",
       "\n",
       "\n",
       "It also uses the Viterbi algorithm \u001b[1m(\u001b[0mslightly adapted\u001b[1m)\u001b[0m to perform decoding.\n",
       "\n",
       "\n",
       "It suffers from the label bias problem, which I will detail in the next post about Conditional Random Fields.\n",
       "\n",
       "\n",
       "Software Packages\n",
       "\n",
       "\n",
       "\u001b[4;94mhttps://github.com/willxie/hmm-vs-memm:\u001b[0m a project for a class by William Xie which implements and compares HMM vs. \n",
       "MEMM on the task of part-of-speech tagging.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────────── </span>Result #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────────────── \u001b[0mResult #\u001b[1;36m1\u001b[0m\u001b[92m ────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">MEMM Important Observations\n",
       "\n",
       "\n",
       "The main advantage over the HMM is the use of feature vectors, making the transition probability sensitive to any \n",
       "word in the input sequence.\n",
       "\n",
       "\n",
       "There is an exponential model associated with each <span style=\"font-weight: bold\">(</span>state, word<span style=\"font-weight: bold\">)</span> pair to calculate the conditional probability of \n",
       "the next state.\n",
       "\n",
       "\n",
       "The exponential model allows the MEMMs to support long-distance interactions over the whole observation sequence \n",
       "together with the previous state, instead of two different probability distributions.\n",
       "\n",
       "\n",
       "MEMM can be also augmented to include features involving additional past states, instead of just the previous one.\n",
       "\n",
       "\n",
       "It also uses the Viterbi algorithm <span style=\"font-weight: bold\">(</span>slightly adapted<span style=\"font-weight: bold\">)</span> to perform decoding.\n",
       "\n",
       "\n",
       "It suffers from the label bias problem, which I will detail in the next post about Conditional Random Fields.\n",
       "\n",
       "\n",
       "Software Packages\n",
       "\n",
       "\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/willxie/hmm-vs-memm:</span> a project for a class by William Xie which implements and compares HMM vs. \n",
       "MEMM on the task of part-of-speech tagging.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "MEMM Important Observations\n",
       "\n",
       "\n",
       "The main advantage over the HMM is the use of feature vectors, making the transition probability sensitive to any \n",
       "word in the input sequence.\n",
       "\n",
       "\n",
       "There is an exponential model associated with each \u001b[1m(\u001b[0mstate, word\u001b[1m)\u001b[0m pair to calculate the conditional probability of \n",
       "the next state.\n",
       "\n",
       "\n",
       "The exponential model allows the MEMMs to support long-distance interactions over the whole observation sequence \n",
       "together with the previous state, instead of two different probability distributions.\n",
       "\n",
       "\n",
       "MEMM can be also augmented to include features involving additional past states, instead of just the previous one.\n",
       "\n",
       "\n",
       "It also uses the Viterbi algorithm \u001b[1m(\u001b[0mslightly adapted\u001b[1m)\u001b[0m to perform decoding.\n",
       "\n",
       "\n",
       "It suffers from the label bias problem, which I will detail in the next post about Conditional Random Fields.\n",
       "\n",
       "\n",
       "Software Packages\n",
       "\n",
       "\n",
       "\u001b[4;94mhttps://github.com/willxie/hmm-vs-memm:\u001b[0m a project for a class by William Xie which implements and compares HMM vs. \n",
       "MEMM on the task of part-of-speech tagging.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────────── </span>Result #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────────────── \u001b[0mResult #\u001b[1;36m2\u001b[0m\u001b[92m ────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">MEMM Important Observations\n",
       "\n",
       "\n",
       "The main advantage over the HMM is the use of feature vectors, making the transition probability sensitive to any \n",
       "word in the input sequence.\n",
       "\n",
       "\n",
       "There is an exponential model associated with each <span style=\"font-weight: bold\">(</span>state, word<span style=\"font-weight: bold\">)</span> pair to calculate the conditional probability of \n",
       "the next state.\n",
       "\n",
       "\n",
       "The exponential model allows the MEMMs to support long-distance interactions over the whole observation sequence \n",
       "together with the previous state, instead of two different probability distributions.\n",
       "\n",
       "\n",
       "MEMM can be also augmented to include features involving additional past states, instead of just the previous one.\n",
       "\n",
       "\n",
       "It also uses the Viterbi algorithm <span style=\"font-weight: bold\">(</span>slightly adapted<span style=\"font-weight: bold\">)</span> to perform decoding.\n",
       "\n",
       "\n",
       "It suffers from the label bias problem, which I will detail in the next post about Conditional Random Fields.\n",
       "\n",
       "\n",
       "Software Packages\n",
       "\n",
       "\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/willxie/hmm-vs-memm:</span> a project for a class by William Xie which implements and compares HMM vs. \n",
       "MEMM on the task of part-of-speech tagging.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "MEMM Important Observations\n",
       "\n",
       "\n",
       "The main advantage over the HMM is the use of feature vectors, making the transition probability sensitive to any \n",
       "word in the input sequence.\n",
       "\n",
       "\n",
       "There is an exponential model associated with each \u001b[1m(\u001b[0mstate, word\u001b[1m)\u001b[0m pair to calculate the conditional probability of \n",
       "the next state.\n",
       "\n",
       "\n",
       "The exponential model allows the MEMMs to support long-distance interactions over the whole observation sequence \n",
       "together with the previous state, instead of two different probability distributions.\n",
       "\n",
       "\n",
       "MEMM can be also augmented to include features involving additional past states, instead of just the previous one.\n",
       "\n",
       "\n",
       "It also uses the Viterbi algorithm \u001b[1m(\u001b[0mslightly adapted\u001b[1m)\u001b[0m to perform decoding.\n",
       "\n",
       "\n",
       "It suffers from the label bias problem, which I will detail in the next post about Conditional Random Fields.\n",
       "\n",
       "\n",
       "Software Packages\n",
       "\n",
       "\n",
       "\u001b[4;94mhttps://github.com/willxie/hmm-vs-memm:\u001b[0m a project for a class by William Xie which implements and compares HMM vs. \n",
       "MEMM on the task of part-of-speech tagging.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────────── </span>Result #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────────────────── \u001b[0mResult #\u001b[1;36m3\u001b[0m\u001b[92m ────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The contrast in state transition estimation between an HMM and a MEMM.  <span style=\"font-weight: bold\">(</span>taken from <span style=\"color: #008000; text-decoration-color: #008000\">\"Speech and Language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Processing\"</span> Daniel Jurafsky &amp; James H. Martin<span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "In contrast to HMMs, in which the current observation only depends on the current state, the current observation in\n",
       "a MEMM may also depend on the previous state. The HMM model includes distinct probability estimates for each \n",
       "transition and observation, while the MEMM gives one probability estimate per hidden state, which is the \n",
       "probability of the next tag given the previous tag and the observation.\n",
       "In the MEMM instead of the transition and observation matrices, there is only one transition probability matrix. \n",
       "This matrix encapsulates all combinations of previous states \\<span style=\"font-weight: bold\">(</span>S_<span style=\"font-weight: bold\">{</span>t−<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>\\<span style=\"font-weight: bold\">)</span> and current observation \\<span style=\"font-weight: bold\">(</span>O_<span style=\"font-weight: bold\">{</span>t<span style=\"font-weight: bold\">}</span>\\<span style=\"font-weight: bold\">)</span> pairs in\n",
       "the training data to the current state \\<span style=\"font-weight: bold\">(</span>S_<span style=\"font-weight: bold\">{</span>t<span style=\"font-weight: bold\">}</span>\\<span style=\"font-weight: bold\">)</span>.\n",
       "Let \\<span style=\"font-weight: bold\">(</span>N\\<span style=\"font-weight: bold\">)</span> be the number of unique states and \\<span style=\"font-weight: bold\">(</span>M\\<span style=\"font-weight: bold\">)</span> the number of unique words, the matrix has the shape:\n",
       "\n",
       "<span style=\"font-weight: bold\">[(</span>N \\cdot M<span style=\"font-weight: bold\">)</span> \\cdot N\\<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The contrast in state transition estimation between an HMM and a MEMM.  \u001b[1m(\u001b[0mtaken from \u001b[32m\"Speech and Language \u001b[0m\n",
       "\u001b[32mProcessing\"\u001b[0m Daniel Jurafsky & James H. Martin\u001b[1m)\u001b[0m\n",
       "\n",
       "In contrast to HMMs, in which the current observation only depends on the current state, the current observation in\n",
       "a MEMM may also depend on the previous state. The HMM model includes distinct probability estimates for each \n",
       "transition and observation, while the MEMM gives one probability estimate per hidden state, which is the \n",
       "probability of the next tag given the previous tag and the observation.\n",
       "In the MEMM instead of the transition and observation matrices, there is only one transition probability matrix. \n",
       "This matrix encapsulates all combinations of previous states \\\u001b[1m(\u001b[0mS_\u001b[1m{\u001b[0mt−\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m\\\u001b[1m)\u001b[0m and current observation \\\u001b[1m(\u001b[0mO_\u001b[1m{\u001b[0mt\u001b[1m}\u001b[0m\\\u001b[1m)\u001b[0m pairs in\n",
       "the training data to the current state \\\u001b[1m(\u001b[0mS_\u001b[1m{\u001b[0mt\u001b[1m}\u001b[0m\\\u001b[1m)\u001b[0m.\n",
       "Let \\\u001b[1m(\u001b[0mN\\\u001b[1m)\u001b[0m be the number of unique states and \\\u001b[1m(\u001b[0mM\\\u001b[1m)\u001b[0m the number of unique words, the matrix has the shape:\n",
       "\n",
       "\u001b[1m[\u001b[0m\u001b[1m(\u001b[0mN \\cdot M\u001b[1m)\u001b[0m \\cdot N\\\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding = embeddings.embed_query(\"What are the difference beetween HMM and MEMM?\")\n",
    "\n",
    "results = vector_store.similarity_search_by_vector(embedding)\n",
    "rprint(f\"Results={len(results)}\")\n",
    "for i, result in enumerate(results):\n",
    "    rprint(Rule(f\"Result #{i}\"))\n",
    "    rprint(result.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b93ff-b6d9-4429-874b-90c98d5d25f3",
   "metadata": {
    "id": "838b93ff-b6d9-4429-874b-90c98d5d25f3"
   },
   "source": [
    "#### Generación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db3cbf-32d6-449e-8dcd-a5221753d91e",
   "metadata": {
    "id": "a1db3cbf-32d6-449e-8dcd-a5221753d91e"
   },
   "source": [
    "La lógica de la app consistirá en los siguientes pasos:\n",
    "\n",
    "1. Tomar la pregunta del usuario\n",
    "2. Obtener documentos reelevantes a la pregunta en cuestión\n",
    "    - La obtención de los documentos estará superditada por el *retriever* que definamos\n",
    "3. Pasar los documentos obtenidos y la pregunta inicial al modelo\n",
    "4. Generar una respuesta\n",
    "    - Para la generación usaremos el modelo obtenido de `ollama`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f5b2be-cc49-4404-ba6f-097cf10d3de6",
   "metadata": {
    "id": "37f5b2be-cc49-4404-ba6f-097cf10d3de6"
   },
   "source": [
    "#### Creando el prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05b34a82-2fb7-4945-80e0-2cd081d3cabe",
   "metadata": {
    "id": "05b34a82-2fb7-4945-80e0-2cd081d3cabe"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the\n",
    "question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the\n",
    "answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d436d91-b48e-4bf9-8ff0-3424f1218d60",
   "metadata": {
    "id": "8d436d91-b48e-4bf9-8ff0-3424f1218d60"
   },
   "source": [
    "Alternativamente se pueden obtener prompts desde el [hub](https://smith.langchain.com/hub/rlm) de Langchain:\n",
    "\n",
    "```python\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2d80eeb-13f5-49f1-adac-ac5bcaa4dedf",
   "metadata": {
    "id": "b2d80eeb-13f5-49f1-adac-ac5bcaa4dedf",
    "outputId": "0a06d173-9a94-4e12-8f82-8884ce99ff1a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the\n",
       "question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the\n",
       "answer concise.\n",
       "Question: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">&lt;The</span><span style=\"color: #008000; text-decoration-color: #008000\"> question in question&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Context: </span><span style=\"color: #000080; text-decoration-color: #000080\">&lt;My retrieved and absolutely relevant documents</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&gt;</span>\n",
       "Answer:\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the\n",
       "question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the\n",
       "answer concise.\n",
       "Question: \u001b[1;32m<\u001b[0m\u001b[1;32mThe\u001b[0m\u001b[32m question in question>\u001b[0m\n",
       "\u001b[39mContext: \u001b[0m\u001b[34m<My retrieved and absolutely relevant documents\u001b[0m\u001b[1;34m>\u001b[0m\n",
       "Answer:\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"[blue]<My retrieved and absolutely relevant documents>[/]\", \"question\": \"[green]<The question in question>[/]\"}\n",
    ").to_messages()\n",
    "\n",
    "rprint(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66feabc1-01ef-4ff0-88cb-65970b807276",
   "metadata": {
    "id": "66feabc1-01ef-4ff0-88cb-65970b807276",
    "outputId": "ec53f1c8-0bc2-4ed3-8d1f-ae04f151c3da"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "panzaGPT [qwen3:1.7b]>>  What is a CRF?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">think</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Okay, let's see. The user is asking what a CRF is. From the context provided, I need to summarize the key points </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">about CRFs.</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">First, the context mentions that CRFs were proposed after MEMM, and the main difference is that CRFs use a single </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">exponential model for the entire sequence of labels, whereas MEMM uses per-state models. This means CRFs consider </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">all transitions together, which avoids the label bias problem. The Viterbi algorithm is used for inference, and the</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">weights in CRFs compete against each other globally. Also, the context notes that CRFs are globally renormalized, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">which is different from MEMM's local approach.</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">So, putting it together: CRFs are a type of probabilistic model used for sequence labeling, using a single </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">exponential model to capture joint probabilities of all label transitions. They avoid label bias by considering all</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">transitions together, using the Viterbi algorithm for inference. The key difference from MEMM is global modeling </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">instead of per-state, leading to better performance in certain tasks.</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">think</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "\n",
       "CRFs are probabilistic models for sequence labeling, using a single exponential model to capture joint \n",
       "probabilities of all label transitions. They avoid the label bias problem by considering all state transitions \n",
       "globally, using the Viterbi algorithm for inference. The key difference from MEMM is that CRFs model output \n",
       "transitions in a unified framework, competing feature weights across states.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mthink\u001b[0m\u001b[39m>\u001b[0m\n",
       "\u001b[39mOkay, let's see. The user is asking what a CRF is. From the context provided, I need to summarize the key points \u001b[0m\n",
       "\u001b[39mabout CRFs.\u001b[0m\n",
       "\n",
       "\u001b[39mFirst, the context mentions that CRFs were proposed after MEMM, and the main difference is that CRFs use a single \u001b[0m\n",
       "\u001b[39mexponential model for the entire sequence of labels, whereas MEMM uses per-state models. This means CRFs consider \u001b[0m\n",
       "\u001b[39mall transitions together, which avoids the label bias problem. The Viterbi algorithm is used for inference, and the\u001b[0m\n",
       "\u001b[39mweights in CRFs compete against each other globally. Also, the context notes that CRFs are globally renormalized, \u001b[0m\n",
       "\u001b[39mwhich is different from MEMM's local approach.\u001b[0m\n",
       "\n",
       "\u001b[39mSo, putting it together: CRFs are a type of probabilistic model used for sequence labeling, using a single \u001b[0m\n",
       "\u001b[39mexponential model to capture joint probabilities of all label transitions. They avoid label bias by considering all\u001b[0m\n",
       "\u001b[39mtransitions together, using the Viterbi algorithm for inference. The key difference from MEMM is global modeling \u001b[0m\n",
       "\u001b[39minstead of per-state, leading to better performance in certain tasks.\u001b[0m\n",
       "\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mthink\u001b[0m\u001b[1m>\u001b[0m\n",
       "\n",
       "CRFs are probabilistic models for sequence labeling, using a single exponential model to capture joint \n",
       "probabilities of all label transitions. They avoid the label bias problem by considering all state transitions \n",
       "globally, using the Viterbi algorithm for inference. The key difference from MEMM is that CRFs model output \n",
       "transitions in a unified framework, competing feature weights across states.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Pregunta del user\n",
    "question = input(f\"panzaGPT [{MODEL}]>> \")\n",
    "\n",
    "# 2. Obtener documentos reelevantes\n",
    "retrieved_docs = vector_store.similarity_search(question)\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "# 3. Pasarlos a junto con la pregunta al modelo\n",
    "prompt_result = prompt.invoke({\"question\": question, \"context\": docs_content})\n",
    "\n",
    "# 4. Generar una respuesta\n",
    "answer = llm.invoke(prompt_result)\n",
    "\n",
    "rprint(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caa59dda-caba-401c-9ed7-6406b4a30c59",
   "metadata": {
    "id": "caa59dda-caba-401c-9ed7-6406b4a30c59",
    "outputId": "8a2384b5-53a5-43a0-df7b-b5ec8c01bd21"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"&lt;think&gt;\\nOkay, let's see. The user is asking what a CRF is. From the context provided, I need to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarize the key points about CRFs.\\n\\nFirst, the context mentions that CRFs were proposed after MEMM, and the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">main difference is that CRFs use a single exponential model for the entire sequence of labels, whereas MEMM uses </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">per-state models. This means CRFs consider all transitions together, which avoids the label bias problem. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Viterbi algorithm is used for inference, and the weights in CRFs compete against each other globally. Also, the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context notes that CRFs are globally renormalized, which is different from MEMM's local approach.\\n\\nSo, putting it</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">together: CRFs are a type of probabilistic model used for sequence labeling, using a single exponential model to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capture joint probabilities of all label transitions. They avoid label bias by considering all transitions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">together, using the Viterbi algorithm for inference. The key difference from MEMM is global modeling instead of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">per-state, leading to better performance in certain tasks.\\n&lt;/think&gt;\\n\\nCRFs are probabilistic models for sequence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">labeling, using a single exponential model to capture joint probabilities of all label transitions. They avoid the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">label bias problem by considering all state transitions globally, using the Viterbi algorithm for inference. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">key difference from MEMM is that CRFs model output transitions in a unified framework, competing feature weights </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">across states.\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'qwen3:1.7b'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-05-12T18:44:14.870185919Z'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'done'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'done_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'total_duration'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28021203471</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'load_duration'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1809971171</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_eval_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">759</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_eval_duration'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11627836584</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'eval_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">286</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'eval_duration'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14582049728</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'qwen3:1.7b'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run--e5eb38eb-5d82-4c2d-925c-6e900f5e51dc-0'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage_metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">759</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">286</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1045</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m\"\u001b[0m\u001b[32m<\u001b[0m\u001b[32mthink\u001b[0m\u001b[32m>\\nOkay, let's see. The user is asking what a CRF is. From the context provided, I need to \u001b[0m\n",
       "\u001b[32msummarize the key points about CRFs.\\n\\nFirst, the context mentions that CRFs were proposed after MEMM, and the \u001b[0m\n",
       "\u001b[32mmain difference is that CRFs use a single exponential model for the entire sequence of labels, whereas MEMM uses \u001b[0m\n",
       "\u001b[32mper-state models. This means CRFs consider all transitions together, which avoids the label bias problem. The \u001b[0m\n",
       "\u001b[32mViterbi algorithm is used for inference, and the weights in CRFs compete against each other globally. Also, the \u001b[0m\n",
       "\u001b[32mcontext notes that CRFs are globally renormalized, which is different from MEMM's local approach.\\n\\nSo, putting it\u001b[0m\n",
       "\u001b[32mtogether: CRFs are a type of probabilistic model used for sequence labeling, using a single exponential model to \u001b[0m\n",
       "\u001b[32mcapture joint probabilities of all label transitions. They avoid label bias by considering all transitions \u001b[0m\n",
       "\u001b[32mtogether, using the Viterbi algorithm for inference. The key difference from MEMM is global modeling instead of \u001b[0m\n",
       "\u001b[32mper-state, leading to better performance in certain tasks.\\n</think\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\n\\nCRFs are probabilistic models for sequence \u001b[0m\n",
       "\u001b[32mlabeling, using a single exponential model to capture joint probabilities of all label transitions. They avoid the \u001b[0m\n",
       "\u001b[32mlabel bias problem by considering all state transitions globally, using the Viterbi algorithm for inference. The \u001b[0m\n",
       "\u001b[32mkey difference from MEMM is that CRFs model output transitions in a unified framework, competing feature weights \u001b[0m\n",
       "\u001b[32macross states.\"\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'model'\u001b[0m: \u001b[32m'qwen3:1.7b'\u001b[0m,\n",
       "        \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-05-12T18:44:14.870185919Z'\u001b[0m,\n",
       "        \u001b[32m'done'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[32m'done_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "        \u001b[32m'total_duration'\u001b[0m: \u001b[1;36m28021203471\u001b[0m,\n",
       "        \u001b[32m'load_duration'\u001b[0m: \u001b[1;36m1809971171\u001b[0m,\n",
       "        \u001b[32m'prompt_eval_count'\u001b[0m: \u001b[1;36m759\u001b[0m,\n",
       "        \u001b[32m'prompt_eval_duration'\u001b[0m: \u001b[1;36m11627836584\u001b[0m,\n",
       "        \u001b[32m'eval_count'\u001b[0m: \u001b[1;36m286\u001b[0m,\n",
       "        \u001b[32m'eval_duration'\u001b[0m: \u001b[1;36m14582049728\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'qwen3:1.7b'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run--e5eb38eb-5d82-4c2d-925c-6e900f5e51dc-0'\u001b[0m,\n",
       "    \u001b[33musage_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'input_tokens'\u001b[0m: \u001b[1;36m759\u001b[0m, \u001b[32m'output_tokens'\u001b[0m: \u001b[1;36m286\u001b[0m, \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m1045\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d660a7-2d80-4c9c-b767-f55e4b8466b0",
   "metadata": {
    "id": "28d660a7-2d80-4c9c-b767-f55e4b8466b0"
   },
   "source": [
    "### Obtenedores (*Retrievers*) y LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a0fc2d-e475-47ed-a121-0cf18577d7f7",
   "metadata": {
    "id": "01a0fc2d-e475-47ed-a121-0cf18577d7f7"
   },
   "source": [
    "#### Retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa252b0-5606-401e-986d-769707d3d3c7",
   "metadata": {
    "id": "faa252b0-5606-401e-986d-769707d3d3c7"
   },
   "source": [
    "Los objetos que heredan de los [*Runnables*](https://python.langchain.com/api_reference/core/index.html#langchain-core-runnables) implementan un conjunto de métodos sincronos y asíncronos. Uno de estos objetos son los [*Retrievers*](https://python.langchain.com/api_reference/core/index.html#langchain-core-retrievers). Podemos obtener *retrievers* de los *vector_stores* o construir los propios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4295aa3c-c45f-489e-a003-f70e179a020b",
   "metadata": {
    "id": "4295aa3c-c45f-489e-a003-f70e179a020b"
   },
   "source": [
    "#### LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b3e494-2296-4f01-a199-7ed5f04911b5",
   "metadata": {
    "id": "76b3e494-2296-4f01-a199-7ed5f04911b5"
   },
   "source": [
    "LangGraph es un orquestador que nos permitirá administrar los pasos de obtención y generación. En general utilizar `langgraph` permite escalar nuestras apps y construir agentes de forma \"sencilla\". Algunas características interesantes son las siguientes:\n",
    "\n",
    "- Definir la lógica de la app una vez habilitar soporte para multiples modelos, llamadas async y batches\n",
    "- Perminte agregar fácilmente características como [persistencia](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpoints), [aprobación human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)\n",
    "\n",
    "Para usar `langgraph` precisamos tres ingredientes:\n",
    "\n",
    "1. Una forma de modelar los estados\n",
    "2. Nodos por los que pasará\n",
    "3. Un flujo de control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97036c03-d6a9-4f9c-8fce-e7116ac6c734",
   "metadata": {
    "id": "97036c03-d6a9-4f9c-8fce-e7116ac6c734"
   },
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    \"\"\"Define the states of the app\"\"\"\n",
    "    question: str\n",
    "    context: list[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97ea6567-c4ad-403d-bac3-7bc57750e6e1",
   "metadata": {
    "id": "97ea6567-c4ad-403d-bac3-7bc57750e6e1"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "# Define app steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a763dd3-9fe8-4cfd-a7e5-86529c16ce9e",
   "metadata": {
    "id": "8a763dd3-9fe8-4cfd-a7e5-86529c16ce9e"
   },
   "outputs": [],
   "source": [
    "# Define control flow\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "# Add a new node\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54565019-64fc-403d-ac76-e345346bddd7",
   "metadata": {
    "id": "54565019-64fc-403d-ac76-e345346bddd7",
    "outputId": "d49e7d52-9944-4e5f-be6f-36949c212b7f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">think</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Okay, let's see. The user is asking what a CRF is. The context provided explains that CRFs were proposed after MEMM</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">and differ in how they model state transitions. The key points are that CRFs use a single exponential model for the</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">entire sequence of labels, whereas MEMMs use per-state models. This means CRFs consider all transitions together, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">avoiding the label bias problem. Also, the inference uses the Viterbi algorithm, and there are software packages </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">like python-crfsuite and CRF++. </span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">So, putting it together: CRFs are a type of probabilistic model used for sequence labeling, contrasting with MEMMs </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">which use local models. They globally model transitions, avoiding label bias, and use the Viterbi algorithm for </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">inference. The answer should mention the key differences, the purpose, and the related software.</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">think</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "\n",
       "A CRF <span style=\"font-weight: bold\">(</span>Conditional Random Field<span style=\"font-weight: bold\">)</span> is a probabilistic model used for sequence labeling, contrasting with MEMMs \n",
       "<span style=\"font-weight: bold\">(</span>Maximum Entropy Markov Models<span style=\"font-weight: bold\">)</span> which use local per-state exponential models. CRFs globally model all state \n",
       "transitions with a single exponential model, avoiding the label bias problem. They use the Viterbi algorithm for \n",
       "inference and are implemented in tools like Python-crfsuite and CRF++.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mthink\u001b[0m\u001b[39m>\u001b[0m\n",
       "\u001b[39mOkay, let's see. The user is asking what a CRF is. The context provided explains that CRFs were proposed after MEMM\u001b[0m\n",
       "\u001b[39mand differ in how they model state transitions. The key points are that CRFs use a single exponential model for the\u001b[0m\n",
       "\u001b[39mentire sequence of labels, whereas MEMMs use per-state models. This means CRFs consider all transitions together, \u001b[0m\n",
       "\u001b[39mavoiding the label bias problem. Also, the inference uses the Viterbi algorithm, and there are software packages \u001b[0m\n",
       "\u001b[39mlike python-crfsuite and CRF++. \u001b[0m\n",
       "\n",
       "\u001b[39mSo, putting it together: CRFs are a type of probabilistic model used for sequence labeling, contrasting with MEMMs \u001b[0m\n",
       "\u001b[39mwhich use local models. They globally model transitions, avoiding label bias, and use the Viterbi algorithm for \u001b[0m\n",
       "\u001b[39minference. The answer should mention the key differences, the purpose, and the related software.\u001b[0m\n",
       "\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mthink\u001b[0m\u001b[1m>\u001b[0m\n",
       "\n",
       "A CRF \u001b[1m(\u001b[0mConditional Random Field\u001b[1m)\u001b[0m is a probabilistic model used for sequence labeling, contrasting with MEMMs \n",
       "\u001b[1m(\u001b[0mMaximum Entropy Markov Models\u001b[1m)\u001b[0m which use local per-state exponential models. CRFs globally model all state \n",
       "transitions with a single exponential model, avoiding the label bias problem. They use the Viterbi algorithm for \n",
       "inference and are implemented in tools like Python-crfsuite and CRF++.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is a CRF?\"})\n",
    "rprint(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb4ad45-833a-4299-8f94-a007b8fef9e5",
   "metadata": {
    "id": "ccb4ad45-833a-4299-8f94-a007b8fef9e5",
    "outputId": "4b2b5818-dbf4-474e-d031-05ae7a572a09"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5520e707-b010-4742-9479-2dc3f390b5f0",
   "metadata": {
    "id": "5520e707-b010-4742-9479-2dc3f390b5f0"
   },
   "source": [
    "### Multiples formas de invocar nuestro grafo (gráfica (?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22b27aeb-56cc-4bb4-90cc-1de2128c3d8f",
   "metadata": {
    "id": "22b27aeb-56cc-4bb4-90cc-1de2128c3d8f",
    "outputId": "bd1bc003-db41-44bd-d9da-143ad2a43c41",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'retrieve'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'e6be1a5b-7ba8-4f8a-9668-e06ce0b05dcd'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1585</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">thinking process.'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'9fde0b98-bb72-4073-ae59-6c64e1541d30'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1585</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">thinking process.'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2b182e3f-5f8e-476b-b506-fd89740f71c7'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1585</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Fig. 1. Overview of a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">“think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">thinking process.'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2d087bfc-687d-47af-a3d2-fe4c1da04fd6'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://lilianweng.github.io/posts/2023-06-23-agent/'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19372</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"(3) Task execution: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">process and show your analysis and model inference results to the user in the first person. If inference results </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contain a file path, must tell the user the complete file path.\"</span><span style=\"font-weight: bold\">)]}}</span>\n",
       "\n",
       "----------------\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'retrieve'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'context'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'e6be1a5b-7ba8-4f8a-9668-e06ce0b05dcd'\u001b[0m, \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \n",
       "\u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m, \u001b[32m'start_index'\u001b[0m: \u001b[1;36m1585\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a \u001b[0m\n",
       "\u001b[32mLLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An \u001b[0m\n",
       "\u001b[32magent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has\u001b[0m\n",
       "\u001b[32mbecome a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to \u001b[0m\n",
       "\u001b[32m“think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. \u001b[0m\n",
       "\u001b[32mCoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s \u001b[0m\n",
       "\u001b[32mthinking process.'\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'9fde0b98-bb72-4073-ae59-6c64e1541d30'\u001b[0m, \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \n",
       "\u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m, \u001b[32m'start_index'\u001b[0m: \u001b[1;36m1585\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a \u001b[0m\n",
       "\u001b[32mLLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An \u001b[0m\n",
       "\u001b[32magent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has\u001b[0m\n",
       "\u001b[32mbecome a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to \u001b[0m\n",
       "\u001b[32m“think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. \u001b[0m\n",
       "\u001b[32mCoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s \u001b[0m\n",
       "\u001b[32mthinking process.'\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'2b182e3f-5f8e-476b-b506-fd89740f71c7'\u001b[0m, \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \n",
       "\u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m, \u001b[32m'start_index'\u001b[0m: \u001b[1;36m1585\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'Fig. 1. Overview of a \u001b[0m\n",
       "\u001b[32mLLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An \u001b[0m\n",
       "\u001b[32magent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCoT; Wei et al. 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m has\u001b[0m\n",
       "\u001b[32mbecome a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to \u001b[0m\n",
       "\u001b[32m“think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. \u001b[0m\n",
       "\u001b[32mCoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s \u001b[0m\n",
       "\u001b[32mthinking process.'\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'2d087bfc-687d-47af-a3d2-fe4c1da04fd6'\u001b[0m, \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \n",
       "\u001b[32m'https://lilianweng.github.io/posts/2023-06-23-agent/'\u001b[0m, \u001b[32m'start_index'\u001b[0m: \u001b[1;36m19372\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m\"\u001b[0m\u001b[32m(\u001b[0m\u001b[32m3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Task execution: \u001b[0m\n",
       "\u001b[32mExpert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference \u001b[0m\n",
       "\u001b[32mresults, the AI assistant needs to describe the process and results. The previous stages can be formed as - User \u001b[0m\n",
       "\u001b[32mInput: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m User Input \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Task Planning: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Tasks \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Model Selection: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m Model Assignment \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, Task Execution: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mPredictions \u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. You must first answer the user's request in a straightforward manner. Then describe the task \u001b[0m\n",
       "\u001b[32mprocess and show your analysis and model inference results to the user in the first person. If inference results \u001b[0m\n",
       "\u001b[32mcontain a file path, must tell the user the complete file path.\"\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "----------------\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is Task Decomposition?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrprint\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstep\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m----------------\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2461\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2455\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2456\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2457\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2458\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2459\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2460\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2462\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2463\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2464\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2465\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2468\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/langgraph/pregel/runner.py:153\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    151\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/langgraph/pregel/retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/langgraph/utils/runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/langgraph/utils/runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mgenerate\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      9\u001b[39m docs_content = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m state[\u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     10\u001b[39m messages = prompt.invoke({\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: state[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m: docs_content})\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m: response.content}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:370\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    360\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    365\u001b[39m     **kwargs: Any,\n\u001b[32m    366\u001b[39m ) -> BaseMessage:\n\u001b[32m    367\u001b[39m     config = ensure_config(config)\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    369\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    380\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:947\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    940\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    944\u001b[39m     **kwargs: Any,\n\u001b[32m    945\u001b[39m ) -> LLMResult:\n\u001b[32m    946\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:766\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    765\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    772\u001b[39m         )\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    774\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1012\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1010\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1016\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:715\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m    709\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    710\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    713\u001b[39m     **kwargs: Any,\n\u001b[32m    714\u001b[39m ) -> ChatResult:\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    718\u001b[39m     generation_info = final_chunk.generation_info\n\u001b[32m    719\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m    720\u001b[39m         message=AIMessage(\n\u001b[32m    721\u001b[39m             content=final_chunk.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m    726\u001b[39m         generation_info=generation_info,\n\u001b[32m    727\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:652\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    644\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    645\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    649\u001b[39m     **kwargs: Any,\n\u001b[32m    650\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    651\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterate_over_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:737\u001b[39m, in \u001b[36mChatOllama._iterate_over_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_iterate_over_stream\u001b[39m(\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    732\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m    733\u001b[39m     stop: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    734\u001b[39m     **kwargs: Any,\n\u001b[32m    735\u001b[39m ) -> Iterator[ChatGenerationChunk]:\n\u001b[32m    736\u001b[39m     is_thinking = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m737\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:639\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    636\u001b[39m chat_params = \u001b[38;5;28mself\u001b[39m._chat_params(messages, stop, **kwargs)\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n\u001b[32m    640\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    641\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/ollama/_client.py:170\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    167\u001b[39m   e.response.read()\n\u001b[32m    168\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m  \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/httpx/_models.py:929\u001b[39m, in \u001b[36mResponse.iter_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    927\u001b[39m decoder = LineDecoder()\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/httpx/_models.py:916\u001b[39m, in \u001b[36mResponse.iter_text\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    914\u001b[39m chunker = TextChunker(chunk_size=chunk_size)\n\u001b[32m    915\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/httpx/_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/httpx/_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/httpx/_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/develop/lectures/st-cl-2025-2-lab/.venv/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    rprint(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bdeb341-601a-4922-a829-10e154bafc72",
   "metadata": {
    "id": "1bdeb341-601a-4922-a829-10e154bafc72",
    "outputId": "438adc30-fd7f-44fa-bfa9-fb1983aa0d35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let's tackle this question. The user is asking about Task Decomposition. From the context provided, I need to explain what Task Decomposition is.\n",
      "\n",
      "Looking at the context, it mentions Chain of Thought (CoT) as a prompting technique where the model breaks down complex tasks into smaller steps. The key points here are that CoT helps the model think step by step, decomposing tasks into manageable parts. The context also states that CoT transforms big tasks into smaller ones, making them easier for the model to handle.\n",
      "\n",
      "So, Task Decomposition is the process of breaking down a complex task into smaller, simpler subtasks. The model uses CoT to simulate this thinking, allowing it to handle each step sequentially. The example given is that the model is instructed to \"think step by step\" to decompose hard tasks. This approach enhances the model's ability to solve complex problems by managing the workload in smaller parts.\n",
      "\n",
      "I need to make sure the answer is concise, uses three sentences, and includes the necessary components like User Input, Task Planning, Model Selection, and Task Execution as per the instruction. The answer should first state the user's request, then describe the process and results. Since the context doesn't provide specific results, I'll keep it general but mention the steps involved.\n",
      "</think>\n",
      "\n",
      "Task Decomposition is the process of breaking down complex tasks into smaller, manageable subtasks to simplify execution. The model uses Chain of Thought (CoT) to simulate this thinking, allowing it to handle each step sequentially. In this case, the agent plans tasks, selects appropriate models, and executes them step by step to achieve the final result."
     ]
    }
   ],
   "source": [
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ab55c4-35fa-418b-af40-6227eda939c7",
   "metadata": {
    "id": "41ab55c4-35fa-418b-af40-6227eda939c7"
   },
   "source": [
    "## Dando posibilidades conversacionales al RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b5b5f-a77f-441b-ae53-9e499b623376",
   "metadata": {
    "id": "394b5b5f-a77f-441b-ae53-9e499b623376"
   },
   "source": [
    "Hoy día es muy popular interactuar con estos sistemas de Q&A a traves de una interfaz de chat conversacional. Esto es permitir que el usuario tenga una conversación de ida y vuelta con nuestro sistema. Esto implica que el sistema debe tener \"memoria\" para acceder a las preguntas y respuestas pasadas y cierta lógica para incorporar el historial para generar nuevas respuestas.\n",
    "\n",
    "Una forma modelar la interface conversacional es a traves de [mensajes](https://python.langchain.com/docs/concepts/messages/) con ciertos roles (user, IA, system), contenido y metadata. En particular los estados de nuestro RAG serán representado como secuencias de mensajes con las siguientes particularidades:\n",
    "\n",
    "1. Entrada del usuario modelada como `HumanMessage`\n",
    "2. La query que haremos al *vector store* como `AIMessage`\n",
    "3. Los documentos reelevantes como `ToolMessage`\n",
    "4. La respuesta final como `AIMessage`\n",
    "\n",
    "Este modelo de estadod viene integrado en LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "871e9300-04ee-4992-9127-40040cf4ee2f",
   "metadata": {
    "id": "871e9300-04ee-4992-9127-40040cf4ee2f"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_msg_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80bc1f1-8680-4886-8fe5-aaf2ab5de3d1",
   "metadata": {
    "id": "f80bc1f1-8680-4886-8fe5-aaf2ab5de3d1"
   },
   "source": [
    "### Tool calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e5ebc1-19ab-4214-aa43-43df6608c475",
   "metadata": {
    "id": "a0e5ebc1-19ab-4214-aa43-43df6608c475"
   },
   "source": [
    "Permitir que se realizen llamadas a *tools* en la etapa de *retrieval* posibilitará que el modelo genera la query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a6f3b9-5f15-4251-a70b-381d9630b550",
   "metadata": {
    "id": "40a6f3b9-5f15-4251-a70b-381d9630b550"
   },
   "source": [
    "#### ❓ ¿Porqué sería reelevante hacer esto?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a38f3e4-9e6f-4b92-9bd3-bdb059c37a78",
   "metadata": {
    "id": "3a38f3e4-9e6f-4b92-9bd3-bdb059c37a78"
   },
   "source": [
    "En una conversación puede que la query del usuario deba contextualizarse basandonos en el historial. Por ejemplo:\n",
    "\n",
    "```\n",
    "User: ¿Qué es el mole?\n",
    "\n",
    "IA: El model es un platillo mexicano, a base de chocolate, pimienta, pan (bolillo), tortilla tostada, chiles, tomate, cebolla, clavo (especie), comino, nuez, almendra (no en todos los tipos de mole), laurel.\n",
    "\n",
    "User: ¿Cuál es la forma mas sencilla de prepararlo?\n",
    "```\n",
    "\n",
    "En este caso, el modelo debería generar una query del esitlo: \"formas sencillas de preparar mole\". Habilitar llamadas a *tools* permite esta generación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33813754-d032-4ff3-a0b1-3065632237db",
   "metadata": {
    "id": "33813754-d032-4ff3-a0b1-3065632237db"
   },
   "outputs": [],
   "source": [
    "# Convirtiendo nuestro retrieve en una tool\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_tool(query: str):\n",
    "    \"\"\"Retrieve information related to a user query\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e77419-b3b2-4af3-ab82-0835fab14ac1",
   "metadata": {
    "id": "36e77419-b3b2-4af3-ab82-0835fab14ac1"
   },
   "source": [
    "Más sobre crear *tools* en la [docu](https://python.langchain.com/docs/how_to/custom_tools/). Acá explican porqué `response_format=\"content_and_artifact\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca3845e-d75f-46ba-85d0-014076cde4fd",
   "metadata": {
    "id": "cca3845e-d75f-46ba-85d0-014076cde4fd"
   },
   "source": [
    "El grafo consistirá en tres nodos:\n",
    "\n",
    "1. Un nodo que procesa la entrada del usuario y genera una query para el *retriever* o responde directamente\n",
    "2. Otro nodo para el *retriever tool* que ejecutará la obtención de los documentos reelevantes\n",
    "3. El último nodo que genera la respuesta final utilizando el contexto del *retriever*\n",
    "\n",
    "Los elementos del grafo se definen acontinuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96c77fc9-a1b1-4c12-9f48-fe080bda425d",
   "metadata": {
    "id": "96c77fc9-a1b1-4c12-9f48-fe080bda425d"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# 1. Generamos un AIMessage que podría incluir la llamada a una tool\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Genera una tool call para retrieval o responde directo\n",
    "    \"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve_tool])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51ee25c7-ec74-47f3-b6b6-7c38516b4122",
   "metadata": {
    "id": "51ee25c7-ec74-47f3-b6b6-7c38516b4122"
   },
   "outputs": [],
   "source": [
    "# 2. Ejecutamos el paso de *retrieval*\n",
    "tools = ToolNode([retrieve_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6240a723-aace-4f48-a423-8f233ba17d41",
   "metadata": {
    "id": "6240a723-aace-4f48-a423-8f233ba17d41"
   },
   "outputs": [],
   "source": [
    "# 3. Generamos la respuesta utilizando el contenido obtenido\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Genera una respuesta\"\"\"\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if not message.type == \"tool\":\n",
    "            break\n",
    "        recent_tool_messages.append(message)\n",
    "    # Obtenemos los mensajes de tools en orden inverso\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "    # Creando un prompt con los mensajes\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    convertation = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message)] + convertation\n",
    "\n",
    "    # Run!\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d4a8d6-c72e-4b0a-adff-1b054b76f072",
   "metadata": {
    "id": "22d4a8d6-c72e-4b0a-adff-1b054b76f072"
   },
   "source": [
    "#### Construyendo el grafo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6f4ac0-cadc-4adc-9ca2-6834ea6ba63a",
   "metadata": {
    "id": "ae6f4ac0-cadc-4adc-9ca2-6834ea6ba63a"
   },
   "source": [
    "Concentraremos los elementos definidos anteriormente en un solo objeto `graph`. Conectaremos los pasos en una secuencia y permitiremos que el primer paso `query_or_respond` realice un *short-circuit* y responda directamente en caso de no necesitar llamas a las *tools*. Esto permire que nuestro RAG brinde una experiencia conversacional más \"natural\", por ejemplo: respondiendo a saludos del usuario donde, en principio, no se requeriría ir a la base de datos vectorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ac540e4-b7ae-4853-a504-747878a1981c",
   "metadata": {
    "id": "7ac540e4-b7ae-4853-a504-747878a1981c"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_msg_builder.add_node(query_or_respond)\n",
    "graph_msg_builder.add_node(tools)\n",
    "graph_msg_builder.add_node(generate)\n",
    "\n",
    "graph_msg_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_msg_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"}\n",
    ")\n",
    "\n",
    "graph_msg_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_msg_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph_tools = graph_msg_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bed0c4-32c2-49a0-925e-d3c4f107f99f",
   "metadata": {
    "id": "19bed0c4-32c2-49a0-925e-d3c4f107f99f",
    "outputId": "37d0adcf-30c9-411b-8600-4c0fc27328e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALcAAAGwCAIAAABkfmPEAAAQAElEQVR4nOydB1gUR//HB+4OOA6O3qsUUYooRQWNvcYWo+avYhIjamzRRI0lMYlvjC3RaIyivmo09kRjN3bEXkBpikhH6R3ujuvH/weX90ISZCHewezdfB4enr3dnb293e/+5jtlZ5h1dXWIQGgWJiIQqCAqIVBDVEKghqiEQA1RCYEaohICNbRRSWmehF8tra2RS0QK+EPYw2TpMZh6xqYMYy7TysGQbaKPaIse5vUluc9qs5L4WU8Ebp2MRUIFx5RhZsOSy2hQx2NgqM+rkoGsa3kyfrXMyJjhEcDxDuKamjMQ3cBXJaCPu2fL7N2MbF2N4PqyTeh3cRtTmC3KfiIoKxCbWbHCR1mxDOkUWjBVyZWDxaJaedhIa2tHA6RdJN+uvnuuLGyEdZc3zBBNwE4lFUWSw9++mLDAxc7NEGkvcVcqq0olgybbITqAl0oEVfJTO/InL3XV00NaT+pDXnaKYPhUe4Q9GKmkOFcUfbRk0lJXpDOkPeIl36keN98Z4Q0uHkomrTuxLV+nJAJ0DDbtGGR643gpwhtcVHLlYFHEUjekewT0NjMyYTyP4yGMwUIlT+5Us02YXCsdrQgOGmBx/VgJwhgsVHLnbDlUISBdhWWg162fRezlCoQr7a8SqD/oPtTSwIjGFdivT4/hlvkZQgWuDQ/tf29SY2scPYxQG5KRkTFy5EjUen755ZeVK1cizWBozMhK5iMsaWeVCPny6nKZnVubqiQlJQX9K/51wpbQwY+T80SAsKSdVZKbWuvXk4s0Q1FR0ZIlSwYNGhQeHj5hwoRTp07ByqioqK+//ho2hYSEQGyANU+fPp0zZ87AgQN79+79/vvvx8bGKpMfPXp0yJAhMTExcIStW7dGRkaeP3/+3LlzkBCiEVI3nl1MqitkCEvauVhRWSTRnCOB3EEul2/ZsoXL5d69e3f16tVOTk5ws4VCYXR0NIjAyMhIJBLNmzcvKCgI1MNkMo8fP75w4cKTJ09aW1vDR9jz2LFj33zzjbu7+7Rp0z788ENXV9dly5ZxOBykbliGepVFYpFAYcTBzqK1s0oENTILW2OkGTIzMydPnuzr6wvL77zzTufOnUElhoaGBgYGenp6pqamsB4Wdu3aZWNjY2ZW3/Y2e/ZskEVSUtKAAQOUKomIiOjZs6fygAwGg8ViKRNqAmMuEy6IEQe7Bs72Vkm1jGOmqS4Bb7zxxp49e6qrq3v16tW1a9eAgIB/7gNSkEgka9euTU9P5/P5yvaKmpoa1Q5KkbUNHLN6lVg5EJX8FX19PT19TbXsLV++3NPT88KFCwcPHjQxMRk/fjyECogHjffJycmZNWtWWFgY5EeQy0il0lGjRjXeARKitoLJ0kN1OLZztrNKjDgMCCdIM0DuENFAWVnZmTNndu7cCTqYOHFi430uXbqkUChWrVoF2RB8zMvLQ+0Hr0JqbIpjZ6t2NkrGXAbEWKQBeDweRBGZrP7gIA7wnn5+fv8sm0B2w2azlRIBIAn8b6adXKNN6IIaueby39ehnVViaWcIrcFIM4DbWLNmzfPnz/Pz8+H2p6WlQVkG1oP9LC8vT0hIgPKwv79/ZWUllG8h3kDBGPaBAhEkEQiaqLqAhLADbAWvg9SNQoYs7Q3w7LjJ0FxlYkuAixJzvLRbP3OkbqAsExoaeu3atb1798Lthyjy7rvvjhs3DjbZ29vfvn378OHDUKB9++23oSCzf/9+ZcF4xYoVEH6gmAMrLSwsbt68OX36dH39P54lKAeBnk6cOAFVJlBcQmolI5HPr5R5dW07G9Ry2r8X0tHvXgyabGftpM39F1vC5YPFbp2NfYI1Vcx+Hdq/AscnhFuQJUI6j4gv7+Cr/so6tdD+XTq69TffujAjoLfZq/q6Xrx4cd26dU1ugoIrFGSa3AQVplDjjjQDVOdDrW6TmyA2673il0DGZ2fXdHfox9GVEE0N2Jg2jGPR7xWuETT79Rpt3eTW2traqqqqJjdBQeZVNaGWlpbgM5BmKCwsfNV1g0KTqsT0N2xtbaESr8lNWz/JmPe9F8K1TzguvaPP7iwY8q69obEu9jKJv14F9WkQTRGu4HJXBky0PfxtLtI90h/zS16KcJYIwkcl0IQx4P/sftvSnlWfbU9BpjD2SsXQ93B/JQevt7Yqi6XXfikZP1/NVRF4kpNS+/haxdsf4f4yDsLwDdD8DOHvPxW+s9DFzJqFtJfk29U5zwSjZjgiOoDj2+TiWsXVI8WGbP3wUdZ4tn69DlDHevdsWefuZqFDLBBNwHdkitSHvDv1V5Nr727k4c/BtpTYQqrLpNlPBMUvxApFXa9RVlwrOkVK3Ee5eR7Ly0jiw/UN6GUmk9VxuAwzKxYtBjKGwi2/WiaolkOjN69SJhLIO/hzOgaZ2rrQry0Cd5WoeJkm5FXWj5gllSigCg6plUePHrm6utrY2CD1YchmQB2sMZcBxTdrR0MLWxrbLNq8dOnSkQ1NyEgznLz9e6+gSeHhfojQFGSMRgI1RCUEaohKCNQQlRCoISohUENUQqCGqIRADVEJgRqiEgI1RCUEaohKCNQQlRCoISohUENUQqCGqIRADVEJgRqiEgI1RCUEaohKCNQQlRCoISohUENUQqCGqIRADVFJPYaGhnq6MDntv4WopB6xWEyXdxzbBaISAjVEJQRqiEoI1BCVEKghKiFQQ1RCoIaohEANUQmBGqISAjVEJQRqiEoI1BCVEKghKiFQQ1RCoIaohEANbcaO1gTBwcF6enoKhUI1FywsOzk5nT17FhEaoYszoKnw9PSE/yqJoIZJ76dMmYIIf0WnVRIREWFo+Je5A5ydnd966y1E+Cs6rZIxY8aALFQfmUzm2LFj/6YbAtJxlaCGcKKa2NXR0fGdd95BhH+g6yoZPXq0MpwwGAwIJK+aCljH0XWVAJMnTwZxuLq6TpgwARGagrq+pDRPXJYv5lfLkJbiZNwn1OuFn59f8s1ahGqRNmJoxDC1Yto6G3HM/s08iM3Vl8hldWd2FsikdWY2hoZsbZtlUacwNNYvzhHq6SM3H3ZgX3PUSl6pEhDHqaiCLn0sHTw0NcMVoe25ebzI3ZfjF2baqlSv9CWndxQE9iMS0Tb6jLdPj+dlPxG0KlXTKinMFDGY+vbuRCJaSLcBVgk3qlqVpGn3WlYoNjEnDYHaibmtYUGWsFVJmo4lQp6cbULsqnaiz0BGxgyRQNHyJE0HDDC05BV8LaauvszSihtMshUCNUQlBGqISgjUEJUQqCEqIVBDVEKghqiEQA1RCYEaohICNUQlBGqISgjUkH6vtOe9qeN+3LYBaRISSwjUEJUQqFGbSkpLSzZsXJWQ+MjUlDt61PjaWsH9B7f3/XQsJSV57kcfbI/a38nHV7nnxMkjB/QfOnPGR7BcWVkRtWNTUtLj6uoqDw/vWTMXdOnSDdafOHH04OGfFn7y2YaN34x48y04rImJ6fq1W1Rft/zzjwUC/pbNu5s5pZKS4u07Nj169EAoErq6uk+aOHXQwGGwPjMzffrMSatXfb9z1xY47LYf9zZzkNFj+r//3swHD+/AOZw+Gc1ms69eu3js2MEXL3OMjTkDBwyLnDZH+TpgYuLjPXujsrLSoVne07PjjMh5AQFdYf3wEb3fe3fGixc59+7fEotFIcE9Fy9aYWZW30VZIpHs+Skq+vqlqqpKKyvrIYNHwHcxGIysrIzIGRM3bth+/LfDT54kMpnM/v2HzJ29UPlKc3Jywg8/rs/NzXZwcFJeRk2jNl+ydt2XOblZ69Zu2fBtVGlp8dVrF+C3NZ9ELpcvWToPZLRs6X92bj/Y0bvTkmXz4MfDJgaTKRIJT58+9vln34DmQChxcfcrKsqVCQUCAdz7YUNHNXNwqVT66dK5eXkvvln1/d49v/YK77t6zYr792+jhlfG4f+Bg7sjJn2wZPGXzZ8kk8U69/tJHx/fHzbvBjXcuHkNjhMS0nPXf498uugLuMGbNq+F3YRC4WcrPvb08N724z74c3PtsHT5R3w+v+HrDI4c2RfULfTE8cs7og48S32yfcdm5cE3/7Du4qWzc2Yv3Lf3+LSps0ETu/dsU53htqiN70ZEnjkVvXzZ1/DY3L4TAyvhmJ9/sZBragaHUq6vqqxAGkY9KoFAEp8QN3nSB926hri7e3zy8XIWk0WZKjb2XkZmGjxYkMrNrcP8j5ZYW9mcOHkUNbyyC9d9/PiI0JCednb2/fsNMTIyuhZ9UZnw7r2b8MD17TOomYM/eHAHHl/QHwQnZ2fXaR/M7tzZ//TZ46i+s1Z9N7xu3UKHDBkB39v8ScIXsdnGEDA6d/KDRxnud2Bg0Izp85ydXHr27A0B49Llc+XlZSUlRbW1tYMGDocDwhWA37Lmm83K50RPT69jx86DB78JyWHrqJHjbty8CiKG8Hn5yvn3353Rv99gJ0dnOJm3xrxz7vwJeHj0GmJGv76D4ZxhQXkRnj9PgWWI0DxeDRzf09MbTmnJp1/x+DykYdSjktwX9QHA27vTHwfV11f+vOaBpwoemq6BwapU/v5d0zOeq3ZQZVIQ5yGTunz5vPLjzZvX+vQZyOFwmjl4ekYqpIJLqVrj07FzZmbanx//d3BKVKchk8nS0lMhy1BtCmw4+cysdBAi/K1a/dnhI/vgJ9T/rq7BoGzlbl5ePqokoCGRSARxEVKBIHz9uqg2gZggVBQVFyo/QmRSbYKckd+ghtzcLGNjYziIcr29vYOlpRXSMOrxJUJh/StxJhwT1RrIsylT8QV8eKSGDg9XrYGrZmNjq/rIaXTAESPGnjt/EjJsyIxj4+6tXfMD5cH/dg7wUXme/zx486j2BH8DnmPfzzv3H9jVeIeKijIIOT9s2nX0l/3nz5/ctXurvZ1DZORcpQ1C9So3Vu1sZFT/ZgLccrBu9QdvdJLKE4b1yv0N/jr6gfLNqVphrfIIfzugRlGPSv745QK+ag1EReXCP2c6E4vFygVQFTxt4Egab1VmB/8EHmgvz47gAzp08LIwt1RFoFcBBxc0Oh9U72b4LVdGk7CN2BDwJoyPGD5sdOP1Fg1PMzzTc2Z/An8g5aO/7gf74u7m4eXVETXceNXOymWIDcqTEfxjE6xXKF7ZddnI0OifvwtpGPXkOC7ObvA/PT1V+REi89OUJOWy8lqoLhNk4eDnlcudO/lD7IUFKIAo/1gGBjbWtq/6ljfffAvMY0zMlaFDR1FOs+fT0RcOnpHxZxYDNrmjd2f0GoDPAIsNFkR1wvb2jmBvTU1M8wvy7ty5odzNw8Nr8cIVcIbZOZnKNVCIUx0E7IWJiQmUaKBMBxHo6ZNE1aanT5O4XDMHe8dmzsHVxR0es5cvc5UfIXcDf4M0jHpUArmjn1+XQ4d/ehh7D3LuNWu/YPwvJMB1hFIfWAqQTg2v5set30FRWbkJSgoQHuCZS0h4VFhUACXMmTMnnz3326u+ZdCg4VB6Avs2dOhIylPq3j0ccqoHSwAAEABJREFUrOJ3G75+lvoUbuGOnT+AUx4/bjJ6PSZOfD/mxlUwH3CflL90/oJIMNpFRQVfrvz02PFDYJnhDwpQcAV8fQOUqUrLSn7evwtO4+7dm+BPwWOB4My4ZlBMO3BoD8iruLgICjvw2+EMm38AwDKDL/lhy/rU5ylJSfFbfvzW3NwCaRi11ZdAkXXDhlUrvlgIwQO8OkTUlGfJsN7AwAAKGlCoGzWmn62t/czpHxUXFyojKlypb9dvhfoSuL5QkQCGY+r7H44bN+lVXwGPLLhFqUTS/NP2xw+Dg6/bGrX9+yVL50JQ8ejgBRUkysqY16Fvn4FQ/jxydN/efTvgN/r7BW7auBNscnBQdyhU/3r8INR/wFe7u3uu+nojlFyUqUaOGFtVVTF7zntSqaR3r35Q9FWuXzB/KVyuTT+shfhqZ2sPlSUT/++95k8AHrn/rPxu67YNH82fBk/ghzPng2Q1PYRi02+TP7hQIZWiwL6W6N/y/aY1oJLd/z2C1AdUwU2eMhrkCBca0YcxYweOe3vSe+9OR9jwy3dZEcvd2JyWvphHjxp6yHoLCvK2Rm2EvDw8rA8itC30UMn5309B+RPKNZ8u/lI18Ca4UajffFWSI4fOgUlEVKjlIFqPpnKcNgAaQcoryl61FbL5xgO5avQgtEM7c5wmAV/cEhvbBgfRekjPAQI1RCUEaohKCNQQlRCoISohUENUQqCGqIRADVEJgRqiEgI1TVc/G3H0FVo7OwEBMZj6RsatGKm1aZVYORiW5rVu4FgCXagoEkMUoOrr9xeaVomzN1ssUvAqpIigdaQ/runSu3XTWryywXPUDIe7Z0r4VSTj0SoeXSlnm+j7hXFblaq5+XFAIse35Nm5GZvbGECMQgTawmLpl7wUyWUKAyO9vuNsUCuhnnU6I0FQmifiV8kRxvAF/Pz8fJ+OPqjNga/Oy8vr5NMJYQyHyzTm6tu6Gjl6GKHWow1zk4tEovXr13/11VeonYiNjQWhjB07FmkpOj2DPaGF0N5tbNq0KT4+HmHAunXrUlJSkDZCb5WcPn26Y8eO3bq97ls2amHZsmW7d+9WjkahZZAch0ANXWNJUVHR6tWrEX6kpqZGRUUh7YKusWTy5MkHDhxgMHCcNu7s2bPV1dVTpkxB2gLJcQjU0C/HOXnyZGJiIsKeHTt2FBcXI62AZrHk2LFj5eXls2bNQnRg0KBBV69eRfSH5DgEamiT4wgEAqiNQHQjLS3t999/RzSHNioZM2bM+PHjEd2ASr+cnJw9e/YgOkNyHAI1NIgljx49evbsGaI5UDSDTBPRE9xVcurUqQsXLnTu/FpjK+LA4MGD33zzTURPsM5xZDKZSCTSmtGI6Ptz8I0lcrn88uXL2jRgFZPJLCsre/LkCaIb+Kpk3LhxAQEBSLtwd3c/c+bMb7/9hmgFpjkONPmaNIC0kby8PGtra9VcBviDYyzJzc2VSCRaPDiis7NzQkIC2BREE7BTSXR09NatW11dXZFWA1kP1BMimoBXjtMwv0CGvz/13DpaQHV1dWlpqZeXF8IevFSSmpoKVdpaOcRqk0CRB66/jU2rX6NqYzC6H0eOHIF2dt2RCAAedtKkSWDCEN5gNH6Jo6Oj4V9nl9IFoLRvYGCA8Ia09hGowSi8FxQUZGVlIR3j1q1bCHswUklMTAw0nCId45NPPkHYg5EvcXJyolF1pLp44403EPYQX0KgBqMcB1o30tPTkY4B+SzCHoxUcvPmTWgvRTrG4sWLEfZg5EtcXFyMjY2RjtGvXz+EPcSXEKghvqSdIb6kdRBfgi3El7QzxJcQtATiS9oZ4ktaB/El2IKRL3F1ddWd6eKDgoL0/jetRHBwsHIhLCxs69atCD8wUknv3r2RzuDg4PC3kZLs7e3nzp2LsASjHOfly5dpaWlIN4BY0vgjlCG6dOmC7evQGKnk1q1bZ8+eRbrBxIkT7ezsVB8htOA8piNGKgFf4u3tjXQDPz+/xkNed+3a1dfXF+EK8SXtRkRERHx8PLgTcCQQWhDGEF/SboALAS8CjgQCCeYvqmEUS8CXFBYWLlq0CGFJnQIVZgsrS6SiWrVNKPVGwPv8PNve/iMeXatEasKIzbCwYzl0YOupLwJgVEN/9+7dioqKkSNHIvwoyhHdOlUGC45eHKlYgTCGZaBfkFk/NNcbb1nbu6unHzFpx6GmJE9y43jJoAgnpkFrpldtV2SSuquH8vuOs7F1UcOLcBj5ktzc3NTUVIQZYqHi1La8YR8400giAJwtnPOpqHw4f/TaYKSSO3funD9/HmHGo6uVwYOsET0JGmQVd0UNjgcjlbi7u/v4tMMkns1TlCviWrEQPTGzMih+IUKvDUZlnPDwcIQfYoHc2BSjq9QqjLlMtZTIiC+hQKGoo6/BhxNXyNVw8hg9JeBLoL6kUyesp2/WTTBSCfgSLpeLCPhBfAmBGox8SU5OjhbMSqCVYBRLoIYefIkWTEygfWCkkg4dOpibmyMCfmCkkrCwMETAEuJLCNQQX0KghvgSAjXElxCowciXZGdn03EeKrWTlZXRf2BIcnICwgaMVHLv3r1Lly4h+vPVyiUXL2nVi0UYqcTDwwPnd1JazvO0FKRdYORLevbsiWhOXV3dgEGhsLD+2/9s37H59MlrEolkz09R0dcvVVVVWllZDxk84v33ZjIYDNinmU0qpFLpzv9uuXU7urKywsLCsl/fwTOmz2My2/quYaQS8CUCgYDWUyjp6en9duzSuAlDF8xfOmjgcFiz+Yd1d+7e+HjBso4dOz99krh5yzq48R/OnN/8JhWHj+y7HnN5+bKvHRycXr7I+W7jKiMjow+mzkJtC0YqAV8C9SV0n2iLw6kfXAPupYmJSXV11eUr5+fM+qR/v8Gw0snROSc36+y536ZHzuXzea/a1PhoOTmZnh7eIcE9lPt8v2EHg9kOtwwjX+Lp6allc7FlZqXL5XJfvy6qNRA2+Hx+UXFhM5saHyGs5xuxcfdXffPZjZvXeHyem1sHZycX1OZgFEt69OiBtIva2vq3pzjGHNUa44ZlWN/MJob+n9ZkyJARxhzO6dPHVq9ZAaand69+kJeZm1ugtoXUl2gQZe4jaBCEkj/EwTFpZtPfDgLK+O7bbadPRi9dsjIx6fHG71ejNofUl2gEZYdqDw9vKLOAM1Wtf/o0ics1c7B3bGZT44PcvhNTWFQAy2w2e9DAYW8OH5OVnYHaHIxyHC8vL2trur4fpcKwgcTEx15ePh3cPYcNHXXg0B57e0f4GJ8QC/40YvI0KAqZcc1etUl1KFj+9dhBmUw2a+YCG1u7oqKCmBtXuwYGozYHI5V0794daQWTJk49+svP9+7fOnzwDNgIyEQ2/bAWKkXsbO2hRmTi/72n3K2ZTSpWfrk+avv3X678VCDgQ51KeFifyGntMPYaRm+TZ2Zm1tbWBgQEIJw4tDa37wQHMxvcp+lskuoyacyvBVOWu6HXA6NY8uDBA6gvwU0lBER8CaElEF9CoAajkjD4kuTkZETAD+JLCNRgpBJvb28bGxtEwA+MVBIaGooIWIKRL0lPT09MTEQE/MBIJbGxsVevXkUE/CC+hEAN8SUEaogvIVBDfAmBGuJLKDCxZEkldB2jUSpWcC3VMFgt8SUUmFmyygtE1k5qGM297YEzV4tK8PIl8fHxCDP8w80yk3iInmQl8fzD1TDsJV6+JDo6GmGGtZNBUH/zmF+LEN2Ac+7W31wtURCjHKdjx46NJzzEB+9uJjJp3dWDBSYWLDs3dp0Ca5uir69XlCvkV0o7hZrCmSN1QObHaSk1FbLcFAGvUsavlCH1kZCY0DWwK1IfHHMm15Lp7ssxtVRbCMBIJeBL+Hx+45kxdYGQkJC4uDiEN8SXEKghvoRADUYqgdiLCFiCUY7z/PnzR48eIQJ+YKQSkEhMTAwi4AdGOU6nTp0cHBwQAT8wUklQUBAiYAnxJQRqiC8hUEN8CYEa4ksI1BBfQqCG+BICNRjlOJ07d3ZyckIE/MBIJbrWZ4BGYJTjPHv2LDY2FhHwAyOVxMfH37x5ExHwg/gSAjXElxCoIb6EQA3xJQRqMMpx/Pz8XFzaYfIXAiUYqSQwMBARsASjHCclJeXhw4dIx7CwaOspkf4FGKkkISHh1q1bSMeorKxE2EN8CYEa4ksI1BBfQqCG+BICNRjlOP7+/q6uroiAHxippEuXLoiAJRjlOE+fPr1//z4i4AdGKklMTLxz5w4i4AfxJQRqiC8hUEN8CYEa4ksI1BBfQqCG+BICNRjlOMnJyXfv3kUE/MAoloBKCgsLw8PDkQ4QHBxcV1enp6fXeDksLGzr1q0IPzBSSUBAgLu7O9IN7O3ti4uLVR9BIg4ODnPmzEFYglGOAyrRkUACdO3a9W9ju8PP9/X1RVhCfEn7MHnyZAgnqo+wPGXKFIQreKnk3r17SDfw8/ODcKJchqASGBiIbSBBuOU4YN+QzqAKJ+BIJk2ahDAGL/eKdAkIJ/CToVgHQQVqFBHGYKSSpKSkmpqa3r17ozakokhSli8W1KhzYqSW06fLezUvLHv7j4q/3j7vW3C4TGsnQ0t7g+Z3w2gWpcOHD8ODtWjRItQmwO8+t7tQUC3jWhuwORg9LW2JUCDjlUs5ZowRkQ4NdTdNg5FKoE2Yx+P17NkTaR6FAp3cmt+5p7mLDwfpPC9SBc8eVL09z0n/FTZVR+ftO72jwCfU3MnLGBEayM+ofR5bNWaWY5NbMSrjgC+5ffs20jxFOeI6BSISaQxcDbgmcGWa3IqRSp48efLgwQOkecoLxcZcHTUizQDXBK5Mk5vwegPUw8MDaZ7aGhlRyT+B8k5tjbTJTXi9TY7aBHBiEF0JfwMcPbRMN7lJF30JobXooi8htBaMchyoqPby8kIE/MBIJTg3iuo4eL1pQUamwBO83toio9zgCfElBGqILyFQQ3wJgRriSwjU4DXzibe3NyLgB16zKCECluA188mNGzcQocV8tXLJxUtnkebBaxaluLg4RGgxz9NSUJtAfEmLKC0t2fD9N4mJj0xMTCdPnFpWXvrg4Z09u46i+ukGKqJ2bEpKelxdXeXh4T1r5oIuXeqnlsvKyoicMXHjhu3Hfzv85Ekik8ns33/I3NkL9Rs6l74q1YkTRw8e/mnhJ59t2PjNiDffmjF93rPUp3v2bEvPeC6RiN3dPWFNULdQmUw2eGh9B+H13/5n+47Np09eg+Wr1y4eO3bwxcscY2POwAHDIqfNMTQ0ROoAo1gCviQ0NBRhyXcbvs7Ozlj9zab1a398EHv35q1o5XABcrl8ydJ5KSnJy5b+Z+f2gx29Oy1ZNi83Nxs2sVgs+L8tauO7EZFnTkUvX/Y1KOD2nZjmUzGYTJFIePr0sc8/+2b0qPEikWjp0nlGbPaG76Kitv7cycd3xRcLy8vLQHO/HbsE+y+Yv/TQgdOwcOPmtdVrVoSE9Nz13yOfLvoi+oCQtD4AAA5WSURBVPqlTZvXIjVBfAk1ZWWlsXH3350yPTiou6en9xefr6mqqlBuio29l5GZtnjRim5dQ9zcOsz/aIm1lc2Jk/UxRq8hZvTrO7hz5/o3skJDetrZ2T9/ntJ8Krj9QqFw/PgI5f7wcfOmXZ8u/tLby6dDB88PPpgNW5+mJMGeHI4J/DcyMjIxqV84cmRfYGAQRBpnJ5eePXvPiJx36fK5qir1vOaDUY6Tk5NTVlbWt29fhBn5+S/hv5/vH0M1wV3p1jW0sCgflp+lPoGY0TUwWLkJchN//66QO6jSenr8mYdCbsXn81qSCmKGcgFUIpFKNm9em5mVLhDwlS888Hg1fztDyIDS0lOnfTBbtSaw4eAvXuSYm6thliaMVNKpUyc+n4/wg8evvysQ9lVruFwzpUr4Ar5UKh06/M8BNSA3sbGxVX00+KszUN5mylTKOIEabvOixbNCQ8JWfL7aytIaUk2KGPXPMxSKhHDkfT/v3H9gV+P1lf+Lea8JqS+hhsmsdxgS8Z/9y2tqqpULJhwTiPngLRrvr89gNH/AlqcCe6FQKD5bvsrAoP4lzfyCvCYPyDZiQ0CaMD5i+LDRjddbWlojdYCRSh4/BsNf3b9/f4QZTo7O8D8t7Zm7e30Xfwh4CYlxdnYOsNy5kz8YTFhwdXVX7lxYVGBpYdX8AVueSiKRGBmxlRIBrl69gP4XkJQolyFjAgtcUlKkOiAkhIKY0rK8Phi519TUVBAKwg8XFzcPD68Dh/ZAqQRKIqvXrlA9o1Cm8PLsCIWLhIRHcKehLDpz5uSz535r/oAtTwXOFxzopUvnoFxz4uQvmZlppqbcjIznAoHAsIHExMdgaMCXTJz4fsyNq4eP7Hv5Mhc8ypq1X8xfEKnU4uuDUSwJDg7G05cAX32x7tsNX3+8cKaNte2UKZFPnyZlZWeghof42/Vboebjy5WfisUiBwenqe9/OG4cxWAkLU/Vu1e/dyZM2b5zszxK1qNH7yWffvXrsQO//HqAxTKYO2fhpIlTj/7y8737tw4fPNO3z0AobB85um/vvh1gk/39Ajdt3An5GlIHuvie8MOLFWIR6trfsuVJoPwJBlMVwBd8MgPKrl+sWIO0iITrFYZGqPuwJi4L8SUtYunyj6D8ufDjzywsLO/eu5mUFL9+3Y9IZ8BIJeBLCgsL8VQJ5DhR27//4qvFkEE4Obl8tuzr7qE6NLgX8SUtwsrKWsvyl1aBkUp8fHwQAUswKgnHxcVdu3YNEfADI5WkpaUlJCQgAn5glOOEhoZi60t0HIxUQrpGYwvxJQRqiC8hUEN8CYEa4ksI1BBfQqBGF30J24Sp0MkRs5sHLgnbtOlednj5ktraWqR5LO1Zzx/xEOGvlLwQegY03ZtCF32JkydbJlXwKqWmFixEaACuBlwTuDJNbsUox4mNjb1y5QpqA/TQiEiHu6dLhDw5IjQMpg1XA64JesXkJxjFkvT09MLCwsGDByPNY2rBHPqe3bFNL5x9TMytWWwTBtJJhHx5VZkkL00w4WMXuCav2g2jHo2gEvAlgYGBqA15HscrzRPzq9pnri0g+UlygH+7TUXHMWfaOhv6hJg2v5uOzo+DDyEhIfiPtKCTvoTQSjBSCeQ4SUlJiIAfGLnXHj16tE19CaG1YKQST09PRMASjHKchw8fXr58GRHwAyOVZGRkJCcnIwJ+EF9CoIb4EgI1xJcQqCG+hEAN8SUEaogvIVCDUY5z//79CxcuIAJ+YKSSrKyslJQ2Glid0CowynHCwsIEAgEi4AdGKunQoQMiYAnxJQRqiC8hUEN8CYEa4ksI1GCU49y7d+/3339HBPzASCXZ2dnPnj1DBPzAKMcJDw8XCoWIgB8YqcTd3R3pGFevXh07dizCHoxyHFQ/Q17Z0KFDkW5w6dKl6Ojozz//HGEPdu/28fl8uHajR49GWk1MTMy5c+c2bNiA6ACOb4DKZLLKykobGxukpdy9e/fIkSM//kibWTHwynGUMJnM8vLyiIgIpI3ExcXt37+fRhJBOL9NXlNTk5mZ2a1bN6RFJCUlbdq0ae/evYhWYD3mAI/Hy8vLw3Zu0NaSmpq6atWqQ4cOIbqBY46jwtTUtLq6et68eYj+QJ3hihUr6CgRRIvxS6AJEIKKvb09oi35+fmzZ88+c+YMoidYxxIlHA5HLpfjPxTMq4BKoMjISPpKBNFCJYCTk1NRUdHKlSsR3QAPPmHChIsXLyI6Q6cRs6AeRaFQqCbqxh+RSDRw4MA7d+4gmkOPWKIE6lGgmECXiw6PX+/evbVAIoheKgG6dOlSUFCwe/duhD1hYWH37t1DWgEZo1Ej9O3b9/z586q5zOkOzWKJisuXL0ODGcKSwYMHnzx5UmskguirkiFDhkCpB8Oyw8iRIw8cOGBpaYm0CK3KcaBA0cYz7CxatAgqcm7cuKH8+Pbbb0MzjZubG9Iu6BpLVICTVZYjoF2wqqpq/fr1qK2A6rKcnByoGgZ1wseJEyfCt2ufRJAWqGT69OlQ6gkODmYwGHp6evHx8aitgO8qLS2FBWhs6t69OzTTaOukcrRXifIJBn0oP5aXl7fZRKLXr19XDcsD1X0LFixAWgq9VQKV3xkZGY3XVFZWws1DmgcyGqjia7wGIsqgQYOQNkJvlUBDoLLjY2MP3jbtgpDdQNxSfYQTYDaAtBF6/6p9+/ZlZ2dDEQOKNhUVFSUlJRD54eY9e/ZM032X4Bv5fD7kdNCuBOVeHx+f4cOHa2ssoVlJWCxU8Cqkgmq5oEYmESsab4LqE1BMeno63DyoyIc2FKRJoGwFEgF9gByhXMNm/znjHctQ38BA35jL4JixzG20IbrQQyVVpbKMRH5GAl8mRxKhgmnIYLCY+gw9hCVMFkNcK5FL5HBpxQKJayeOT5CJRxcOoi24q0TIl18/XlZToajTZ3JtjTkWRohWyKWKmpJafplAKpKGDrYI6MVFNARrldw+U/H0bpWtl5WFE+3bREAuxekVIp5oxDQHO1fadJFRgq9Kft2cz+KYWDhrT5sZIKmVFqSUhgwy8w+jU1DBUiV16L+fZTn62ZpYsZE2AkLpEs7xDzNFNAFHlexekePazcHAWDvrHpQUPC316mLYfYgFogPY1ar9sjHP0ddGuyUCOPrZpCcIoeCG6ABeKrl5spxtyTWmW0Hm3+EUYBd3jVddJkXYg5FKKoulafF8rj2N6xVaC8fa9OqRUoQ9GKnkxskyW0+t6uJFiakNm1+jyM/AfZwwXFRS8kIsEetBvRnSMaA2KD6mBuENLipJjePpY/w6VnzS5cVf9BAKeUjdsLkGBVm10DKFMAYXlWQlC0xtdC6QKDG1Ns5+gnVhBwuVVBRLWWymIYeFdBKuncnLNDHCGCyqJapKJHVIgw28L/NTLlzZnleQqlDIvTxDxwz/xMK8fpyLfUeW6usxfLx6XL99oIZXZmvtPnbkYjcXf9gkl8tO/77pcdLFOoXCt9MbHu4aHJIJnpC8NKwnLMQiltTWyBgsBtIMFZUFO36aq6/PmD1t+8ypPwoEVf/d95FMVl9LwWIYZOXGg3oWzjm4culFIyPO8dNrlamib/78IO7U6OEffzJnv7tLwLUbGhzjimnAEAmIL6FCUCPXnEruPDiup68fMWGVg72Xq7PfpHFflZa/ePIspn6bnp5MKh41bIGBgRH8BQUOKyzOkMoksOVR4gV/377dg0ZZW7n06jnB2yMUaQx9hh78iYUKhCtYqEQhRwymps7kRd5TVydfNvuPpjVLC0cLc4eConTlRxAB6EO5bMyub6eFggxEmrLyl67O/qqDgLyQJjHkMOUY18Fi4UuMufpSkQRpBpFYkPMicenKPzs4yuVScCHKZSbT8O8J6uokkvpqLgPWnw0FhoaaLH/VIUGlBC4CwhVMVMKUyzRV/8g2NAHvOW7U0sYrDQ2bawdgNUQXofjP0qkmakpUSMVyI46mMly1gIVKTM1ZLANNPUmQWcQnX7aydGYw/vixJaW5piZWzSRhMQ0gVyosTFetSct8iDSGTCy374B1XREWUc7e3bCyQCCXasS+hfcYJxTxjp74Or8wrbTsxeXruzdsnZRfmNp8qm4BQ5JSrj94dKawKOP6rQPgapHGqCkR2DhhXVeESzcON18TuFgWTurvvgV2FcrA5y79uG3XDCgP29t5RU753sXJt/lUg/tH8msrz17YrKhT+HXq8+bguQd//RyWkQYQVAi8Ah0QxuDSVy3nae3DaD40fSEdQyaSV74om7DAEWEMLr7a3c9YXCMS8TRV0sGWkqwKvx649wDHqOPgG2Otbp2pcAlseoxoqMDYvGNqk5v09fRflReEdx/35uA5SE3kvkzetf/jJjdB3T9U9jfZzNAjeMyoYfObTCUWSCUCsW9P3IfFxqt39Lk9xQwOl23WRBcChUIhFjc927BEIlLVjP0NBoP1qk3/AmjcUValNLkJTI9qgIwWnkNZZnnIAI67L+7d87DrQ79tUYbvAHc9fUzf7lQjpdlVtvao79s0sGLY1fdNXuKaeT8PaTsVeTxGnZgWEkF4vo/Dr5Yf+S7PK9xZT0sDCkjEiCV9cyptppzDse3AxIwxbp5DytVsUY0WFnlKMyo4hmIaSQRh/jb5+T1F1ZV11h6WBmxteImrqoBfklnRfbBl1/5miFbgPjJFejz/5skyrp2pkakBTTvGSoQyXsPgFDZOzL5v23DMsG7YaxJ6jHKT+pCf8rCmILPW2o0L58syhAZ/hj4T06Z2KKBJhTKZWCaXKWqrhKiuroMfJ7CPuZUDXTv20mrErDqU86y2oljCq5QJquQSMaa9ADlmBnV1ChMzpoUN09bVyMqBZqOV/BMypwWBGi1/tZ+gFohKCNQQlRCoISohUENUQqCGqIRADVEJgZr/BwAA//94tehRAAAABklEQVQDAP4PcXJTqBVgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph_tools.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f1803-7df4-4740-aa9e-eb1202fa0b8f",
   "metadata": {
    "id": "513f1803-7df4-4740-aa9e-eb1202fa0b8f"
   },
   "source": [
    "### Pruebas del RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700c7f8-7539-4fd6-b1b3-28d7ca801fd4",
   "metadata": {
    "id": "5700c7f8-7539-4fd6-b1b3-28d7ca801fd4",
    "outputId": "aa504549-4a69-414f-c4b0-38e978ba8233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user said \"Hello\". I need to respond appropriately. Since there's no specific query here, I should greet them back and offer help. Let me check if there's any function needed. The provided tools have a retrieve_tool, but the user's message isn't asking for information retrieval. So I don't need to call any functions. Just a friendly response.\n",
      "</think>\n",
      "\n",
      "Hello! How can I assist you today? 😊\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Hello\"\n",
    "\n",
    "for step in graph_tools.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a9ad8a-3ed9-42c9-8a2a-087a5b7e61b4",
   "metadata": {
    "id": "e3a9ad8a-3ed9-42c9-8a2a-087a5b7e61b4"
   },
   "source": [
    "Vemos que no ejecutó el paso de *retriever*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b2fd92-4ee4-43fb-ba42-a3b143f9558d",
   "metadata": {
    "id": "28b2fd92-4ee4-43fb-ba42-a3b143f9558d",
    "outputId": "2813fa5e-70f3-474d-c2a7-e5f7751c5527"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's a CRF?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_tool (412a72ab-ec11-4604-ba3d-88645a5a756f)\n",
      " Call ID: 412a72ab-ec11-4604-ba3d-88645a5a756f\n",
      "  Args:\n",
      "    query: What is a CRF?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_tool\n",
      "\n",
      "Source: {'source': 'https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/', 'start_index': 633}\n",
      "Content: Introduction\n",
      "CRFs were proposed roughly only a year after the Maximum Entropy Markov Model, basically by the same authors. Reading through the original paper that introduced Conditional Random Fields, one finds at the beginning of this sentence:\n",
      "“The critical difference between CRF and MEMM is that the latter uses per-state exponential models for the conditional probabilities of next states given the current state, whereas CRF uses a single exponential model to determine the joint probability of the entire sequence of labels, given the observation sequence. Therefore, in CRF, the weights of different features in different states compete against each other.”\n",
      "This means that in the MEMMs there is a model to compute the probability of the next state, given the current state and the observation. On the other hand, CRF computes all state transitions globally, in a single model.\n",
      "\n",
      "Source: {'source': 'https://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/', 'start_index': 633}\n",
      "Content: Introduction\n",
      "CRFs were proposed roughly only a year after the Maximum Entropy Markov Model, basically by the same authors. Reading through the original paper that introduced Conditional Random Fields, one finds at the beginning of this sentence:\n",
      "“The critical difference between CRF and MEMM is that the latter uses per-state exponential models for the conditional probabilities of next states given the current state, whereas CRF uses a single exponential model to determine the joint probability of the entire sequence of labels, given the observation sequence. Therefore, in CRF, the weights of different features in different states compete against each other.”\n",
      "This means that in the MEMMs there is a model to compute the probability of the next state, given the current state and the observation. On the other hand, CRF computes all state transitions globally, in a single model.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking what a CRF is. Let me check the context provided.\n",
      "\n",
      "From the sources, CRFs are mentioned as being proposed after the Maximum Entropy Markov Model. The key difference is that MEMMs use per-state exponential models for next state probabilities, while CRFs use a single model for the entire sequence of labels. So CRFs consider all state transitions globally, not just individual ones. That means the weights in CRFs compete against each other, unlike MEMMs which have separate models for each state. \n",
      "\n",
      "I need to explain this in three sentences. Start by defining CRF, mention the difference from MEMM, and highlight the global approach with competing weights. Make sure it's concise and clear.\n",
      "</think>\n",
      "\n",
      "A Conditional Random Field (CRF) is a probabilistic model used for sequence labeling tasks, where it computes the joint probability of labels given the observations using a single exponential model. Unlike the Maximum Entropy Markov Model (MEMM), which uses per-state exponential models for individual transitions, CRFs aggregate all state transitions into a global model, allowing features in different states to compete against each other. This global approach enables CRFs to capture complex dependencies between labels in a unified framework.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"What's a CRF?\"\n",
    "\n",
    "for step in graph_tools.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e30161-c2b7-41e5-988e-f12388e71f12",
   "metadata": {
    "id": "33e30161-c2b7-41e5-988e-f12388e71f12"
   },
   "source": [
    "# Práctica final: Construcción de un RAG especializado\n",
    "\n",
    "## Fecha de entrega: 25 de Mayo de 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b449c0-7199-4def-8e9e-58c3b48a3916",
   "metadata": {
    "id": "e0b449c0-7199-4def-8e9e-58c3b48a3916"
   },
   "source": [
    "Desarrolla en equipos de dos/tres personas una aplicación *user-friendly* que implemente un RAG con algún LLM \"ligero\" local usando `ollama`\n",
    "\n",
    "#### Requerimientos\n",
    "\n",
    "- Debería poder correr \"razonablemente bien\" en sus laptops\n",
    "- Interface de usuaria\n",
    "  - Puede ser CLI o GUI\n",
    "    - Opciones GUI: [Streamlit](https://streamlit.io/), [Gradio](https://www.gradio.app/)\n",
    "    - Opciones CLI: [Argparse](https://docs.python.org/3/library/argparse.html), [Click](https://click.palletsprojects.com/en/stable/)\n",
    "  - La usuaria deberia poder agregar sus documentos personales en local\n",
    "    - El soporte de formatos queda a su consideración\n",
    "      - CSVs, txts, pdfs o todos \n",
    "- Agrega documentación sobre el uso y capacidades del sistema\n",
    "  - Recursos sobre documentaciones perronas: https://diataxis.fr/\n",
    "- Agrega una reflexión sobre las limitaciones del sistema y problemas sociales que puedan surgir de los mismos como riesgos, sesgos, protección de datos, implicaciones éticas y su impacto en la diversidad social.\n",
    "  - Aborda los temas que consideres más reelevantes, no necesariamente todos\n",
    "\n",
    "\n",
    "### Ideas de apps (elige una)\n",
    "\n",
    "- StudyBuddy: Aplicación que con base en tus notas de clase y documentos relacionados te ayuda a estudiar para pasar tu examen final.\n",
    "- LegalLangSimplifier: Poder hacer queries en un conjunto de documentos legales (el diario oficial de la federación, la constitución, reglamento de tránsito, mi contrato de empleado de la UNAM) y obtener respuestas entendibles para cualquier persona sin especialización en este lenguaje.\n",
    "- La app que quieras proponer 🧙🏼‍♂️\n",
    "  - Debe utilizar RAG\n",
    "\n",
    "**NOTA:** Experimenten con modelos pequeños para la etapa de desarrollo, modifiquen los prompts y consideren las limitantes de recursos de cómputo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59d81c-8a51-4083-af3b-22b8dffda35c",
   "metadata": {
    "id": "4e59d81c-8a51-4083-af3b-22b8dffda35c"
   },
   "source": [
    "### Referencias\n",
    "\n",
    "- https://python.langchain.com/docs/tutorials/rag/\n",
    "- https://python.langchain.com/docs/tutorials/qa_chat_history/\n",
    "- [Capítulo 14 del libro Speech and Language Processing (Jurafsky et al. 2025)](https://web.stanford.edu/~jurafsky/slp3/14.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0152f927-09fd-4ac1-8c8a-8dcf2a53feda",
   "metadata": {
    "id": "0152f927-09fd-4ac1-8c8a-8dcf2a53feda"
   },
   "source": [
    "![](https://c.tenor.com/RxH7CLG1iC8AAAAC/thats-all-folks-looney.gif)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
