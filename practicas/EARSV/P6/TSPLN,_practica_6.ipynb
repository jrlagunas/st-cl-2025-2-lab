{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3fb258e5",
      "metadata": {
        "id": "3fb258e5"
      },
      "source": [
        "#Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8497e3b2",
      "metadata": {
        "id": "8497e3b2"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import pipeline\n",
        "from huggingface_hub import Repository\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82a939fc",
      "metadata": {
        "id": "82a939fc"
      },
      "source": [
        "#Carga del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf57aba0",
      "metadata": {
        "id": "bf57aba0",
        "outputId": "2682f20b-64f4-4a22-dce5-be2123fc272b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cargamos el dataset de titulares sarcásticos vs. no sarcásticos\n",
        "dataset = load_dataset(\"raquiba/Sarcasm_News_Headline\")  # 49 000 ejemplos aprox.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ac27b91",
      "metadata": {
        "id": "4ac27b91"
      },
      "source": [
        "#Preprocesamiento y tokenización."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45ce81e0",
      "metadata": {
        "id": "45ce81e0",
        "outputId": "ba23b5bd-ba1f-46d3-cf1c-564491b47c4c",
        "colab": {
          "referenced_widgets": [
            "91bb6515be4145758ff42c08a3063ebd"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91bb6515be4145758ff42c08a3063ebd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/26709 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)  # Tokenizer de BERT básico\n",
        "\n",
        "def preprocess(batch):\n",
        "    return tokenizer(batch[\"headline\"],\n",
        "                     truncation=True,\n",
        "                     padding=\"max_length\",\n",
        "                     max_length=128)\n",
        "\n",
        "# Tokenizamos en paralelo\n",
        "dataset = dataset.map(preprocess, batched=True, remove_columns=[\"headline\", \"article_link\"])\n",
        "# Renombramos la columna de etiquetas a \"labels\" para que sea compatible con el Trainer\n",
        "dataset = dataset.rename_column(\"is_sarcastic\", \"labels\")\n",
        "\n",
        "dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d33f4a1",
      "metadata": {
        "id": "4d33f4a1"
      },
      "source": [
        "#Configuración del modelo y entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5619c8c",
      "metadata": {
        "id": "c5619c8c",
        "outputId": "4762b12f-d84c-4d5a-adf9-c028ab14f595"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "C:\\Users\\efrah\\AppData\\Local\\Temp\\ipykernel_8908\\1435210233.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5367' max='5367' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5367/5367 2:15:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.223600</td>\n",
              "      <td>0.070220</td>\n",
              "      <td>0.977386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.088100</td>\n",
              "      <td>0.018745</td>\n",
              "      <td>0.995020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.025300</td>\n",
              "      <td>0.006071</td>\n",
              "      <td>0.998615</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5367, training_loss=0.12810042949724135, metrics={'train_runtime': 8136.6382, 'train_samples_per_second': 10.552, 'train_steps_per_second': 0.66, 'total_flos': 5647481470010880.0, 'train_loss': 0.12810042949724135, 'epoch': 3.0})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cargamos un modelo de clasificación con 2 etiquetas\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "# Definimos argumentos de entrenamiento\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"sarcasm-checkpoint\",\n",
        "    eval_strategy=\"epoch\",      # Evalúa al final de cada época\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=200,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        ")\n",
        "\n",
        "# Creamos el Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=lambda p: {\"accuracy\": (p.predictions.argmax(-1) == p.label_ids).mean()},\n",
        ")\n",
        "# Entrenamiento\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2188a82",
      "metadata": {
        "id": "d2188a82"
      },
      "source": [
        "#Evaluación y prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c0aab1c",
      "metadata": {
        "id": "8c0aab1c",
        "outputId": "e4548918-239d-4a6f-a51b-62618da93d90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.0060714962892234325, 'eval_accuracy': 0.9986146991650754, 'eval_runtime': 760.3585, 'eval_samples_per_second': 35.127, 'eval_steps_per_second': 1.098, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# Evaluar en el test set\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)  # Devuelve accuracy, loss, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f32cbe6b",
      "metadata": {
        "id": "f32cbe6b",
        "outputId": "77722844-21d2-4c95-8525-baf3a303b7ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "c:\\Users\\efrah\\Documents\\Entornos\\TSPLN\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texto: scientist discovers water is wet, wins nobel prize for groundbreaking revelation\n",
            "  Sarcástico: LABEL_0 (0.9507)\n",
            "\n",
            "Texto: local man finally learns to parallel park after 20 years of daily practice\n",
            "  Sarcástico: LABEL_1 (0.9999)\n",
            "\n",
            "Texto: city council announces new plan to solve traffic by building more traffic lights\n",
            "  Sarcástico: LABEL_1 (0.9993)\n",
            "\n",
            "Texto: study confirms people who sleep 8 hours feel more rested\n",
            "  Sarcástico: LABEL_1 (0.9999)\n",
            "\n",
            "Texto: ceo of fast-food chain urges employees to eat healthier during unpaid overtime\n",
            "  Sarcástico: LABEL_1 (0.9999)\n",
            "\n",
            "Texto: new app reminds users to blink regularly while staring at screens\n",
            "  Sarcástico: LABEL_1 (0.9998)\n",
            "\n",
            "Texto: weather forecast predicts rain during outdoor wedding, couple devastated\n",
            "  Sarcástico: LABEL_0 (0.9976)\n",
            "\n",
            "Texto: man wins lifetime supply of broccoli, considers moving to another country\n",
            "  Sarcástico: LABEL_1 (0.9998)\n",
            "\n",
            "Texto: government proposes tax on air to fund climate change initiatives\n",
            "  Sarcástico: LABEL_0 (0.9969)\n",
            "\n",
            "Texto: new yoga studio opens downtown, offers free classes this weekend\n",
            "  Sarcástico: LABEL_1 (0.6936)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Función de inferencia básica\n",
        "\n",
        "sarcasm_pipe = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"EARSV/sarcasm-detector\",\n",
        "    tokenizer=\"EARSV/sarcasm-detector\",\n",
        "    return_all_scores=False\n",
        ")\n",
        "# Prueba rápida\n",
        "examples = [\n",
        "    \"scientist discovers water is wet, wins nobel prize for groundbreaking revelation\",\n",
        "    \"local man finally learns to parallel park after 20 years of daily practice\",\n",
        "    \"city council announces new plan to solve traffic by building more traffic lights\",\n",
        "    \"study confirms people who sleep 8 hours feel more rested\",\n",
        "    \"ceo of fast-food chain urges employees to eat healthier during unpaid overtime\",\n",
        "    \"new app reminds users to blink regularly while staring at screens\",\n",
        "    \"weather forecast predicts rain during outdoor wedding, couple devastated\",\n",
        "    \"man wins lifetime supply of broccoli, considers moving to another country\",\n",
        "    \"government proposes tax on air to fund climate change initiatives\",\n",
        "    \"new yoga studio opens downtown, offers free classes this weekend\"\n",
        "]\n",
        "\n",
        "for text in examples:\n",
        "    res = sarcasm_pipe(text)[0]\n",
        "    print(f\"Texto: {text}\\n  Sarcástico: {res['label']} ({res['score']:.4f})\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "561f8518",
      "metadata": {
        "id": "561f8518"
      },
      "source": [
        "#Subir el modelo a Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a710bcfe",
      "metadata": {
        "id": "a710bcfe",
        "outputId": "cf22eb07-0548-4fb1-f687-155e7b533f6f",
        "colab": {
          "referenced_widgets": [
            "fe022f56bf48408a8d42b8452eb198f7"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Copia de Seguridad\\Documentos\\Carrera Ciencia de Datos\\8.Octavo Semestre\\Procesamiento de Lenguaje Natural\\Practicas\\P6\\sarcasm-detector-local is already a clone of https://huggingface.co/EARSV/sarcasm-detector. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe022f56bf48408a8d42b8452eb198f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload file model.safetensors:   0%|          | 1.00/418M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: \u001b[33m-------------------------------------------------------------------------\u001b[0m        \n",
            "remote: \u001b[33mYour push was accepted, but with warnings: \u001b[0m        \n",
            "remote: \u001b[33m- Warning: empty or missing yaml metadata in repo card\u001b[0m        \n",
            "remote: \u001b[33mhelp: https://huggingface.co/docs/hub/model-cards#model-card-metadata\u001b[0m        \n",
            "remote: \u001b[33m-------------------------------------------------------------------------\u001b[0m        \n",
            "remote: \u001b[32m-------------------------------------------------------------------------\u001b[0m        \n",
            "remote: \u001b[32mPlease find the documentation at:\u001b[0m        \n",
            "remote: \u001b[32mhttps://huggingface.co/docs/hub/model-cards#model-card-metadata\u001b[0m        \n",
            "remote: \u001b[32m\u001b[0m        \n",
            "remote: \u001b[32m-------------------------------------------------------------------------\u001b[0m        \n",
            "To https://huggingface.co/EARSV/sarcasm-detector\n",
            "   093b3f9..b630f4b  main -> main\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'https://huggingface.co/EARSV/sarcasm-detector/commit/b630f4b8093b3e7507041edfbb7f6f0e342c6e54'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Clonamos el repo de Hugging Face donde subiremos el modelo\n",
        "repo = Repository(\n",
        "    local_dir=\"sarcasm-detector-local\",\n",
        "    clone_from=\"EARSV/sarcasm-detector\"\n",
        ")\n",
        "\n",
        "# Copiamos el modelo y el tokenizer al repo\n",
        "model.save_pretrained(\"sarcasm-detector-local/\")\n",
        "tokenizer.save_pretrained(\"sarcasm-detector-local/\")\n",
        "\n",
        "# Añadimos el README.md\n",
        "with open(\"sarcasm-detector-local/README.md\",\"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "# Sarcasm Detector\n",
        "\n",
        "Fine-tuned `bert-base-uncased` on raquiba/Sarcasm_News_Headline.\n",
        "\n",
        "**Exactitud (test)**: 99.86 %\n",
        "**Epochs**: 3\n",
        "**Batch size**: 16\n",
        "**Dataset**: titulares con etiqueta `is_sarcastic`\n",
        "    \"\"\")\n",
        "\n",
        "# Commit y push\n",
        "repo.push_to_hub(commit_message=\"Initial upload of sarcasm-detector\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}