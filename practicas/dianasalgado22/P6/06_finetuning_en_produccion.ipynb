{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053db5ad",
   "metadata": {},
   "source": [
    "# Pr√°ctica 6: *Fine-tuning en producci√≥n*\n",
    "\n",
    "**Fecha de entrega: 11 de Mayo de 2025**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd1c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading 06_finetuning_en_produccion.ipynb in format ipynb\n",
      "[jupytext] Updating notebook metadata with '{\"jupytext\": {\"formats\": \"ipynb,py\"}}'\n",
      "[jupytext] Updating 06_finetuning_en_produccion.ipynb\n",
      "[jupytext] Updating 06_finetuning_en_produccion.py\n"
     ]
    }
   ],
   "source": [
    "#!jupytext --set-formats ipynb,py 06_finetuning_en_produccion.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48625fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from transformers import Trainer, AutoModelForSequenceClassification, AutoTokenizer√±\n",
    "from transformers import DataCollatorWithPadding\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import utils\n",
    "\n",
    "\n",
    "# Descargadas\n",
    "from codecarbon import EmissionsTracker\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5209eeab",
   "metadata": {},
   "source": [
    "## Hacer el fine tuning del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc33c4",
   "metadata": {},
   "source": [
    "\n",
    "- Selecciona un modelo pre-entrenado como base y realiza *fine-tuning* para resolver alguna tarea de NLP que te parezca reelevante\n",
    "  - Procura utilizar datasets peque√±os para que sea viable\n",
    "  - Recuerda las posibles tareas disponibles en HF `*For<task>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "376d95c3-7bff-48ca-8104-8b23cad6cfee",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Detectar el dispositivo (CPU o GPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdc3193e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2947/2947 [00:00<00:00, 34824.03 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 368/368 [00:00<00:00, 28619.98 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizacion del modelo terminada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dianasalgado/.local/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_61546/1371394887.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "[codecarbon WARNING @ 13:20:51] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "[codecarbon INFO @ 13:20:51] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 13:20:51] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 13:20:52] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 13:20:52] CPU Model on constant consumption mode: Intel(R) Core(TM) i9-10850K CPU @ 3.60GHz\n",
      "[codecarbon WARNING @ 13:20:52] No CPU tracking mode found. Falling back on CPU load mode.\n",
      "[codecarbon INFO @ 13:20:52] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 13:20:52] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 13:20:52] The below tracking methods have been set up:\n",
      "                RAM Tracking Method: RAM power estimation model\n",
      "                CPU Tracking Method: cpu_load\n",
      "                GPU Tracking Method: pynvml\n",
      "            \n",
      "[codecarbon INFO @ 13:20:52] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 13:20:52]   Platform system: Linux-6.8.0-58-generic-x86_64-with-glibc2.35\n",
      "[codecarbon INFO @ 13:20:52]   Python version: 3.10.12\n",
      "[codecarbon INFO @ 13:20:52]   CodeCarbon version: 3.0.1\n",
      "[codecarbon INFO @ 13:20:52]   Available RAM : 31.255 GB\n",
      "[codecarbon INFO @ 13:20:52]   CPU count: 20 thread(s) in 1 physical CPU(s)\n",
      "[codecarbon INFO @ 13:20:52]   CPU model: Intel(R) Core(TM) i9-10850K CPU @ 3.60GHz\n",
      "[codecarbon INFO @ 13:20:52]   GPU count: 1\n",
      "[codecarbon INFO @ 13:20:52]   GPU model: 1 x NVIDIA GeForce RTX 3080\n",
      "[codecarbon INFO @ 13:20:55] Emissions data (if any) will be saved to file /home/dianasalgado/Documentos/Practica06/Ejecuciones/runs/Model_delarosajav95_HateSpeech-BETO-cased-v2/250508T132050/emissions.csv\n",
      "[codecarbon WARNING @ 13:20:55] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "[codecarbon INFO @ 13:20:55] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 13:20:55] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 13:20:56] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 13:20:56] CPU Model on constant consumption mode: Intel(R) Core(TM) i9-10850K CPU @ 3.60GHz\n",
      "[codecarbon WARNING @ 13:20:56] No CPU tracking mode found. Falling back on CPU load mode.\n",
      "[codecarbon INFO @ 13:20:56] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 13:20:56] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 13:20:57] The below tracking methods have been set up:\n",
      "                RAM Tracking Method: RAM power estimation model\n",
      "                CPU Tracking Method: cpu_load\n",
      "                GPU Tracking Method: pynvml\n",
      "            \n",
      "[codecarbon INFO @ 13:20:57] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 13:20:57]   Platform system: Linux-6.8.0-58-generic-x86_64-with-glibc2.35\n",
      "[codecarbon INFO @ 13:20:57]   Python version: 3.10.12\n",
      "[codecarbon INFO @ 13:20:57]   CodeCarbon version: 3.0.1\n",
      "[codecarbon INFO @ 13:20:57]   Available RAM : 31.255 GB\n",
      "[codecarbon INFO @ 13:20:57]   CPU count: 20 thread(s) in 1 physical CPU(s)\n",
      "[codecarbon INFO @ 13:20:57]   CPU model: Intel(R) Core(TM) i9-10850K CPU @ 3.60GHz\n",
      "[codecarbon INFO @ 13:20:57]   GPU count: 1\n",
      "[codecarbon INFO @ 13:20:57]   GPU model: 1 x NVIDIA GeForce RTX 3080\n",
      "[codecarbon INFO @ 13:21:00] Emissions data (if any) will be saved to file /home/dianasalgado/Documentos/Practica06/emissions.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2211' max='2211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2211/2211 01:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.631200</td>\n",
       "      <td>0.449598</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.827957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.758325</td>\n",
       "      <td>0.834239</td>\n",
       "      <td>0.839895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.876154</td>\n",
       "      <td>0.831522</td>\n",
       "      <td>0.841837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 13:21:15] Energy consumed for RAM : 0.000086 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 13:21:16] Delta energy consumed for CPU with cpu_load : 0.000058 kWh, power : 13.391666666666667 W\n",
      "[codecarbon INFO @ 13:21:16] Energy consumed for All CPU : 0.000058 kWh\n",
      "[codecarbon INFO @ 13:21:16] Energy consumed for all GPUs : 0.001120 kWh. Total GPU Power : 252.0076046426905 W\n",
      "[codecarbon INFO @ 13:21:16] 0.001264 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:21:16] Energy consumed for RAM : 0.000086 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 13:21:16] Delta energy consumed for CPU with cpu_load : 0.000057 kWh, power : 13.191666666666668 W\n",
      "[codecarbon INFO @ 13:21:16] Energy consumed for All CPU : 0.000057 kWh\n",
      "[codecarbon INFO @ 13:21:16] Energy consumed for all GPUs : 0.001150 kWh. Total GPU Power : 258.5313336662824 W\n",
      "[codecarbon INFO @ 13:21:16] 0.001292 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:21:30] Energy consumed for RAM : 0.000167 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 13:21:31] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.9453125 W\n",
      "[codecarbon INFO @ 13:21:31] Energy consumed for All CPU : 0.000110 kWh\n",
      "[codecarbon INFO @ 13:21:31] Energy consumed for all GPUs : 0.002261 kWh. Total GPU Power : 273.6747162971153 W\n",
      "[codecarbon INFO @ 13:21:31] 0.002537 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:21:31] Energy consumed for RAM : 0.000167 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 13:21:31] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.9296875 W\n",
      "[codecarbon INFO @ 13:21:31] Energy consumed for All CPU : 0.000109 kWh\n",
      "[codecarbon INFO @ 13:21:31] Energy consumed for all GPUs : 0.002264 kWh. Total GPU Power : 267.32802936910855 W\n",
      "[codecarbon INFO @ 13:21:31] 0.002539 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:21:45] Energy consumed for RAM : 0.000247 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 13:21:46] Delta energy consumed for CPU with cpu_load : 0.000059 kWh, power : 14.546875 W\n",
      "[codecarbon INFO @ 13:21:46] Energy consumed for All CPU : 0.000168 kWh\n",
      "[codecarbon INFO @ 13:21:46] Energy consumed for all GPUs : 0.003297 kWh. Total GPU Power : 248.78298574668173 W\n",
      "[codecarbon INFO @ 13:21:46] 0.003712 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:21:46] Energy consumed for RAM : 0.000247 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 13:21:46] Delta energy consumed for CPU with cpu_load : 0.000060 kWh, power : 14.8203125 W\n",
      "[codecarbon INFO @ 13:21:46] Energy consumed for All CPU : 0.000169 kWh\n",
      "[codecarbon INFO @ 13:21:46] Energy consumed for all GPUs : 0.003323 kWh. Total GPU Power : 254.328088780098 W\n",
      "[codecarbon INFO @ 13:21:46] 0.003738 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:22:00] Energy consumed for RAM : 0.000328 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 13:22:01] Delta energy consumed for CPU with cpu_load : 0.000059 kWh, power : 14.6328125 W\n",
      "[codecarbon INFO @ 13:22:01] Energy consumed for All CPU : 0.000227 kWh\n",
      "[codecarbon INFO @ 13:22:01] Energy consumed for all GPUs : 0.004467 kWh. Total GPU Power : 280.9038721222068 W\n",
      "[codecarbon INFO @ 13:22:01] 0.005022 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:22:01] Energy consumed for RAM : 0.000328 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 13:22:01] Delta energy consumed for CPU with cpu_load : 0.000058 kWh, power : 14.375 W\n",
      "[codecarbon INFO @ 13:22:01] Energy consumed for All CPU : 0.000226 kWh\n",
      "[codecarbon INFO @ 13:22:01] Energy consumed for all GPUs : 0.004496 kWh. Total GPU Power : 281.7307173016274 W\n",
      "[codecarbon INFO @ 13:22:01] 0.005050 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:22:15] Energy consumed for RAM : 0.000408 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 13:22:16] Delta energy consumed for CPU with cpu_load : 0.000052 kWh, power : 12.9765625 W\n",
      "[codecarbon INFO @ 13:22:16] Energy consumed for All CPU : 0.000280 kWh\n",
      "[codecarbon INFO @ 13:22:16] Energy consumed for all GPUs : 0.005515 kWh. Total GPU Power : 251.5771196234355 W\n",
      "[codecarbon INFO @ 13:22:16] 0.006203 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:22:16] Energy consumed for RAM : 0.000408 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 13:22:16] Delta energy consumed for CPU with cpu_load : 0.000054 kWh, power : 13.375 W\n",
      "[codecarbon INFO @ 13:22:16] Energy consumed for All CPU : 0.000280 kWh\n",
      "[codecarbon INFO @ 13:22:16] Energy consumed for all GPUs : 0.005545 kWh. Total GPU Power : 251.57691400122079 W\n",
      "[codecarbon INFO @ 13:22:16] 0.006233 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:22:30] Energy consumed for RAM : 0.000489 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 13:22:31] Delta energy consumed for CPU with cpu_load : 0.000053 kWh, power : 13.1015625 W\n",
      "[codecarbon INFO @ 13:22:31] Energy consumed for All CPU : 0.000332 kWh\n",
      "[codecarbon INFO @ 13:22:31] Energy consumed for all GPUs : 0.006697 kWh. Total GPU Power : 283.74360994075806 W\n",
      "[codecarbon INFO @ 13:22:31] 0.007518 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:22:31] Energy consumed for RAM : 0.000489 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 13:22:31] Delta energy consumed for CPU with cpu_load : 0.000054 kWh, power : 13.4140625 W\n",
      "[codecarbon INFO @ 13:22:31] Energy consumed for All CPU : 0.000334 kWh\n",
      "[codecarbon INFO @ 13:22:31] Energy consumed for all GPUs : 0.006728 kWh. Total GPU Power : 284.096693027497 W\n",
      "[codecarbon INFO @ 13:22:31] 0.007551 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:22:43] Energy consumed for RAM : 0.000551 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 13:22:43] Delta energy consumed for CPU with cpu_load : 0.000039 kWh, power : 12.5 W\n",
      "[codecarbon INFO @ 13:22:43] Energy consumed for All CPU : 0.000373 kWh\n",
      "[codecarbon INFO @ 13:22:43] Energy consumed for all GPUs : 0.007213 kWh. Total GPU Power : 149.49768825137352 W\n",
      "[codecarbon INFO @ 13:22:43] 0.008136 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento del modelo delarosajav95/HateSpeech-BETO-cased-v2 terminada\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='184' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [92/92 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 13:22:45] Energy consumed for RAM : 0.000569 kWh. RAM Power : 20.0 W\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluacion del modelo delarosajav95/HateSpeech-BETO-cased-v2 terminada\n",
      "{'eval_loss': 0.4495979845523834, 'eval_accuracy': 0.8260869565217391, 'eval_f1': 0.8279569892473119, 'eval_runtime': 2.5274, 'eval_samples_per_second': 145.603, 'eval_steps_per_second': 36.401, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 13:22:46] Delta energy consumed for CPU with cpu_load : 0.000051 kWh, power : 12.552083333333334 W\n",
      "[codecarbon INFO @ 13:22:46] Energy consumed for All CPU : 0.000383 kWh\n",
      "[codecarbon INFO @ 13:22:46] Energy consumed for all GPUs : 0.007348 kWh. Total GPU Power : 156.24832849115776 W\n",
      "[codecarbon INFO @ 13:22:46] 0.008301 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:22:49] Energy consumed for RAM : 0.000585 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 13:22:49] Delta energy consumed for CPU with cpu_load : 0.000010 kWh, power : 12.5 W\n",
      "[codecarbon INFO @ 13:22:49] Energy consumed for All CPU : 0.000393 kWh\n",
      "[codecarbon INFO @ 13:22:49] Energy consumed for all GPUs : 0.007480 kWh. Total GPU Power : 139.47758824241726 W\n",
      "[codecarbon INFO @ 13:22:49] 0.008458 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 13:22:49] 0.039214 g.CO2eq/s mean an estimation of 1,236.661527426431 kg.CO2eq/year\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emisiones estimadas durante el ajuste fino del modelo: 0.004290 kg CO‚ÇÇ\n"
     ]
    }
   ],
   "source": [
    "# rutas con los datos\n",
    "main_dir = \"./data\"\n",
    "train_rute = main_dir + '/train_es_LimpiezaFinal.csv'\n",
    "test_rute = main_dir + '/dev_es_LimpiezaFinal.csv'\n",
    "\n",
    "# Nombre del modelo\n",
    "model_name = \"delarosajav95/HateSpeech-BETO-cased-v2\"\n",
    "# Nombre del tokenizador\n",
    "tokenizer_name = \"delarosajav95/HateSpeech-BETO-cased-v2\"\n",
    "\n",
    "# Definir el directorio de salida con una marca de tiempo\n",
    "run_dir = join('./Ejecuciones', 'runs', f'Model_{model_name.replace(\"/\", \"_\")}', utils.timestamp())\n",
    "\n",
    "# Cargar los datos y procesarlos\n",
    "train_dataset,eval_dataset,test_dataset = utils.prepareDatasets(train_rute, test_rute)\n",
    "\n",
    "# Tokenizar los datos \n",
    "tokenized_train, tokenized_dev, tokenizer = utils.tokenizer(tokenizer_name,\n",
    "                                                                train_dataset,\n",
    "                                                                eval_dataset)\n",
    "\n",
    "# Preparar el objeto para la recolecci√≥n y padding din√°mico de los datos\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Inicializar el modelo pre-entrenado\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
    "\n",
    "# Generar los argumentos de entrenamiento\n",
    "training_args= utils.newTrainingArguments(run_dir)\n",
    "\n",
    "# Configurar el entrenador (Trainer)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics= utils.compute_metrics\n",
    ")\n",
    "\n",
    "# Iniciar el rastreador\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "\n",
    "# Entrenar el modelo\n",
    "trainer.train()\n",
    "print(f\"Entrenamiento del modelo {model_name} terminada\")\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "evaluation_results = trainer.evaluate()\n",
    "\n",
    "print(f\"Evaluacion del modelo {model_name} terminada\")\n",
    "print(evaluation_results)\n",
    "\n",
    "# Guardar la informacion del entrenamiento y la evaluacion\n",
    "utils.save_info(model,run_dir,trainer,training_args,tokenizer)\n",
    "\n",
    "# Detener y mostrar emisiones\n",
    "emissions = tracker.stop()\n",
    "print(f\"Emisiones estimadas durante el ajuste fino del modelo: {emissions:.6f} kg CO‚ÇÇ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a0fec3",
   "metadata": {},
   "source": [
    "## Poner en producci√≥n el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d358b9e1",
   "metadata": {},
   "source": [
    "Este codigo se encuentra en la carpeta *detectorSexismo*\n",
    "\n",
    "El url de la aplicaci√≥n es : https://huggingface.co/spaces/diana-salgado/detectorSexismo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796b34b9",
   "metadata": {},
   "source": [
    "## Reporte de la actividad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f94995",
   "metadata": {},
   "source": [
    "Durante esta actividad, desarroll√© y publiqu√© una aplicaci√≥n web basada en un modelo de lenguaje entrenado para clasificar textos en espa√±ol como sexistas o no sexistas. La tarea se resolvi√≥ de forma satisfactoria, ya que el modelo logra ofrecer resultados interpretables y r√°pidos para cualquier oraci√≥n corta escrita en espa√±ol, lo cual resulta √∫til tanto en contextos acad√©micos como en an√°lisis social o monitoreo de contenido en redes.\n",
    "\n",
    "**Utilidad de la Aplicaci√≥n**\n",
    "\n",
    "La app es particularmente √∫til para usuarios que desean identificar sesgos de g√©nero en lenguaje cotidiano, especialmente en publicaciones de redes sociales como Twitter. Al estar disponible p√∫blicamente en Hugging Face Spaces, es accesible desde cualquier dispositivo y puede servir como herramienta educativa o de apoyo en proyectos de investigaci√≥n relacionados con el an√°lisis de discurso o igualdad de g√©nero.\n",
    "\n",
    "**Fine-tuning del Modelo**\n",
    "\n",
    "El entrenamiento del modelo fue relativamente sencillo, ya que reutilic√© c√≥digo previamente desarrollado durante mi servicio social. Originalmente, prob√© m√∫ltiples modelos antes de seleccionar el m√°s efectivo para espa√±ol: [delarosajav95/HateSpeech-BETO-cased-v2]. El conjunto de datos utilizado fue el corpus de la competencia EXIST 2024, compuesto por tweets en espa√±ol, al cual se le aplic√≥ preprocesamiento (limpieza de s√≠mbolos no alfanum√©ricos, stopwords, conversi√≥n a min√∫sculas, etc.).\n",
    "\n",
    "Dado que entrenar en mi laptop con CPU resultaba demasiado lento, realic√© el ajuste fino en una computadora del laboratorio LATTE del instituto, equipada con una NVIDIA GeForce RTX 3080, logrando completar el entrenamiento en menos de 5 minutos.\n",
    "\n",
    "**Producci√≥n y Despliegue**\n",
    "\n",
    "Poner el modelo en producci√≥n represent√≥ un mayor reto, ya que era la primera vez que lo publicaba en Hugging Face Spaces. Aunque inicialmente fue una curva de aprendizaje considerable, el proceso fue bastante amigable gracias a la documentaci√≥n oficial de Hugging Face y al apoyo recibido de herramientas como ChatGPT. Aprend√≠ a empaquetar correctamente el modelo, generar el archivo requirements.txt, y estructurar el c√≥digo para que fuese compatible con Gradio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d90b14",
   "metadata": {},
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6796d1",
   "metadata": {},
   "source": [
    "**Reporte de emisiones con CodeCarbon**\n",
    "\n",
    "Utilic√© CodeCarbon para medir el impacto ambiental del ajuste fino de mi modelo. El entrenamiento fue realizado en una m√°quina con GPU NVIDIA GeForce RTX 3080, y las emisiones estimadas fueron de **0.0041 kg de CO‚ÇÇ**, lo que equivale aproximadamente a la energ√≠a consumida por una l√°mpara LED encendida durante unas 3 horas. No fue posible medir las emisiones de la aplicaci√≥n en producci√≥n, ya que Hugging Face Spaces no permite el monitoreo del consumo energ√©tico del entorno, por lo que CodeCarbon no puede ser utilizado de forma efectiva en ese contexto."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
